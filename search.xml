<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[lamp使用https]]></title>
    <url>%2F2018%2F08%2F08%2Flamp%E4%BD%BF%E7%94%A8https%2F</url>
    <content type="text"><![CDATA[直接使用yum安装lamp环境1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#安装lamp[root@www2 ~] yum -y install mariadb-server httpd php php-mysql php-fpm openssl-devel#安装http支持ssl的模板，安装成功后，会有/etc/httpd/conf.d/ssl.conf 文件[root@www2 ~] yum install mod_ssl -y#启动lamp环境相关服务[root@www2 httpd]# systemctl restart httpd[root@www2 httpd]# systemctl restart mariadb[root@www2 httpd]# systemctl restart php-fpm#设置mysql数据库密码，创建安装discuz和WordPress的数据库[root@www2 httpd]#mysqlMariaDB [(none)]&gt; set password=password('123qwe'); #设置数据库密码Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.01 sec)MariaDB [(none)]&gt; create database discuz; #创建数据库Query OK, 1 row affected (0.00 sec)#授权www可以本地登陆MariaDB [(none)]&gt; grant all on discuz.* to www@'localhost' identified by '123qwe'; Query OK, 0 rows affected (0.00 sec)#设置www可以远程登陆数据库MariaDB [(none)]&gt; grant all on discuz.* to www@'%' identified by '123qwe';Query OK, 0 rows affected (0.00 sec)#将生成的签名放入到/etc/httpd/conf.d/下[root@www2 httpd]# ls conf.d/autoindex.conf README server.csr ssl.conf welcome.confphp.conf server.crt server.key userdir.conf server.key.unsecure#将保护私钥的密码从认证文件里抽离出来，生成server.key.unsecure[root@www2 ~]# openssl rsa -in server.key -out server.key.unsecure#修改ssl的配置文件，指明认证文件位置[root@www2 ~]# vim /etc/httpd/conf.d/ssl.conf100 SSLCertificateFile /etc/httpd/conf.d/server.crt 101 102 # Server Private Key:103 # If the key is not combined with the certificate, use this104 # directive to point at the key file. Keep in mind that if105 # you've both a RSA and a DSA private key you can configure106 # both in parallel (to also allow the use of DSA ciphers, etc.)107 SSLCertificateKeyFile /etc/httpd/conf.d/server.key.unsecure [root@www2 ~]# vim /etc/php.ini #修改php配置文件，让httpd支持phpshort_open_tag = On # 重启lamp环境的服务，让修改的配置生效设置httpd虚拟机主机,在相应的地方创建相应的目录及文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#修改httpd配置文件，加载相应的模块[root@www2 ~]# vim /etc/httpd/conf/httpd.conf ServerName 192.168.100.20:80 LoadModule socache_dbm_module modules/mod_socache_dbm.soLoadModule socache_shmcb_module modules/mod_socache_shmcb.soLoadModule ssl_module modules/mod_ssl.so #开启ssl模块LoadModule rewrite_module modules/mod_rewrite.so #开启重定向[root@www2 ~]# vim /etc/httpd/conf.d/vhost.conf &lt;Directory "/var/www/html/www1"&gt; #设置虚机目录权限Options FollowSymLinks #Options通常有Indexes选项，它的作用就是当该目录下没有 index.html 文件时，就显示目录结构，去掉 Indexes，Apache 就不会显示该目录的列表了。AllowOverride All #是否允许覆盖，All是允许，可让.htaccess文件可以生效，None是不允许，由于要http强制跳转到https，所以需要开启这一选项Require all granted #响应所有请求&lt;/Directory&gt;&lt;VirtualHost 192.168.100.20:8081&gt; #虚机ip及端口，这个端口是通过443转发访问的，httpd的主配置文件不需要添加Listen这个端口的配置DocumentRoot "/var/www/html/www1" #虚机目录ServerName 192.168.100.10 #虚机域名ErrorLog "logs/www1-error_log" CustomLog "logs/www1-access_log" common&lt;/VirtualHost&gt;&lt;Directory "/var/www/html/www2"&gt;Options FollowSymLinksAllowOverride AllRequire all granted &lt;/Directory&gt;&lt;VirtualHost 192.168.100.20:8088&gt;DocumentRoot "/var/www/html/www2"ServerName 192.168.100.10 ErrorLog "logs/www2-error_log" CustomLog "logs/www2-access_log" common&lt;/VirtualHost&gt;&lt;Directory "/var/www/html/discuz/upload"&gt;Options FollowSymLinksAllowOverride AllRequire all granted &lt;/Directory&gt;&lt;VirtualHost 192.168.100.20:8888&gt;DocumentRoot "/var/www/html/discuz/upload"ServerName 192.168.100.10 ErrorLog "logs/discuz-error_log" CustomLog "logs/discuz-access_log" common&lt;/VirtualHost&gt;&lt;Directory "/var/www/html/wordpress"&gt;Options FollowSymLinksAllowOverride AllRequire all granted &lt;/Directory&gt;&lt;VirtualHost 192.168.100.20:8000&gt;DocumentRoot "/var/www/html/wordpress"ServerName 192.168.100.10 ErrorLog "logs/wordpress-error_log" CustomLog "logs/wordpress-access_log" common&lt;/VirtualHost&gt;设置Apache的rewrite功能123456[root@www2 ~]# vim /var/www/html/www1/.htaccess RewriteEngine onRewriteCond %&#123;SERVER_PORT&#125; !^443$RewriteRule ^(.*)?$ https://%&#123;SERVER_NAME&#125;%&#123;REQUEST_URI&#125; [L,R]#在其他三个虚机的根目录下也穿件相同的.htaccess文件在火狐浏览器上访问，导入ca证书，存入本地导入成功，就会http自动跳转到https，之后安装网页模板验证：输入https://192.168.100.20/discuz/upload/install进行安装，安装成功后如下]]></content>
      <categories>
        <category>CA</category>
      </categories>
      <tags>
        <tag>CA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统开机过程]]></title>
    <url>%2F2018%2F07%2F31%2F%E7%B3%BB%E7%BB%9F%E5%BC%80%E6%9C%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[步骤1：上电自检POST(Power-on self test)，主要负责检测系统外围关键设备（如：CPU、内存、显卡、I/O、键盘鼠标等）是否正常。例如，最常见的是内存松动的情况，BIOS自检阶段会报错，系统就无法启动起来；步骤2：步骤1成功后，便会执行一段小程序用来枚举本地设备并对其初始化。这一步主要是根据我们在BIOS中设置的系统启动顺序来搜索用于启动系统的驱动器，如硬盘、光盘、U盘、软盘和网络等。我们以硬盘启动为例，BIOS此时去读取硬盘驱动器的第一个扇区(MBR，512字节)，然后执行里面的代码。实际上这里BIOS并不关心启动设备第一个扇区中是什么内容，它只是负责读取该扇区内容、并执行。至此，BIOS的任务就完成了，此后将系统启动的控制权移交到MBR部分的代码。步骤3：系统引导grub引导也分为两个阶段stage1阶段和stage2阶段1)、stage1：stage1是直接被写入到MBR中去的，这样机器一启动检测完硬件后，就将控制权交给了GRUB的代码。 BIOS将stage1载入内存中0x7c00处并跳转执行。stage1（/stage1/start.S）的任务非常单纯，仅仅是将硬盘0头0道2扇区读入内存。而0头0道2扇区内容是源代码中的/stage2/start.S，编译后512字节，它是stage2或者stage1_5的入口。而此时，stage1是没有识别文件系统的能力的。2)、stage2： 它的主要作用就是负责将stage2或stage1.5从硬盘读到内存中。如果是stage2，它将被载入到0x820处；如果是stage1.5，它将被载入到0x2200处。这里的stage2或者stage1_5不是/boot分区/boot/grub目录下的文件，因为这个时候grub还没有能力识别任何文件系统。步骤4：启动内核当stage2被载入内存执行时，它首先会去解析grub的配置文件/boot/grub/grub.conf，然后加载内核镜像到内存中，并将控制权转交给内核。而内核会立即初始化系统中各设备并做相关的配置工作，其中包括CPU、I/O、存储设备等。Linux的内核镜像仅是包含了基本的硬件驱动，在系统安装过程中会检测系统硬件信息，根据安装信息和系统硬件信息将一部分设备驱动写入 initrd 。这样在以后启动系统时，一部分设备驱动就放在initrd中来加载。grub的stage2将initrd加载到内存里，让后将其中的内容释放到内容中，内核便去执行initrd中的init脚本，这时内核将控制权交给了init文件处理。我们简单浏览一下init脚本的内容，发现它也主要是加载各种存储介质相关的设备驱动程序。当所需的驱动程序加载完后，会创建一个根设备，然后将根文件系统rootfs以只读的方式挂载。这一步结束后，释放未使用的内存，转换到真正的根文件系统上面去，同时运行/sbin/init程序，执行系统的1号进程。此后系统的控制权就全权交给/sbin/init进程了。步骤5：初始化系统1)、执行系统初始化脚本(/etc/rc.d/rc.sysinit)，对系统进行基本的配置，以读写方式挂载根文件系统及其它文件系统，到此系统算是基本运行起来了，后面需要进行运行级别的确定及相应服务的启动。2)、执行/etc/rc.d/rc脚本。该文件定义了服务启动的顺序是先K后S，而具体的每个运行级别的服务状态是放在/etc/rc.d/rc.d（=0~6）目录下，所有的文件均是指向/etc/init.d下相应文件的符号链接。rc.sysinit通过分析/etc/inittab文件来确定系统的启动级别，然后才去执行/etc/rc.d/rc*.d下的文件。3)、执行用户自定义引导程序/etc/rc.d/rc.local。其实当执行/etc/rc.d/rc3.d/S99local时，它就是在执行/etc/rc.d/rc.local。S99local是指向rc.local的符号链接。4)、完成了系统所有的启动任务后，linux会启动终端或X-Window来等待用户登录。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[DevOps是什么]]></title>
    <url>%2F2018%2F07%2F31%2FDevOps%E6%98%AF%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[DevOps（Development和Operations的组合词）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。它是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作。DevOps 是一种工程模式，本质上是一种分工，通过对开发、运维、测试，配管等角色职责的分工，实现工程效率最大化，进而满足业务的需求。DevOps的核心是角色的分工，而不是组织架构变化，垂直化的组织架构不代表可以实现DevOps所需要的分工模式，横向的组织架构也不代表传统的分工模式。DevOps的目标是工程效率最大化，它本身也只是一种方法论，是为了实现工程效率最大化的目标而存在的。DevOps与传统模式的区别传统分工模式下，PD将需求提出来，开发者根据需求写代码，然后告诉SCM，SCM拿着代码去打包，打包后告诉QA，QA测试完成后通知运维OPS上线，OPS进行上线部署，最后整个需求得到release。它的优势在于：分工与责任清晰，质量有保障，层层制约，容易把控。它的劣势也很明显：沟通成本与等待成本高，每一个环节都有成为瓶颈的风险，比如DEV知道怎样写代码，但QA也需要了解需求才能知道怎么做测试，OPS也需要了解需求维持线上稳定性，OPS负责交付，容易演变成擦屁股的角色，包括日常出现的bug。在DevOps分工模式下，一切都改变了，不再是每个人做完自己的事情然后交给下一个人。这个分工模式下，开发通过工具驱动所有流程运转向前走，比如开发写完代码通过工具驱动自动化打包，自动化测试，自动化部署或升级，还会配备监控；SCM、OPS和QA等在工具的外围，确保在工具中的每一个环节可以正常运转，它们支撑工具的目的是确保DEV可以使用工具完成人肉完成的事情，这是决策的变化，还要保证工具中的几个模块可以支撑最新的业务变化，当业务有了更新的变化时，须保证工具可以支撑开发。DevOps分工模式的好处很明显：可以减少沟通成本与等待风险，降低正常需求交付所需时间，DEV负责交付，避免交付扯皮。DevOps分工模式的劣势也很突出：每个环节参与角色较多，风险较高，对于业务形态比较多的企业较明显，工具支撑多种业务形态的成本是非常高的，当工具搞不定时，需要人肉补位保证业务发布，如果补位较多，那么DevOps分工就失败了；专业度会有降低，工具只能支持在精确输入的情况下以非常精确的方式完成一件固定的事情，一旦输入有变化而超出规则，该环节就比较麻烦了，工具的专业提升比人要慢的多；DEV权利过大，容易军阀化。DevOps的难点和需要解决的问题寻找平衡点DevOps是为了追求工程效率最大化而存在的，但是工程效率和稳定性的目标在大部分场景下都是相悖的，如何能够在工程效率提升的前提下，保证稳定性不出问题？传统分工模式是OPS团队负责，在DevOps分工模式中已经没有OPS团队了，只能开发团队负责，当一个团队同时负责两个相互有冲突的case时，该怎么办呢？如果分成两部分人分别负责业务KPI和稳定性KPI，就回到了传统的分工模式。责权划分对于开发者而言，主业是coding，其它包括打包、测试、发布都是辅业，它是工具的使用者，并不能完全将所有事情做得完美，在除coding以外的所有环节中，责任和分工要怎么来分，除了开发以外的事情要占用开发人员多少精力，才能保证DEV使用顺畅，跟上公司业务发展？其中核心是工具，工具是将二者粘合在一起的，工具起到了赋能和粘合的作用，工具还须可介入，需要人肉补位；另外，工具的进化要运维团队、测试团队和SCM团队来负责，工具自己要足够开放，才能让其它团队可以不断优化某一环节；工具也要保证可持续成长，跟上时代的发展。制约与考核打破原先的平衡以后，新的平衡如何建立？重新建立平衡是需要时间的，DEV在工程中话语权加大，权利是一定会被制约的，不是内部，就是外部市场。每一个问题都要根据公司的实际情况寻找一个平衡点，找到责权划分，怎样去考核和制约，只有将这三个点解完，才可能活下来将分工模式持续跑下去。DevOps怎么衡量？DevOps可以由四个角度做衡量：工程效率：从某一个开发的团队接到需求，到需求交付上线的时间有多长。工程效率能够提升多少代表DevOps发挥作用的大小；稳定性：当稳定性没有保证时，效率越高死的越快；非研发工作占比：当占比非常大时，离失败就不远了；业务规模与运维人员比例：谷歌的每一个SRE也要管理2000台机器的业务。总结实现自动化运维后，很多运维人员就会面临失业，但这是时代发展的必然结果，我们只需欣然接受；DevOps没有最佳实践，我们该更关注一些案例的环境和业务背景，DevOps本身不是目标，是一个方法，一个理论；DevOps和传统模式没有好坏之分，只有适不适合。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的nginx规则总结]]></title>
    <url>%2F2018%2F07%2F31%2F%E5%AE%9E%E7%94%A8%E7%9A%84Nginx%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[1. 概述大家都知道Nginx有很多功能模块，比如反向代理、缓存等，这篇文章总结下我们这些年实际环境中那些有用的Nginx规则和模块，大部分是用法的概括及介绍，具体细节在实际配置时再自行google。2. 内置语法先介绍Nginx默认已支持的内置功能，靠这些基本就满足大部分的web服务需求。2.1 proxy代理proxy常用于两类应用场景，一类是中转，如异地科学的上网方式，另外一类是到后端服务的负载均衡方案。用反向代理时候，需要特别注意里面的域名默认是在nginx启动时候就解析了，除非reload否则一直用的是当初解析的域名，也就是说不能动态解析。但这个问题是可以通过别的模块或者用内置字典变量方式来解决。12345678&gt; resolver 114.114.114.114;&gt; server &#123;&gt; location / &#123;&gt; set $servers github.com;&gt; proxy_pass http://$servers;&gt; &#125;&gt; &#125;&gt;2.1.1 中转针对某个域名进行中转：12345678910&gt; server &#123;&gt; listen 172.16.10.1:80;&gt; server_name pypi.python.org;&gt; location ~ /simple &#123;&gt; proxy_set_header Host $http_host;&gt; proxy_redirect off;&gt; proxy_pass http://pypi.python.org;&gt; &#125;&gt; &#125;&gt;注意如果是前后端域名不一样的话需要处理proxy_redirect的301跳转之类的显示，否则在跳转时候会跳转到proxy_pass的域名。另外可以直接代理所有80端口的http流量：12345678910&gt; server &#123;&gt; listen 80;&gt; server_name _;&gt; resolver 114.114.114.114;&gt; set $URL $host;&gt; location / &#123;&gt; proxy_pass http://$URL;&gt; &#125;&gt; &#125;&gt;如果是想代理https的站点也不是不可能，只是需要自行处理CA证书导入即可，而且经过https中转的流量对nginx是透明的，也就是有证书的时候做窃听和劫持的情况。2.1.2 负载均衡这是代理的另外一个常见用法，通过upstream到多个后端，可以通过weight来调节权重或者backup关键词来指定备份用的后端，通常默认就可以 了，或者可以指定类似ip_hash这样的方式来均衡，配置很简单，先在http区域添加upstream定义：123456&gt; upstream backend &#123;&gt; ip_hash;&gt; server backend1.example.com weight=5;&gt; server backend2.example.com weight=5;;&gt; &#125;&gt;然后在server里面添加proxy_pass：123456&gt; location / &#123;&gt; proxy_pass http://backend;&gt; proxy_http_version 1.1;&gt; proxy_set_header Connection &quot;&quot;;&gt; &#125;&gt;做负载均衡的时候可以智能识别后端服务器状态，虽然可以智能地proxy_next_upstream到另外的后端，但还是会定期损失一些正常的“尝试性”的连接，比如过了max_fails 次尝试之后，休息fail_timeout时间，过了这个时间之后又会去尝试，这个时候可以使用第三方的upstream_check模块来在后台定期地自动探索，类似这样：12&gt; check interval=3000 rise=2 fall=5 timeout=2000 type=http;&gt;这样替代用户正常的连接来进行尝试的方式进一步保障了高可用的特性。还有就是在做前端代理的时候也是这样的方式，直接proxy_pass到后端即可，比如CDN的场景。2.2 防盗链普通的防盗链是通过referer来做，比如：1234567&gt; location ~* \.(gif|jpg|png|bmp)$ &#123;&gt; valid_referers none blocked *.example.com server_names ~\.google\. ~\.baidu\.;&gt; if ($invalid_referer) &#123;&gt; return 403;&gt; &#125;&gt; &#125;&gt;再精细一点的就是URL加密，针对一些用户IP之类的变量生成一个加密URL通常是针对文件下载时候用到，可以通过openresty来写lua脚本或者是accesskey之类的模块来实现。2.3 变量nginx里面支持正则匹配和变量配置，默认的变量比如remote_addr、request_filename、query_string、server_name之类的，这些组合在一起可以做很多规则，或者还有日志里面status、http_cookie等。还有在进行多域名配置时候可以用通配符，比如：123&gt; server_name ~^(www\.)?(.+)$;&gt; root /data/web/$2;&gt;这样就实现了自动进行域名的目录指派。变量方面，比如配置变量a=1：12&gt; set $a 1;&gt;下面这个案例配合if判断来做有更大的用处。2.4 if判断nginx里面支持一些简单的if判断，但是没有多重逻辑的语法，多个判断条件用起来需要结合变量的方式来实现，比如允许ip地址为10.10.61段和和192.168.100段的用户访问，其余的拒绝，返回405状态码：1234567891011&gt; set $err 0;&gt; if ( $remote_addr ~ 10.10.61.)&#123;&gt; set $err 0;&gt; &#125;&gt; if ( $remote_addr ~ 192.168.100.)&#123;&gt; set $err 0;&gt; &#125;&gt; if ( $err = 1)&#123;&gt; return 405;&gt; &#125;&gt;这样通过一个err变量比较巧妙实现了需求。2.5 error_page有用到后端proxy的地方需要加上这句话才可以传到状态码到nginx：12&gt; fastcgi_intercept_errors on;&gt;具体配置一般是配置到具体的错误URL页面，比如：12345&gt; #返回具体状态码&gt; error_page 404 403 /4xx.html&gt; #返回200状态码&gt; error_page 404 403 =200 /error.html&gt;或者采用callback的方式统一做处理：123456&gt; error_page 404 403 = @fallback; &gt; location @fallback &#123;&gt; proxy_pass http://backend;&gt; access_log /data/logs/404_error.log access;&gt; &#125;&gt;这样在重定向时不会改变URL，然后把404页面直接返回。2.6 rewriterewrite做一些301、302之类的跳转，同时也可以在CDN前端做“去问号”缓存的效果。12345&gt; location /db.txt &#123;&gt; rewrite (.*) $1? break;&gt; include proxy.conf;&gt; &#125;&gt;另外最常见的跳转写法：12&gt; rewrite ^/game/(.*) /$1;&gt;把/game/test跳转为/test的效果，注意这样是没有状态码的，如果访问正常就直接返回200状态码。可以在后面加个permanent参数，就变为了301 Moved Permanently，或者添加redirect改为302跳转。同理，还可以进行多个正则匹配进行URL重组，比如：12&gt; rewrite ^/download/(.*)/lastest/(.*)$ /file/$1?ver=$2 break;&gt;2.7 日志字段想针对每个连接进行日志留档，可以在nginx日志那里配置好字段，比如记录cookie之类的数据。在log_format字段里面加入$http_cookie变量即可。另外post的数据可以永久保留在文件里面，比如用来做http的日志备份，包括get和post的原始数据，把这个值开启即可：12&gt; client_body_in_file_only on;&gt;然后post的数据就会保存在nginx/client_body_temp文件夹里面。2.8 internal关键词这个关键词很少见，但有时候是很有用的，比如在有很多规则时候，突然需要针对某个目录转为nginx内部处理。12345&gt; location ^~ /upload/down/ &#123;&gt; alias /data/web/dts/dtsfile/down/;&gt; internal;&gt; &#125;&gt;2.9 try_files字面意思是尝试，后面可以接多个目录或者文件，比如kohana框架：12&gt; try_files $uri /index.php?$query_string;&gt;先看是否有URL这个文件，没有的话再调用index.php来处理，或者支持状态码处理：12&gt; try_files /foo /bar/ =404;&gt;没有这两个文件的话返回404状态。2.10 auth认证可以做简单的用户登录认证方式，其中的passwd_file得通过apache的htpasswd命令来生成。123&gt; auth_basic &quot;Restricted&quot;;&gt; auth_basic_user_file passwd_file;&gt;认证通过之后每次访问会在头部添加Authorization字段包含用户名密码的base64加密密文给服务端。2.11 gzip普通的线上web站点gzip压缩是必须要开的，压缩一些文本类型的文件再返回给用户。注意必须手动指定全需要压缩的类型，比如css、js之类的，线上配置如下：1234567&gt; gzip on;&gt; gzip_min_length 2048;&gt; gzip_buffers 4 16k;&gt; gzip_vary on;&gt; gzip_http_version 1.1;&gt; gzip_types text/plain text/css text/xml application/xml application/javascript application/x-javascript ;&gt;2.12 mime配置很久以前基本是忽略这个配置，但手游流行之后就发现异常了，需要让手机浏览器知道返回的apk后缀是什么类型，否则类似IE浏览器会以zip后缀返回，需要加上：123&gt; application/vnd.android.package-archive apk;&gt; application/iphone pxl ipa;&gt;2.13 限速限速包括限制请求的并发数和请求的下载速度。简单的限制某个线程的下载速度就直接加上一句话就可以了：12&gt; limit_rate 1024k;&gt;要限制某个IP的并发数之类的就需要用ngx_http_limit_req_module和ngx_http_limit_conn_module模块了，不过是默认就编译好的。比如使用一个 10M 大小的状态缓存区，针对每个IP每秒只接受20次的请求：12&gt; limit_req_zone $binary_remote_addr zone=NAME:10m rate=20r/s;&gt;2.14 location匹配location匹配有多种方式，常见的比如1234&gt; location = / &gt; location / &gt; location ^~ /test&#123;&gt;是有优先级的，直接 ”=” 的优先级是最高的，一般就用”~”这个符号来匹配php就好了，不过是区分了大小写的：12&gt; location ~ .*\.php$&gt;2.15 文件缓存返回给用户的文件一般都配置了过期时间，让浏览器缓存起来。比如缓存14天：12&gt; expires 14d;&gt;针对某些特殊的文件就需要location匹配之后进行禁止缓存配置：1234&gt; add_header Cache-Control no-cache;&gt; add_header Cache-Control no-store;&gt; expires off;&gt;2.16 缓存文件nginx可以作为ATS这样的缓存服务器来缓存文件，配置也比较简单，不过我们很少用，除非一些特殊的场合，参考配置：123456789101112&gt; #先在全局下面定义好缓存存放的目录&gt; proxy_cache_path /data/cache/ levels=1:2 keys_zone=cache_one:10m inactive=7d max_size=10g;&gt; proxy_temp_path /data/cache/proxy_temp_path;&gt; proxy_cache_key $host$uri$is_args$args;&gt; #然后在server里面的location匹配好目的文件，加入下一段即可&gt; proxy_cache cache_one;&gt; proxy_cache_valid 200 304 24h;&gt; proxy_cache_valid any 10m;&gt; proxy_pass https://$host;&gt; proxy_cache_key $host$uri$is_args$args;&gt; add_header Nginx-Cache &quot;$upstream_cache_status&quot;; 3. 内置模块&gt;3. 内置模块nginx含有大量的模块可以支持多种复杂的需求，比如源码目录src/http/modules里面就有很多c模块的代码，或者直接通过./configure –help|grep module来查看有哪些内置模块，编译时候直接加上就可以了。除了nginx内置的模块，网络上还有很多第三方的模块，可以通过编译时候加参数–add-module=PATH指定模块源码来编译。下面介绍一些我们线上用过而且比较赞的内置模块。3.1 stream端口转发的模块，从nginx1.9版本才开始支持，包含tcp和udp的支持，和IPTABLES相比这个虽然是应用层，会监听端口，但是配置起来很方便，比IPTABLES灵活，在tcp模块下面添加类似vhost的server就可以了，方便自动化管理，参考配置：123456&gt; server &#123;&gt; listen PORT;&gt; proxy_pass IP:PORT;&gt; access_log /data/logs/tcp/PORT.log;&gt; &#125;&gt;3.2 http_realip_modulenginx反向代理之后，如何让后端web直接获取到的IP不是反向代理的iP，而是直接获取到用户的真实IP呢，就需要这个模块了，不需要代码那里再做类似X-Real-IP的变量特殊判断。3.3 http_slice_module在做CDN时候可以用到，让一个大文件分片，分成多个小文件通过206断点续传到后端，然后再组合起来，避免大文件直接回源导致多副本和多次回源的问题。3.4 http_secure_link_module前面说到的防盗链可以用这个来做，但是这个一般是针对那种文件下载时候用到的，比如从网页下载时候，服务端生成一个加密URL给用户，然后这个URL有过期时间之类的，避免此URL被多次分享出去，不过普通的素材加载还是用普通的防盗链即可。3.5 http_sub_module替换响应给用户的内容，相对于sed之后再返回，比如可以在需要临时全局修改网站背景或者title时候可以一次性处理好。4. 扩展项目简单介绍下大名鼎鼎的两个基于nginx的扩展项目，也是我们线上有很多地方用到的。4.1 openresty集成lua脚本，几乎可以完成任何普通web相关的需求。比如URL加密进行防劫持和防盗链，服务端动态生成一串aes加密的URL给CDN，CDN的openresty解密之后用普通的URL转发到后端，然后再返回给用户正确的内容。4.2 tengine淘宝的nginx修改版，实现了很多nginx的收费功能或者是特殊功能，比如动态加载、concat合并请求，动态解析等。我们python开发的后台基本都是用的这个版本，主要是利用了concat的合并素材的功能。5. 结语Nginx是个非常实用软件，部分功能已经超越了普通的web服务定位，同时它具备开源、轻量、自动化等特性，能有效解决实际工作中很多特殊场景的需求，祝Nginx在全球的份额持续攀升~原文地址：http://www.yunweipai.com/archives/24973.html]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[buffer 和 cache]]></title>
    <url>%2F2018%2F07%2F31%2Fbuffer_%E5%92%8C_cache%2F</url>
    <content type="text"><![CDATA[[linux 操作系统中buffer 和 cache 的作用]Buffer 和 cache （它们都是占用内存）。Buffer: 系统分配但未被使用的buffer 数量。buffer ：作为buffer cache的内存，是块设备的读写缓冲区cache（名词）：作为page cache的内存， 文件系统的cacheBuffer 缓冲区:是块设备的读写缓冲区，buffer 是I/O 缓存，用于内存和硬盘（或其他 I/O设备）之间的数据交换的速度而设计的。分析：1**、**通常在写一个非常大的文件，文件会被分成一个个的小 block块–&gt;一直往内存上写–&gt;然后再写入磁盘,, 这个文件非常的大，但是会被分成一个个小的block块，每次都一点一点的–&gt;写入内存–&gt;再写入磁盘, 这样的效率较慢 。2**、 这种情况下，内存就会攒足一次大的block块–&gt;再写入磁盘，这样的话就不会有第一种情况里的延迟。 这就是buffer.**Cache**高速缓存** ：cache是高速缓存，用于cpu与内存之间的缓冲。主要原因是cpu与memory,由于cpu快，memory跟不上，且有些值使用次数多，所以放入cache中，主要目的是，使用内存来缓存可能被再次访问的数据。 Cache 经常被使用在I/O 请求上。为提高系统性能。从硬盘上读内容时的情况：例如 要打开一个非常大的视频文件从硬盘–&gt;读到内存—&gt;显示出来。 第一次打开这个文件的时候需要等待一些时间（视电脑性能），然后第二次打开的时候会比第一次流畅许多。例如：小明第一次看这个10G的视频文件，从硬盘–&gt;内存–&gt;显示，他看完以后就关机了，内存也就清空空间了，但是他回头一想，电影中的某个情节想再回顾一下，这个时候，从硬盘–&gt;读到内存 ，这个时候的内存没有再次从硬盘读取，而是之前关机有缓存，读取的时间可能比之前流畅，这就是cache.是为了提高文件读取效率的做法。如果 cache 的值很大，说明cache住的文件数很多。如果频繁访问到的文件都能被cache住，那么磁盘的读IO 必会非常小。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库优化建议]]></title>
    <url>%2F2018%2F07%2F31%2F%E4%BC%98%E5%8C%96_MySQL_%E6%95%B0%E6%8D%AE%E5%BA%93%E6%80%A7%E8%83%BD%E7%9A%84%E5%BB%BA%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[应用程序、网站和数据库之间的交互会直接影响到应用服务水平的确立。这种交互的一个核心组成部分是：各种应用程序如何去查询数据库，以及数据库是如何响应各种请求的。MySQL 数据库性能的 7 点必备技巧：学习如何使用EXPLAIN创建正确的索引拒绝默认设置将数据库载入内存中使用SSD存储横向扩展追求可视性一、EXPLAIN 命令输出有两种不同的格式：老式的表格形式和较新的、能够提供更为细节化的、结构化的 JSON 文档。1mysql&gt; explain format=json select avg(k) from sbtest1 where id between 1000 and 2000 \G二、创建正确的索引索引是通过减少在数据库里查询时，必须扫描的数据量来提高查询的自身效率。在 MySQL 中，索引被用于加快对数据库的访问，并有助于遵循数据库的各种约束（例如 UNIQUE 和 FOREIGN KEY）。数据库索引就像书的索引一样，它们的位置信息被保存，并且包含有数据库的主要信息。它们是数据位置的一种参考方法或映射，因此索引并不会更改数据库中的任何数据。它们只是指向数据存放的位置而已。不过，索引并不总能匹配上任何的负载请求。在系统运行中，您应当不断为查询的上下文环境创建各种索引。虽然有着良好索引的数据库会运行更快速，但是如果出现单个索引的缺失，则会拖慢整个数据库的效率。因此，我们需要使用 EXPLAIN 来查找缺失的索引，并将其添加上去。需要注意的是：不要添加您所不需要的索引，因为不必要的索引会反过来拖慢数据库。三、拒绝默认设置就像其他任何软件那样，MySQL 也能通过各种可配置的设置，来修改其行为并最终优化其性能。同时这些配置的设置经常会被管理员所忽略，并一直保持着默认值的状态。为了让 MySQL 获得最佳的性能，了解如何配置 MySQL，以及将它们设置为最适合您的数据库环境的状态是非常重要的。在默认情况下，MySQL 是针对小规模的发布、安装进行调优的，而并非真正的生产环境规模。因此，通常您需要将 MySQL 配置为使用所有可用的内存资源，并且能允许您的应用程序所需的最大连接数。这里有三个有关 MySQL 性能优化的设置，值得您去仔细地配置：innodb_buffer_pool_size数据和索引被用作缓存的缓冲池。当您的数据库服务器有着大量的系统内存时，可以用到该设置。如果您只运行 InnoDB 存储引擎，那么您通常可以分配 80％ 左右的内存给该缓冲池。而如果您要运行非常复杂的查询或者您有大量的并发数据库连接，亦或您有非常大的数据表的情况，那么就可能需要将此值下调一个等级，以便为其他的调用分配更多的内存。您在设置 InnoDB 缓冲池大小的时候，要确保其设置既不要过大，也不要频繁引起交换（swapping），因为这些绝对会降低您的数据库性能。有一个简单的检查方法就是在“Percona 监控和管理”。如果您一开始并没有将 innodb_buffer_pool_size 的值设置正确，也不必担心。从 MySQL 5.7 开始，您可以动态地改变 InnoDB 缓冲池的大小，而不需要重新启动数据库服务器了。innodb_log_file_size这是指单个 InnoDB 日志文件的大小。默认情况下，InnoDB 使用两个值，这样您就可以通过将其增加一倍，来让 InnoDB 获得循环的重做日志空间，以确保交易的持久性。这同时也优化了对数据库的写入性能。设置 innodb_log_file_size 的值是很值得推敲的：如果分配了较大的重做空间，那么对于写入密集型的工作负载来说性能会越好。但是如果您的系统遭受到断电或其他问题导致崩溃的时候，那么其恢复时间则会越长。您可能会问：怎么才能知道自己的 MySQL 性能是否受限于当前的 InnoDB 日志文件大小呢？您可以通过查看未实际使用的重做日志空间大小来判定。最简单的方法就是查看“Percona 监控和管理”的 InnoDB 指标仪表板。因此，您的日志文件应该至少比使用量大 20％，从而保持系统处于最佳的性能状态。max_connections大型应用程序通常需要比默认数量多得多的连接。不同于其他的变量，如果您没能将该值设置正确，您就会碰到性能方面的问题。也就是说，如果连接的数量不足以满足您的应用需求，那么应用程序将根本无法连接到数据库，在用户看来就像宕机了一样。由此可见，将它设置正确是非常重要的。对于在多台服务器上运行着具有多个组件的复杂应用来说，您想获知到底需要多少个连接是非常困难的。幸运的是，MySQL 能够在峰值操作时轻易地获悉所用到的连接数量。通常，您需要确保在应用程序所使用到的最大连接数和可用的最大连接数之间至少有 30％ 的差额。查看这些数字的一个简单方法是：在“Percona 监控和管理”的系统概述界面中查看使用 MySQL 连接图。还有一点需要记住：如果您的应用程序所创建的连接数量过多，通常会导致数据库运行缓慢。在这种情况下，您应该在数据库性能上做文章，而不是简单地允许建立更多的连接。更多的连接会使得潜在的性能问题更加恶化。四、将数据库载入内存中年来，出现了固态硬盘（SSD）方向上的转变。尽管固态硬盘比传统机械旋臂硬盘快得多，但是它们仍然敌不过将数据存在内存里。这种差别不仅来自于存储性能本身，还来自于数据库从磁盘或 SSD 里存取数据时所产生的额外工作。随着近年来硬件技术的改进，不管您是运行在云端，还是管理着自己的硬件，将数据库载入内存已经变得可行五、使用 SSD 存储无论您的数据库是否已被载入内存，您都需要使用快速存储来处理写入操作，并且避免在数据库启动后（重启之后）出现性能问题。这里的快速存储就是指固态硬盘。一些所谓的“专家”仍在基于成本和可靠性的基础上，主张使用机械旋臂硬盘。坦率地说，当涉及到数据库操作时，这些建议往往是过时的或是完全错误的。现如今，固态硬盘的性能已经非常卓越、可靠且价格低廉了。并非所有的固态硬盘都是同等生产的。对于数据库服务器来说，您应该选用那些专供服务器工作负载、且能精心呵护数据的 SSD。例如：防止断电损坏的，而避免使用那些专为台式和笔记本电脑设计的商用固态硬盘。通过 NVMe 或英特尔 Optane 技术来直接连接的 SSD 往往能够提供最佳的性能。即使远程连接到 SAN、NAS 或云端的块设备上，固态硬盘也能比机械旋臂硬盘提供更为优越的性能。六、横向扩展即使是性能最高的服务器也有局限性。业界一般用两种方法来进行扩展：纵向和横向。纵向扩展意味着购买更多的硬件。这样做不但成本昂贵，而且硬件折旧速度快。而横向扩展，则在处理负载方面有如下几点优势：您可以从更小型、成本更低的系统中获益。横向扩展使得系统的线性扩展更方便、更快捷。由于数据库会横跨增长到多个物理机上，横向扩展在保护数据库的同时，消除了硬件单点故障。尽管横向扩展有着诸多优势，不过它还是具有一定的局限性。横向扩展需要数据复制，例如基本的 MySQL Replication 或是用于数据同步的 Percona XtraDB 群集。但是作为回报，您也会获得更高的性能和可用性。如果您需要更高级的扩展性，那么请考虑使用 MySQL 分片（sharding）。另外，您还需要确保连接到群集架构的应用程序可以找到它们所需的数据。这通常是通过诸如 ProxySQL 或 HAProxy 的一些代理服务器和负载平衡器来实现的。当然，过早地规划横向扩展，会增加分布式数据库的复杂性。最近发布的 MySQL 8 候选版本已声称自己能够在单一的系统上处理超过 200 万个简单查询。七、追求可视性可视性是系统设计的最佳境界，MySQL 也不例外。一旦完成了 MySQL 环境的搭建、运行并调优，您千万不要认为已经万事大吉了。数据库环境既会受到来自系统更改或流量负荷的影响，也会遇到例如流量高峰、应用程序错误以及 MySQL 自身的各种问题。为了快速、有效地解决各种问题，您需要建立和实施一些监控机制，从而能获悉数据库环境的状态，并在出现错误时及时分析服务器上的数据。因此理想情况就是在系统出现问题或是被用户所察觉之前就做到防范于未然。常用的监测工具有：MySQL企业监控器（Enterprise Monitor）。Monyog。具有免费与开源版本的 Percona 监控和管理（PMM）。这些工具在监控和故障排除方面提供了很好的操作可视性。随着越来越多的公司在大规模生产环境中使用开源的数据库（特别是MySQL）来管理和服务他们的业务数据，他们需要把工作重心放在保持数据库的调优和运行效率上。MySQL 的确是一款能够提升您的应用程序和网站性能的优秀数据库，当然您需要通过对它进行调整，以满足业务需求，监测、发现并防止任何瓶颈和性能方面的问题。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql日志查询]]></title>
    <url>%2F2018%2F07%2F31%2Fmysql%E6%97%A5%E5%BF%97%E6%9F%A5%E8%AF%A2%E9%9B%86%2F</url>
    <content type="text"><![CDATA[mysql日志查询binlog介绍binlog,即二进制日志,它记录了数据库上的所有改变.改变数据库的SQL语句执行结束时,将在binlog的末尾写入一条记录,同时通知语句解析器,语句执行完毕.binlog格式登录到mysql查看binlog只查看第一个binlog文件的内容 show binlog events;查看指定binlog文件的内容 show binlog events in ‘mysql-bin.000002’;查看当前正在写入的binlog文件 show master status\G获取binlog文件列表 show binary logs;用mysqlbinlog工具查看本地查看123456&gt; 基于开始/结束时间 mysqlbinlog --start-datetime='2013-09-10 00:00:00' --stop-datetime='2013-09-10 01:01:01' -d 库名 二进制文件&gt; 基于pos值mysqlbinlog --start-postion=107 --stop-position=1000 -d 库名 二进制文件&gt; 转换为可读文本mysqlbinlog –base64-output=DECODE-ROWS -v -d 库名 二进制文件远程查看123&gt; 指定开始/结束时间,并把结果重定向到本地t.binlog文件中.mysqlbinlog -u username -p password -hl-db1.dba.beta.cn6.qunar.com -P3306 \--read-from-remote-server --start-datetime='2013-09-10 23:00:00' --stop-datetime='2013-09-10 23:30:00' mysql-bin.000001 &gt; t.binlog]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql多表查询]]></title>
    <url>%2F2018%2F07%2F31%2FMySQL%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[一使用SELECT子句进行多表查询SELECT 字段名 FROM 表1，表2 … WHERE 表1.字段 = 表2.字段 AND 其它查询条件SELECT a.id,a.name,a.address,a.date,b.math,b.english,b.chinese FROM tb_demo065_tel AS b,tb_demo065 AS a WHERE a.id=b.id注:在上面的的代码中，以两张表的id字段信息相同作为条件建立两表关联，但在实际开发中不应该这样使用，最好用主外键约束来实现二使用表的别名进行多表查询如:SELECT a.id,a.name,a.address,b.math,b.english,b.chinese FROM tb_demo065 a,tb_demo065_tel b WHERE a.id=b.id AND b.id=’$_POST[textid]’SQL语言中，可以通过两种方式为表指定别名第一种是通过关键字AS指定,如SELECT a.id,a.name,a.address,b.math,b.english,b.chinese FROM tb_demo065 AS a,tb_demo065_tel AS b WHERE a.id=b.id第二种是在表名后直接加表的别名实现SELECT a.id,a.name,a.address,b.math,b.english,b.chinese FROM tb_demo065 a,tb_demo065_tel b WHERE a.id=b.id使用表的别名应注意几下几点(1)别名通常是一个缩短了的表名，用于在连接中引用表中的特定列，如果连接中的多个表中有相同的名称列存在，必须用表名或表的别名限定列名(2)如果定义了表的别名就不能再使用表名三合并多个结果集SQL语言中，可以通过UNION 或 ALL将多个SELECT语句的查询结果合并输出，这两个关键字的使用说明如下：UNION:利用该关键字可以将多个SELECT 语句的查询结果合并输出，并删除重复行ALL:利用该关键字可以将多个SELECT 语句的查询结果合并输出，但不会删除重复行在使用UNION或ALL关键字将多个表合并输出时，查询结果必须具有相同的结构并且数据类型必须兼容,另外使用UNION时两张表的字段数量也必须相同，否则会提示SQL语句有错误。e.x:SELECT id,name,pwd FROM tb_demo067 UNION SELECT uid,price,date FROM tb_demo067_tel四简单嵌套查询子查询:子查询是一个SELECT查询，返回单个值且嵌套在SELECT、INSERT、UPDATE和DELETE语句或其它查询语句中，任何可以使用表达式的地方都可以使用子查询.SELECT id,name,sex,date FROM tb_demo068 WHERE id in(SELECT id FROM tb_demo068 WHERE id=’$_POST[test]’)内连接：把查询结果作为WHERE子句的查询条件即称为内连接五复杂的嵌套查询多表之间的嵌套查询可以通过谓词IN实现，语法格式如下:test_expression[NOT] IN{subquery}参数说明：test_expression指SQL表达式，subquery包含某结果集的子查询多表嵌套查询的原理:无论是多少张表进行嵌套，表与表之间一定存在某种关联，通过WHERE子句建立此种关联实现查询六嵌套查询在查询统计中的应用实现多表查询时，可以同时使用谓词ANY、SOME、ALL,这些谓词被称为定量比较谓词，可以和比较运算符联合使用，判断是否全部返回值都满足搜索条件.SOME和ANY谓词是存在量的，只注重是否有返回值满足搜索条件，这两个谓词的含义相同，可以替换使用;ALL谓词称为通用谓词，它只关心是否有谓词满足搜索要求.SELECT * FROM tb_demo069_people WHERE uid IN(SELECT deptID FROM tb_demo069_dept WHERE deptName=’$_POST[select]’)SELECT a.id,a.name FROM tb_demo067 AS a WHERE id&lt;3)ANY 大于子查询中的某个值=ANY 大于等于子查询中的某个值&lt;=ANY 小于等于子查询中的某个值=ANY 等于子查询中的某个值!=ANY或&lt;&gt;ANY 不等于子查询中的某个值ALL 大于子查询中的所有值=ALL 大于等于子查询中的所有值&lt;=ALL 小于等于子查询中的所有值=ALL 等于子查询中的所有值!=ALL或&lt;&gt;ALL 不等于子查询中的所有值七.使用子查询作派生的表在实际项目开发过程中经常用到从一个信息较为完善的表中派生出一个只含有几个关键字段的信息表，通过子查询就可以来实现这一目标,如SELECT people.name,people.chinese,people.math,people.english FROM (SELECT name,chinese,math,english FROM tb_demo071) AS people注:子查询应遵循以下规则:(1)由比较运算符引入的内层子查询只包含一个表达式或列名，在外层语句中的WHERE子句内命名的列必须与内层子查询命名的列兼容(2)由不可更改的比较运算符引入的子查询(比较运算符后面不跟关键字ANY或ALL)不包括GROUP BY 或 HAVING子句，除非预先确定了成组或单个的值(3)用EXISTS引入的SELECT列表一般都由*组成，不必指定列名(4)子查询不能在内部处理其结果八使用子查询作表达式SELECT (SELECT AVG(chinese)FROM tb_demo071),(SELECT AVG(english)FROM tb_demo071),(SELECT AVG(math)FROM tb_demo071) FROM tb_demo071注：在使用子查询时最好为列表项取个别名，这样可以方便用户在使用mysql_fetch_array()函数时为表项赋值,如SELECT (SELECT AVG(chinese) FROM tb_demo071) AS yuwen ,(SELECT AVG(english) FROM tb_demo071) AS yingyu,(SELECT AVG(math) FROM tb_demo071) AS shuxue FROM tb_demo071九使用子查询关联数据SELECT * FROM tb_demo072_student WHERE id=(SELECT id FROM tb_demo072_class WHERE className = ‘$_POST[text]’)十多表联合查询利用SQL语句中的UNION，可以将不同表中符合条件的数据信息显示在同一列中。e.x:SELECT FROM tb_demo074_student UNION SELECT FROM tb_demo074_fasten注:使用UNION时应注意以下两点：(1)在使用UNION运算符组合的语句中，所有选择列表的表达式数目必须相同，如列名、算术表达式及聚合函数等(2)在每个查询表中，对应列的数据结构必须一样。十一对联合后的结果进行排序为了UNION的运算兼容，要求所有SELECT语句都不能有ORDER BY语句，但有一种情况例外，那就是在最后一个SELECT语句中放置ORDER BY 子句实现结果的最终排序输出。e.x:SELECT FROM tb_demo074_student UNION SELECT FROM tb_demo074_fasten ORDER BY id使用UNION条件上相对比较苛刻，所以使用此语句时一定要注意两个表项数目和字段类型是否相同十二条件联合语句SELECT FROM tb_demo076_BEIJING GROUP BY name HAVING name=’人民邮电出版社’ OR name=’机械工业出版社’ UNION SELECT FROM tb_demo076_BEIJING GROUP BY name HAVING name &lt;&gt;’人民邮电出版社’ AND name &lt;&gt;’机械工业再版社’ ORDER BY id上面语句应用了GROUP BY分组语句和HAVING语句实现条件联合查询。其实现目的是先保证将’人民邮电出版社’和’机械工业出版社’始终位于名单最前列，然后再输出其它的出版社十三简单内连接查询SELECT filedlist FROM table1 [INNER] JOIN table2 ON table1.column1 = table2.column1其中，filedlist是要显示的字段,INNER表示表之间的连接方式为内连接，table1.column1=table2.column1用于指明两表间的连接条件，如:SELECT a.name,a.address,a.date,b.chinese,b.math,b.english FROM tb_demo065 AS a INNER JOIN tb_demo065_tel AS b on a.id=b.id十四复杂内连接查询复杂的内连接查询是在基本的内连接查询的基础上再附加一些查询条件，如:SELECT a.name,a.address,a.date,b.chinese,b.math,b.english FROM tb_demo065 AS a INNER JOIN tb_demo065_tel AS b on a.id=b.id WHERE b.id=(SELECT id FROM tb_demo065 WHERE tb_demo065.name=’$_POST[text]’)总之，实现表与表之间的关联的本质是两表之间存在共同的数据项或者相同的数据项，通过WHERE 子句或内连接INNER JOIN … ON 语句将两表连接起来，实现查询十五使用外连接实现多表联合查询(1)LEFT OUTER JOIN表示表之间通过左连接方式相互连接，也可简写成LEFT JOIN,它是以左侧的表为基准故称左连接，左侧表中所有信息将被全部输出，而右侧表信息则只会输出符合条件的信息，对不符合条件的信息则返回NULLe.x:SELECT a.name,a.address,b.math,b.english FROM tb_demo065 AS A LEFT OUTER JOIN tb_demo065_tel AS b ON a.id=b.id(2)RIGHT OUTER JOIN表示表之间通过右连接方式相互连接，也可简写成RIGHT JOIN,它是以右侧的表为基准故称右连接，右侧表中所有信息将被全部输出，而左侧表信息则只会输出符合条件的信息，对不符合条件的信息则返回NULLE.X:SELECT a.name,a.address,b.math,b.english FROM tb_demo065 AS A RIGHT OUTER JOIN tb_demo065_tel AS b ON a.id=b.id十六利用IN或NOTIN关键字限定范围e.x:SELECT * FROM tb_demo083 WHERE code IN(SELECT code FROM tb_demo083 WHERE code BETWEEN ‘$_POST[text1]’ AND ‘$_POST[text2]’)利用IN可指定在范围内查询，若要求在某范围外查询可以用NOT IN代替它十七由IN引入的关联子查询e.x:SELECT * FROM tb_demo083 WHERE code IN(SELECT code FROM tb_demo083 WHERE code = ‘$_POST[text]’)十八利用HAVING语句过滤分组数据HAVING子句用于指定组或聚合的搜索条件，HAVING通常与GROUP BY 语句一起使用，如果SQL语句中不含GROUP BY子句，则HAVING的行为与WHERE子句一样.e.x:SELECT name,math FROM tb_demo083 GROUP BY id HAVING math &gt; ‘95’]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql常用备份操作]]></title>
    <url>%2F2018%2F07%2F31%2Fmysql%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[mysql压缩备份123451、mysqldump 备份并压缩sql文件mysql&gt;mysqldump -h主机ip -u用户名 -p密码（也可不输入） 数据库名 | gzip &gt; 压缩后文件位置2、mysql直接用压缩文件恢复mysql&gt;gunzip &lt; backupfile.sql.gz | mysql -u用户名 -p密码（也可不输入） 数据库名一、备份常用操作基本命令1、备份命令mysqldump格式格式：mysqldump -h主机名 -P端口 -u用户名 -p密码 –database 数据库名 &gt; 文件名.sql2、备份MySQL数据库为带删除表的格式备份MySQL数据库为带删除表的格式，能够让该备份覆盖已有数据库而不需要手动删除原有数据库。mysqldump –add-drop-table -uusername -ppassword -database databasename &gt; backupfile.sql3、直接将MySQL数据库压缩备份mysqldump -hhostname -uusername -ppassword -database databasename | gzip &gt; backupfile.sql.gz4、备份MySQL数据库某个(些)表mysqldump -hhostname -uusername -ppassword databasename specific_table1 specific_table2 &gt; backupfile.sql5、同时备份多个MySQL数据库mysqldump -hhostname -uusername -ppassword –databases databasename1 databasename2 databasename3 &gt; multibackupfile.sql仅仅备6、仅备份份数据库结构mysqldump –no-data –databases databasename1 databasename2 databasename3 &gt; structurebackupfile.sql7、备份服务器上所有数据库mysqldump –all-databases &gt; allbackupfile.sqlmysqldump -h 192.168.27.40 –flush-logs –all-databases -p -udba &gt; /mysql_backup/backup_40.sql忽略某个表，mysqldump不提供忽略某个库的参数mysqldump -h 192.168.27.72 –ignore-table=huisou.tbl_product_sale_summary –flush-logs –all-databases -pjsrh1sdshj -udba &gt; //mysql_backup/dbbackup/mysqlback/hs.sql8、还原MySQL数据库的命令mysql -hhostname -uusername -ppassword databasename &lt; backupfile.sql9、还原压缩的MySQL数据库gunzip &lt; backupfile.sql.gz | mysql -uusername -ppassword databasename10、将数据库转移到新服务器mysqldump -uusername -ppassword databasename | mysql –host=... -C databasename11、–master-data 和–single-transaction在mysqldump中使用–master-data=2，会记录binlog文件和position的信息 。–single-transaction会将隔离级别设置成repeatable-commited12、导入数据库常用source命令，用use进入到某个数据库，mysql&gt;source d:\test.sql，后面的参数为脚本文件。13、查看binlog日志查看binlog日志可用用命令 mysqlbinlog binlog日志名称|more14、general_logGeneral_log记录数据库的任何操作，查看general_log 的状态和位置可以用命令show variables like “general_log%” ,开启general_log可以用命令set global general_log=on二、增量备份小量的数据库可以每天进行完整备份，因为这也用不了多少时间，但当数据库很大时，就不太可能每天进行一次完整备份了，这时候就可以使用增量备份。增量备份的原理就是使用了mysql的binlog志。1、首先做一次完整备份：mysqldump -h10.6.208.183 -utest2 -p123 -P3310 –single-transaction –master-data=2 test&gt;test.sql这时候就会得到一个全备文件test.sql在sql文件中我们会看到：– CHANGE MASTER TO MASTER_LOG_FILE=’bin-log.000002’, MASTER_LOG_POS=107;是指备份后所有的更改将会保存到bin-log.000002二进制文件中。2、在test库的t_student表中增加两条记录，然后执行flush logs命令。这时将会产生一个新的二进制日志文件bin-log.000003，bin-log.000002则保存了全备过后的所有更改，既增加记录的操作也保存在了bin-log.00002中。3、再在test库中的a表中增加两条记录，然后误删除t_student表和a表。a中增加记录的操作和删除表a和t_student的操作都记录在bin-log.000003中。三、恢复1、首先导入全备数据mysql -h10.6.208.183 -utest2 -p123 -P3310 &lt; test.sql，也可以直接在mysql命令行下面用source导入2、恢复bin-log.000002mysqlbinlog bin-log.000002 |mysql -h10.6.208.183 -utest2 -p123 -P33103、恢复部分 bin-log.000003在general_log中找到误删除的时间点，然后更加对应的时间点到bin-log.000003中找到相应的position点，需要恢复到误删除的前面一个position点。可以用如下参数来控制binlog的区间–start-position 开始点 –stop-position 结束点–start-date 开始时间 –stop-date 结束时间找到恢复点后，既可以开始恢复。mysqlbinlog mysql-bin.000003 –stop-position=208 |mysql -h10.6.208.183 -utest2 -p123 -P3310]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git和svn区别]]></title>
    <url>%2F2018%2F07%2F31%2FSVN%E5%92%8Cgit%E5%B7%AE%E5%88%AB%2F</url>
    <content type="text"><![CDATA[区别：最核心的区别Git是分布式的，而Svn不是分布的。Git把内容按元数据方式存储，而SVN是按文件Git没有一个全局版本号，而SVN有：目前为止这是跟SVN相比Git缺少的最大的一个特征。Git的内容的完整性要优于SVN: GIT的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。克隆一份全新的大目录，git要比SVN快的多。版本库（repository):SVN只能有一个指定中央版本库。当这个中央版本库有问题时，所有工作成员都一起瘫痪直到版本库维修完毕或者新的版本库设立完成。而 Git可以有无限个版本库。或者，更正确的说法，每一个Git都是一个版本库，区别是它们是否拥有活跃目录（Git Working Tree）。如果主要版本库（例如：置於GitHub的版本库）发生了什麼事，工作成员仍然可以在自己的本地版本库（local repository）提交，等待主要版本库恢复即可。工作成员也可以提交到其他的版本库！分支（Branch）在SVN，分支是一个完整的目录。且这个目录拥有完整的实际文件。如果工作成员想要开啟新的分支， 还得让其他人重新切分支重新下载 。而 Git，每个工作成员可以任意在自己的本地版本库开啟无限个分支 ，开一个分支，做喜欢的事。完全不需担心妨碍其他工作成员。只要我不合并及提交到主要版本库，没有一个工作成员会被影响。SVN 的主要功能SVN属于集中化的版本控制系统，有个不太精确的比喻:SVN = 版本控制+ 备份服务器SVN使用起来有点像是档案仓库的感觉，支持并行读写文件，支持代码的版本化管理，功能包括取出、导入、更新、分支、改名、还原、合并等。SVN大都采用图形界面操作，直观，上手快。SVN对中文支持好，操作简单，使用没有难度，美工人员，产品人员，测试人员，实施人员都可轻松上手。使用界面统一，功能完善，操作方便。Git的主要功能Git是一个分布式版本控制系统，操作命令包括：clone，pull，push,branch ,merge ,push,rebase，Git擅长的是程序代码的版本化管理。对程序源代码进行差异化的版本管理，代码库占极少的空间。易于代码的分支化管理。不支持中文，图形界面支持差，使用难度大。不易推广。SVN更适用于项目管理， Git仅适用于代码管理。最后总结一下：SVN的特点是简单，只是需要一个放代码的地方时用是OK的。Git的特点版本控制可以不依赖网络做任何事情，对分支和合并有更好的支持(当然这是开发者最关心的地方)，不过想各位能更好使用它，需要花点时间尝试下。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用函数]]></title>
    <url>%2F2018%2F07%2F26%2F%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[map函数12345678910111213141516171819202122232425262728293031323334格式：map(func, seq1[, seq2,…]) 第一个参数接受一个函数名，后面的参数接受一个或多个可迭代的序列，返回的是一个集合。Python函数编程中的map()函数是将func作用于seq中的每一个元素，并将所有的调用的结果作为一个list返回。如果func为None，作用同zip()。#使用lambda&gt;&gt;&gt; print map(lambda x: x % 2, range(7))[0, 1, 0, 1, 0, 1, 0]一个seq时，可以使用filter()函数代替当seq多于一个时，map可以并行（注意是并行）地对每个seq执行每个seq的同一位置的元素同时传入一个多元的func函数之后，得到一个返回值，并将这个返回值存放在一个列表中&gt;&gt;&gt; print map(lambda x , y : x ** y, [2,4,6],[3,2,1])[8, 16, 6] #执行过程[2**3,4**2,6**1]&gt;&gt;&gt; print map(lambda x , y : (x ** y, x + y), [2,4,6],[3,2,1])[(8, 5), (16, 6), (6, 7)]&gt;&gt;&gt; print map(None, [2,4,6],[3,2,1]) #func为NONE时，就同zip一样了[(2, 3), (4, 2), (6, 1)]其他用法例子：***将元组转换成list***&gt;&gt;&gt; map(int, (1,2,3))[1, 2, 3]***将字符串转换成list***&gt;&gt;&gt; map(int, '1234')[1, 2, 3, 4]***提取字典的key，并将结果存放在一个list中***&gt;&gt;&gt; map(int, &#123;1:2,2:3,3:4&#125;)[1, 2, 3]***字符串转换成元组，并将结果以列表的形式返回***&gt;&gt;&gt; map(tuple, 'agdf')[('a',), ('g',), ('d',), ('f',)]#将小写转成大写def u_to_l (s): return s.upper()print map(u_to_l,'asdfd')zip函数12345678910111213141516171819202122232425262728293031323334353637383940zip函数返回一个以元组为元素的列表，其中第 i 个元组包含每个参数序列的第 i 个元素。返回的列表长度被截断为最短的参数序列的长度。只有一个序列参数时，它返回一个1元组的列表。没有参数时，它返回一个空的列表。概括起来一句话：zip函数返回的是一个列表，但是列表里面的元素是由一个个元组构成的..做机器学习分类的时候，就可以利用zip函数，将我们的数据点与我们的数据点对应的标签进行关联..#例一：x = [1, 2, 3]y = [4, 5, 6]z = [7, 8, 9]xyz = zip(x, y, z)print xyz[(1, 4, 7), (2, 5, 8), (3, 6, 9)]#例二：x = [1, 2, 3]x = zip(x)print x[(1,), (2,), (3,)]#例三：x = zip()print x[]#例四：x = [1, 2, 3]y = [4, 5, 6]z = [7, 8, 9]xyz = zip(x, y, z)u = zip(*xyz)print u[(1, 2, 3), (4, 5, 6), (7, 8, 9)]一般认为这是一个unzip的过程，它的运行机制是这样的：在运行zip(*xyz)之前，xyz的值是：[(1, 4, 7), (2, 5, 8), (3, 6, 9)]那么，zip(*xyz) 等价于 zip((1, 4, 7), (2, 5, 8), (3, 6, 9))所以，运行结果是：[(1, 2, 3), (4, 5, 6), (7, 8, 9)]#例五：x = [1, 2, 3]r = zip(* [x] * 3)print r[(1, 1, 1), (2, 2, 2), (3, 3, 3)]它的运行机制是这样的：[x]生成一个列表的列表，它只有一个元素x[x] * 3生成一个列表的列表，它有3个元素，[x, x, x]zip(* [x] * 3)的意思就明确了，zip(x, x, x)random1234567891011import randomresult1=random.random() #随机生成一个浮点数[0,1)result2=random.randint(1, 10) #产生1-10的一个随机整数,包含1和10result3=random.uniform(1.1, 2.1) #产生1.1-2.2之间的随机浮点数result4=random.choice("python") #参数是一个可以迭代的类型，从参数中随机选一个元素result5=random.randrange(1,50,2) #随机产生1-50，间隔为2随机整数，左闭右开，不包含50test_list=[1,2,3,4,5]random.shuffle(test_list) #需要注意的是这个操作是在原来参数的基础上操作的，不会返回新的数据print("test_list:"+str(test_list))test_list:[3, 4, 1, 5, 2] #shuffle就是将原有列表的顺序打乱，也就是重新洗牌的功能random.sample(seq,n) #可以从指定的序列中，随机的截取指定长度的片断，不作原地修改。os模块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#当前使用平台：os.name #返回当前使用平台的代表字符，Windows用'nt'表示，Linux用'posix'表示#当前路径和文件os.getcwd() #返回当前工作目录os.listdir(path) #返回path目录下所有文件列表#abspath() 将相对路径转化为绝对路径path = './boys'#相对result = os.path.abspath(path)print(result)#系统操作：os.system() #运行shell命令&gt;&gt;&gt;os.system('cmd') #Windows下打开终端&gt;&gt;&gt;os.system('ls') #Linux下查看当前目录所有文件#查看文件名或目录：os.path.split(path) #将path的目录和文件名分开为元组，split() 将一个完整的路径切割成目录部分和主体部分os.path.join(path1,path2,...) #将path1，怕path2，...进行组合，若path2为绝对路径，则会将path1删除os.path.dirname(path) #返回path中的目录（文件夹部分），结果不包含'\'os.path.basename(path) #返回path中的文件名#dirname() 获取完整路径当中的目录部分 &amp; basename()获取完整路径当中的主体部分#创建目录：os.mkdir(path) #创建path目录（只能创建一级目录，如'F:\XXX\WWW'）,在XXX目录下创建WWW目录os.makedirs(path) #创建多级目录（如'F:\XXX\SSS'），在F盘下创建XXX目录，继续在XXX目录下创建SSS目录#删除文件或目录：os.remove(path) #删除文件（必须是文件）os.rmdir(path) #删除path目录(只能删除一级目录，如'F:\XXX\SSS'),只删除SSS目录，只能删除空目录os.removedirs(path) #删除多级目录（如'F:\XXX\SSS'）,必须为空目录，删除SSS、FFF目录#更改路径：os.chdir(path) #将当前工作目录更改为指定路径path#查看文件时间：os.path.getmtime(path) #返回文件或目录的最后修改时间，结果为秒数os.path.getatime(path) #返回文件或目录的最后访问时间，结果为秒数os.path.getctime(path) #返回文件或目录得创建时间，结果为秒数#查看文件大小：os.path.getsize(path) #返回文件的大小，若是目录则返回0#查看文件：os.path.exists(path) #判断path是否存在，存在返回True,不存在返回Falseos.path.isfile(path) #判断path是否为文件，是返回True,不是返回Falseos.path.isdir(path) #判断path是否目录，是返回True，不是返回Falseos.path.islink(path) #islink() 检测是否是链接os.path.isabs(path) #isabs() 检测一个路径是否是绝对路径os.path.samefile(path1,path2) #samefile() 检测2个路径是否是同一个文件#获取文件和目录：os.walk(path) #递归返回path下的目录（包括path目录）、子目录、文件名的三元组#获得shell命令返回值：fp=os.popen(cmd) #打开命令cmd或从命令cmd打开管道，返回值是连接到管道的文件对象rlt=fp.read()或 rlt=fp.readlines() #读取结果os.system('dir') #获取系统命令的返回结果，但无法保存到一个变量里#rename() 文件或文件夹重命名os.rename('/home/sy/a','/home/sy/alibaba'）os.rename('02.txt','002.txt')#stat() 获取文件或者文件夹的信息result = os.stat('/home/sy/PycharmProject/Python3/10.27/01.py) #getenv() 获取系统的环境变量result = os.getenv('PATH')print(result.split(':')) #putenv() 将一个目录添加到环境变量中(临时增加仅对当前脚本有效)os.putenv('PATH','/home/sy/下载')os.system('syls')#常用变量&gt;&gt;&gt; os.curdir #curdir 表示当前文件夹 .表示当前文件夹 一般情况下可以省略'.'&gt;&gt;&gt; os.pardir #pardir 表示上一层文件夹 ..表示上一层文件夹 不可省略!'..'&gt;&gt;&gt; os.name #name 获取代表操作系统的名称字符串'nt'&gt;&gt;&gt; os.sep #sep 获取系统路径间隔符号 window -&gt;\ linux -&gt;/'\\'&gt;&gt;&gt; os.extsep #extsep 获取文件名称和后缀之间的间隔符号 window &amp; linux -&gt; .'.'&gt;&gt;&gt; repr(os.linesep) #linesep 获取操作系统的换行符号 window -&gt; \r\n linux/unix -&gt; \n"'\\r\\n'" &gt;&gt;&gt; path = '/home/sy/000.py' #splitext() 将一个路径切割成文件后缀和其他两个部分,主要用于获取文件的后缀&gt;&gt;&gt; result = os.path.splitext(path)&gt;&gt;&gt; print(result)('/home/sy/000', '.py')sys模块123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#sys.argv: 实现从程序外部向程序传递参数。可以用sys.argv获取当前正在执行的命令行参数的参数列表(list)sys.argv[0] 当前程序名sys.argv[1] 第一个参数sys.argv[0] 第二个参数#sys.exit([arg]): 程序中间的退出，arg=0为正常退出。调用sys.exit(n)可以中途退出程序，当参数非0时，会引发一个SystemExit异常，从而可以在主程序中捕获该异常。sys.getdefaultencoding(): 获取系统当前编码，一般默认为ascii。#sys.setdefaultencoding():设置系统默认编码，执行dir（sys）时不会看到这个方法，在解释器中执行不通过，可以先执行reload(sys)，在执行 setdefaultencoding('utf8')，此时将系统默认编码设置为utf8。（见设置系统默认编码 ）#sys.getfilesystemencoding(): 获取文件系统使用编码方式，Windows下返回'mbcs'，mac下返回'utf-8'.#sys.path: 获取指定模块搜索路径的字符串集合，可以将写好的模块放在得到的某个路径下，就可以在程序中import时正确找到。#sys.platform: 获取当前系统平台。如win32表示是Windows 32bit操作系统，linux2表示是linux平台；#sys.stdin,sys.stdout,sys.stderr: stdin , stdout , 以及stderr 变量包含与标准I/O 流对应的流对象. 如果需要更好地控制输出,而print 不能满足你的要求, 它们就是你所需要的. 你也可以替换它们, 这时候你就可以重定向输出和输入到其它设备( device ), 或者以非标准的方式处理它们&gt;&gt;&gt; sys.stdin.readline() #从标准输入读一行sfdsafkjl'sfdsafkjl\n'&gt;&gt;&gt; sys.stdout.write("AAA") AAA3&gt;&gt;&gt; sys.stdout.write("BBBBBb")BBBBBb6#sys.modules功能：sys.modules是一个全局字典，该字典是python启动后就加载在内存中。每当程序员导入新的模块，sys.modules将自动记录该模块。当第二次再导入该模块时，python会直接到字典中查找，从而加快了程序运行的速度。它拥有字典所拥有的一切方法。&gt;&gt;&gt; sys.modules.keys() #返回所有已经导入模块列表dict_keys(['builtins', 'sys', '_frozen_importlib', '_imp', '_warnings', '_thread', '_weakref', '_frozen_importlib_external', '_io', 'marshal', 'nt', 'winreg', 'zipimport', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_weakrefset', 'site', 'os', 'errno', 'stat', '_stat', 'ntpath', 'genericpath', 'os.path', '_collections_abc', '_sitebuiltins', 'sysconfig', '_bootlocale', '_locale', 'encodings.gbk', '_codecs_cn', '_multibytecodec', 'atexit', 'pydoc', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'types', 'functools', '_functools', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'weakref', 'collections.abc', 'warnings', 'importlib.machinery', 'importlib.util', 'importlib.abc', 'contextlib', 'inspect', 'ast', '_ast', 'dis', 'opcode', '_opcode', 'enum', 'linecache', 'tokenize', 're', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'copyreg', 'token', 'pkgutil', 'platform', 'subprocess', 'time', 'signal', 'threading', 'traceback', 'msvcrt', '_winapi', 'urllib', 'urllib.parse', 'tempfile', 'shutil', 'fnmatch', 'posixpath', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random'])&gt;&gt;&gt; print(sys.modules["os"])&lt;module 'os' from 'D:\\Program Files (x86)\\Python36-35\\lib\\os.py'&gt;#还可以通过key值获取模块所处路径&gt;&gt;&gt; sys.hexversion #获取python解释器的版本值，16进制格式50726384&gt;&gt;&gt; sys.version #获取python解释器的版本信息'3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 16:07:46) [MSC v.1900 32 bit (Intel)]'&gt;&gt;&gt; sys.copyright #返回python版权相关信息'Copyright (c) 2001-2018 Python Software Foundation.\nAll Rights Reserved.\n\nCopyright (c) 2000 BeOpen.com.\nAll Rights Reserved.\n\nCopyright (c) 1995-2001 Corporation for National Research Initiatives.\nAll Rights Reserved.\n\nCopyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\nAll Rights Reserved.'&gt;&gt;&gt; sys.api_version #解释器的C的API版本1013&gt;&gt;&gt; sys.version_info #python版本信息，final表示最终版本，candidate表示候选，还有后续发行版本sys.version_info(major=3, minor=6, micro=5, releaselevel='final', serial=0)&gt;&gt;&gt; sys.executable #返回python解释器的路径'D:\\Program Files (x86)\\Python36-35\\python.exe'&gt;&gt;&gt; sys.getwindowsversion() #获取windows的版本信息sys.getwindowsversion(major=10, minor=0, build=17134, platform=2, service_pack='')&gt;&gt;&gt;]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[函数进阶]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%AC%AC%E4%B8%89%E9%98%B6%E6%AE%B5%E5%87%BD%E6%95%B0%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[闭包1234567891011121314151617181920212223242526实现闭包步骤：- 1: 你要先来一个函数嵌套 - 外函数里包装一个内函数- 2: 外函数作用域有一个局部数据对象- 3: 内部函数对于外部函数作用域里非全局变量的引用- 4: 外函数返回内部函数 def wai(): a = 1 #a是属于wai函数作用域里的 def nei(): #nei函数就是一个载体了 print(a) return nei #返回的是一个函数对象 func = wai() #func -&gt; None #func == nei func() # a #返回的nei函数可以在wai函数执行完成之后，继续不报错执行 #证明了在nei函数，也就是此时的func中，保留一个a变量。 1: 闭包内部创建载体，可以使一个局部变量续命2:变量私有化： 每一次闭包函数执行后的返回值都是一个新的，这是因为函数运行首先开辟的都 是一块新的函数临时空间 每一次闭包函数执行后，都是返回了一个不一样的闭包函数载体， 那么这个载体里的变量，也是不一样的3: 变量状态维持： 闭包函数载体(返回值)，只要存活着，那么它其中的变量也将会一直维护4: 闭包会一直保存变量，所以呢，本该死去的局部变量现在无法及时得到释放, 消耗内存123456789101112131415161718192021mylist = [1,2,3]def func(): a = 1 #局部变量 只能存活在函数运行期间 #mylist[0] += 1 #在函数内部引用全局可变变量，那么其实你们都是全局的 mylist = ['a','b'] #局部变量 return afunc #函数对象 函数名func() #函数调用print(mylist)#让一个局部变量存活下来: #1: 返回值 #2: global #3: 列表保存数据 全局共享同一个(只在函数内部做修改) 可变数据的引用 #4: 闭包也可以给一个局部变量续命#对于可变数据对象： #赋值：我为自己创建了一个新得 找了新欢 #直接创建了一个新的 ： 局部变量 #修改：影响咱俩共有的女朋友 #全局被局部所使用 ： 全局装饰器123456789101112131415161718# 装饰器可以在函数运行前添加功能，并且不影响原有函数内容函数三要素def func(arg): #定义 var = arg ** 2 return var函数名: func函数参数(形参)：arg函数返回值: arg默认的，如果没有函数内的return语句，函数默认返回Noneres = func(10) #执行函数名：func返回值：res参数(实参)：10- func：函数对象- func() ：函数调用普通装饰器123456789101112131415161718192021222324252627def wai(b_func): #外函数的参数是一个函数对象 def nei(): print("嘿嘿嘿") #在nei函数里写的代码基本上都是添加的功能 return b_func() #这个是nei函数返回值，用来返回之前在wai函数所接收的参数 #b_func() #return '' return nei #返回了wai函数里的这个定义好的闭包容器@wai #语法糖def func(): print('哈哈哈哈') return 'func'res = func() #调用一个被装饰函数 其实相等于 wai(func)()print('func的返回值:',res)#func() 传统函数调用 #1: print('哈哈哈') #2: return None#func() 被装饰时调用 @wai #被装饰函数: func #装饰器函数: wai #1: wai(func) -&gt; return nei #2: nei() -&gt; #1: print("嘿嘿嘿") #2: return b_func() #1: b_func() -&gt; 'func' #内部调用被装饰函数 #2: return 'func' #内部闭包函数的返回值 其实是被装饰函数的返回值被装饰函数带参数12345678910111213def wai(func): #装饰器 def nei(var1,var2): var1 = 100 #在闭包函数内部对被装饰函数参数进行干预 var2 = 99 return func(var1,var2) return nei@waidef work(a,b): return a + bres = work(20,30) #wai(work)(a,b)print(res)装饰器函数也可以有参数123456789101112131415161718192021222324252627282930313233343536373839#商品mind = Truezhekou = 0.9 #折扣的数值youhuiquan = 5# 当你的装饰器函数也需要参数的时候，只需要多一层包装即可def dazhe(con,zk,yhq): def wai(func): def nei(money): print('-----------') if con: print('打折!') money = money * zk elif yhq: print("优惠券！") money = money - yhq return func(money) return nei return wai#dazhe -&gt; wai#wai -&gt; nei#nei -&gt; func()@dazhe(mind,zhekou,youhuiquan)def apple(money): print('苹果的价钱是:%d' % money) return money@dazhe(mind,zhekou,youhuiquan)def pants(money): print('裤子的价钱是:%d' % money) return money@dazhe(mind,zhekou,youhuiquan)def skirt(money): print('裙子的价钱是:%d' % money) return moneyapple(10)pants(50)skirt(100)1234567891011121314151617181920212223242526272829def wai(b_func): #外函数的参数是一个函数对象 def nei(): print("嘿嘿嘿") #在nei函数里写的代码基本上都是添加的功能 return b_func() #这个是nei函数返回值，用来返回之前在wai函数所接收的参数 #b_func() #return '' return nei #返回了wai函数里的这个定义好的闭包容器@wai #语法糖def func(): print('哈哈哈哈') return 'func'res = func() #调用一个被装饰函数 其实相等于 wai(func)()print('func的返回值:',res)#func() 传统函数调用 #1: print('哈哈哈') #2: return None#func() 被装饰时调用 @wai #被装饰函数: func #装饰器函数: wai #1: wai(func) -&gt; return nei #2: nei() -&gt; #1: print("嘿嘿嘿") #2: return b_func() #1: b_func() -&gt; 'func' #内部调用被装饰函数 #2: return 'func' #内部闭包函数的返回值 其实是被装饰函数的返回值123456789101112131415161718192021222324252627import randomdef func_1(): print('穿裙子')def func_2(): print('穿大衣')def func_3(): print('穿牛仔')func_dict = &#123; '裙子':func_1, '大衣':func_2, '牛仔':func_3,&#125;choice = random.choice(list(func_dict.keys()))def _wai(choice): def wai(func): def nei(): func_dict[choice]() return func() return nei return wai@_wai(choice)def girl(): print('上班了！')girl() #装饰这个函数异常捕获123456789101112131415161718192021222324252627282930313233常见错误：IndentationError: unexpected indent 缩进错误ZeroDivisionError: division by zero 除数为0NameError: name 'b' is not defined 访问未声明变量IndexError: list index out of range 访问越界(超过了原有数据的长度)变量KeyError: 2 访问字典中(JSON类似)不存在key值AttributeError: module 'socket' has no attribute 'create' 访问一个对象(变量，函数，类，模块)不存在的属性异常捕获的作用： - 异常捕获可以提高代码的健壮性 - 让我们的代码在不同情况下，可以让程序继续向下，而不是直接中断 - 有一些异常错误，需要额外导入模块才可以使用，切记。异常的类型： SystemExit(系统中断异常) KeyboardInterrupt(ctrl+c) Exception(内建异常类) Python中的异常都是继承自这个Exception而来的try: print('打开文件') #捕获异常 fp = open('1.txt')except FileNotFoundError : print('这个文件不存在') #捕获到异常后要做的事情except Exception as e: #捕获所有错误，一般不用finally: #不管错误是否发生，都执行这里的代码，比如关闭文件else: print("关闭文件") fp.close()#else 分支可以在没有异常出现的时候 执行手动抛出异常123456789101112131415161718#手动抛出异常，就是直接raise raise MyError('你能不能好好传参') try: raise TypeError('我心情不好，我就是要报错') #raise语句去将一个合法的异常except TypeError: print('这是我刚才自己要抛出来的异常，现在我要捕获他')print("哈哈哈哈哈哈")def func(name,age): if type(name) == str and type(age) == int: print('%s:%d' % (name,age,abc)) #定义了传入参数的类型，类型不对就报错 else: raise TypeError('你能不能好好传参') #%d只能接受数字name = '小明'age = '18'func(name,age)自定义异常1234567891011121314151617class MyError(Exception): #面向对象的继承方法 pass #什么都不干，过！#继承已又的异常基类，从这个基础来创建自己的异常# 现在已经创建出来了一个自己的错误def func(name,age): #name str #age int if type(name) == str and type(age) == int: print('%s:%d' % (name,age,abc)) else: raise MyError('你能不能好好传参')name = '小明'age = '18'func(name,age)1234567891011121314#coding: utf-8#2,3版本是两个Pythontry: from urllib.request import urlopen from urllib.error import URLErrorexcept ImportError: from urllib2 import urlopen,URLErrorurl = 'https://www.asdaskljdklasjdsajdlk.com'try: res = urlopen(url) print(res.read())except URLError: print('[+] 链接异常，无法访问')12345678910111213human = &#123; 'name':'小明', 'company':'小红', #'gays':'小暗'&#125;try: print('%s的老婆是%s' % (human['name'],human['company'],human['gays']))except KeyError as e: if 'company' in str(e): print('他没老婆') elif 'gays' in str(e): print('他没老公')时间模块time1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556- time.time() -&gt; float_time - linux时间：从1970年1月1日， 00:00:00 - 获取从Unix时间到现在经过的秒数 -&gt; 浮点数- time.localtime(float_time) -&gt; 时间元组 - 如果不传递参数，那么默认返回本地时间的一个时间元组 res = time.localtime() -&gt; 时间结果是具备时区的time.struct_time( tm_year=2018, 年 tm_mon=6, 月 tm_mday=9, 日 tm_hour=10, 时 tm_min=17, 分 tm_sec=9, 秒 tm_wday=5, 星期几 星期一数字是0 从0开始 表示星期几 tm_yday=160, 今年第几天 tm_isdst=0 夏令时)res.tm_yearres.tm_mon通过返回值的内置属性来获取到对应的值time.sleep(seconds) --&gt; 程序休眠，让程序挂起time.clock() ---&gt; 一般衡量程序的耗时 - win： - 第一次调用：返回当前的CPU时间 - 第二次调用：返回距离上一次调用所花费的时间 - linux： - 直接返回程序运行到执行这个函数所花费的时间time.asctime(时间元组)time.strftime(格式，时间元组) -&gt; 良好可读性的字符串 将时间元组根据你指定的格式来成为一个良好可读性的字符串time.strptime(良好可读性的字符串，格式) -&gt; 时间元组 把一个字符串变成时间元组。 %Y: 年份 Year%m: 月份 month%d: 天数 day#年月日，时分秒中，只有月和天是小写的，其他都是大写的%H：时 Hour%M：分 Minute%S：秒 Seconds#以上六个死记硬背'%Y-%m-%d %H:%M:%S'%x 月/日/年%A: 星期的全称英语%a：星期的缩写英语%F 年/月/日%T 时/分/秒 - strf 将时间元组变成字符串- strp 将字符串变成时间元组- 时间元组用来被处理，时间字符串只是一个展示的123456&gt;&gt;&gt; time.time()1530412385.3557775&gt;&gt;&gt; time.localtime()time.struct_time(tm_year=2018, tm_mon=7, tm_mday=1, tm_hour=10, tm_min=33, tm_sec=14, tm_wday=6, tm_yday=182, tm_isdst=0)&gt;&gt;&gt; time.asctime(time.localtime())'Sun Jul 1 10:33:39 2018'datetime模块123456789101112131415161718192021222324252627datetime.datetime - 处理年月日，时分秒的 - datetime.datetime.now() - datetime.datetime.today() - 获取当前的时间 - 返回值：datetime.datetime类型 - 返回值类型支持差值运算，用来求出两个时间区间的秒数，或者说你指定的时间单位datetime.date - 处理年月日 - datetime.date.today() - 年月日返回当前时间datetime.time - 只能处理时分秒 - 多用来创建时分秒的时间 创建时间 datetime.datetime(2018,6,6,10,10,59) 创建年月日，时分秒 datetime.date(2018,6,6) 创建年月日 datetime.time(10,50,59) 创建时分秒 #我想求出再过20天是啥时候&gt;&gt;&gt; de = datetime.timedelta(days=25)&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; now + de datetime.datetime(2018, 7, 4, 11, 20, 2, 286059)#结果中，会自动把天数，月数向上换算1234567891011&gt;&gt;&gt; datetime.datetime.now()datetime.datetime(2018, 7, 1, 10, 30, 36, 190926)&gt;&gt;&gt; de=datetime.timedelta(days=20) #求20天后日期时间&gt;&gt;&gt; now=datetime.datetime.now()&gt;&gt;&gt; now+dedatetime.datetime(2018, 7, 21, 10, 31, 53, 726784)&gt;&gt;&gt; de=datetime.timedelta(days=-20) #使用-20求的是20天之前的日期时间&gt;&gt;&gt; now+dedatetime.datetime(2018, 6, 11, 10, 31, 53, 726784)随机模块random12345678910111213141516171819202122232425262728293031- random.randrange(stop) - 生产出从0到stop区间内的一个随机整数 - 不包含stop- random.randrange(start,stop,step) - 生产出从0到stop区间内以步长为step的一个随机整数 - 不包含stop- random.randint(start,stop) - 返回start和stop区间内的一个随机整数 - 起点和终点都可能被取到- random.getrandbits(num) - 传入一个num值，0-2**num次方，去一个随机的整数 - 如果传递的num是1，0 - 2 ** 1 0 -2 - 不能取到终点：如果你传递的是2**3,那么取不到8- 随机浮点数- random.random() -&gt; &lt;1 - 返回介于0到1之间的浮点数- random.uniform(start,stop) - 取出一个从start开始到stop结束的一个随机浮点数 - 这里start也可能出现 - stop的值是不取的- 随机序列- random.choice(seq) - 从一个非空序列中随机选择一个元素 - 序列为空则报错 - 序列：字符串，列表，元组 支持索引操作的数据- random.shuffle(seq) - 打乱序列的顺序- random.sample(seq,num) - num是我要从seq中随机抽取数据的长度，num 一定要小于 len(seq) - 从seq中 随机抽取num个数据 返回成一个列表 - num代表取几个SYS模块12345678910111213141516171819202122232425262728293031sys.argv: 获取当前程序的命令行参数 命令行参数 就是你在执行.py脚本时传递的 参数的列表sys.argv[0]: 当前程序的名字sys.platform - 用来输出当前的环境平台 - os.namesys.exit(0) 直接退出程序sys.path - 环境变量列表IO流处理： i: in 进去 - 键盘向程序输入内容 - 写文件 - 接受其他服务器反馈 o: out 出来 - print向屏幕打印 - 读文件 - 向其他服务器发送请求IO是影响程序性能,print操作是IO操作，那么尽量少在代码里printsys.stdin - 标准输入 input sys.stdin.readline()[:-1] == input()sys.stdout - 标准输出 print sys.stdout.write('abc\n') == print('abc')sys.stderr - 标准出错]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[函数]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5%E5%87%BD%E6%95%B0%E8%83%8C%E8%AF%B5%2F</url>
    <content type="text"><![CDATA[函数参数1234567891011121314151617181920212223242526272829303132333435363738394041424344## 函数 是一个容器，里面包含了代码执行语句，还有一系列的变量数据函数的参数是在定义函数时括号中的内容形参是一个待赋值的变量实参是函数实际调用时传递进去的值形参是被实参所赋值实参在传递的时候要和形参一一对应缺省参数： 在函数定义时，指明一个形参的默认值，就可以不给这个具有默认值得参数传递参数了 给一个具有默认参数的形参传递一个实参，那么会覆盖原有的默认值 缺省参数的定义顺序一点是从右向左，从后向前 #缺省参数可以让形参具有默认值 #缺省参数的定义一定是从右向左 #缺省参数后面要么是缺省，要么就没参数了不定长参数： 元组不定长*arg def func(*args): print(args) func([1,2,3],'abc','中国') 字典不定长： def func(**kwargs): print(kwargs) #*args 用来接收不定长参数保存成元组 func(a=&#123;'name':'小明','sex':'man'&#125;,b=2,c=3) 形参：a,b,c 实参：就是后面的数据 不定长参数可以接收空值 def func(i,j,*args,**kwargs): #**kwargs 用来接收不定长参数保存成字典，而且在函数调用时， #一定要注意使用命名传参的方式 print(i,j,args,kwargs) func(1,2) 传递的时候首先传递单纯变量作为元组不定长，键值对不定长必须在后命名参数 def func(a,b,c,d,e,f): pass func(b=1,a=2,d=3,f=4,e=3,c=5) #命名传参可以打乱顺序返回值 - 函数内部的一些操作，不能影响外界的事务 - return 语句 在函数执行完成之后返回一个结果 - return 会终止函数运行 - 函数调用完成之后会返回结果 - 默认的函数如果没有返回值，那么返回None - 函数返回值可以任意多个 - 只要是合理的数据，**模块**，对象，函数名均可以返回函数作用域1234567891011121314151617181920212223242526272829303132333435a = 1 #全局就是全局def func(): a = 2 #局部就是局部 #修改全局a变为2 错误 #在局部空间创建一个新的同名a 正确 print("内:",a) global 把一个局部变量声明成全局的a = 1 #全局就是全局def func(): global a #升级局部变量成为全局的 a = 2 #局部就是局部 #修改全局a变为2 正确 #在局部空间创建一个新的同名a 错误的 print("内:",a) #局部作用域：函数内空间#全局作用域：整个脚本空间- 形参都是局部的- 不可变数据对象，在函数内外的值，用到了引用计数- 全局变量可以被局部作用域使用- 但是局部变量不可以被全局作用域所使用，除非你用global语句升级，声明为全局变量- 全局可变对象,在函数内部使用的时,其实是一个共享状态- 是因为列表的指针域 是一个 也会存在引用计数的情况- 解决办法就是在函数内部使用深浅拷贝 #内外其实现在共同使用同一个列表 #内外互相影响，用的就是同一个列表 #这样的数据可以在函数之间进行通信可变数据在传递参数时 - 在函数内部直接通过形参修改,也会影响原有数据 - 可变对象在传递参数时,只是一个引用不可变数据在传递参数时 - 在函数内部直接通过形参修改,不会影响原有数据1234567891011121314+= 或者 = 号赋值都会使一个不可变数据类型在函数的局部作用域下成为一个局部变量a = 1def func(): a = a + 1func()# 整个作用域下的a都是来自于同一个作用域的 #你不能说 第一个a是局部的、第二个a是全局的 #这样的话，一个a在一个内存空间下可以表示两个值了，这就二义性了# 现在的a 就是一个局部变量了# 局部变量a 需要 局部变量a + 1# 这个代码会报错# local variable 'a' referenced before assignment12345678910111213141516171819mylist = [1,2,3,4,5,6]def func(): mylist[0] = 'a' print('内:',mylist) #内外其实现在共同使用同一个列表 #内外互相影响，用的就是同一个列表 #这样的数据可以在函数之间进行通信func()print('外:',mylist)#==================mylist = [1,2,3,4,5,6] #全局变量def func(): new_list = mylist.copy() #浅拷贝之后，互不影响 new_list[0] = 'a' #局部变量 print('内:',new_list)func()print('外:',mylist)1234567891011121314151617mydict = &#123; 'name':'Small White', 'money':500&#125; #字典是一个可变的 def func(key,value): mydict[key] += valuemove_dict = &#123; '中彩': [func,20], '生病': [func,-20], #字典的value要给定一个实际的值&#125;move = '中彩'move_dict[move][0]('money',move_dict[move][1])#move_dict[move][0] 取到函数#move_dict[move][1] 取到应该修改的值print(mydict)匿名函数123456789101112131415- lambda 表达式- 除了def语句,我们还可以通过lambda语句来创建函数- lambda创建的函数 因为默认不具有名字，他需要我们来指定一个变量名来保存- 表达式的结果，将作为返回值自动返回- 轻量级的函数 一般使用lambda来实现a = lambda x: x*2a(2)#lamdba 参数 : 表达式mylist = [lambda x,y:x**y,lambda x,y:x**(y+1),lambda x,y:x**(y+2)] #跳转表for var in range(5): #取出来0-4的数据 for func in mylist: res = func(var,2) print(res) print('-------------')123456789#计算器oper_func_dict = &#123; '+':lambda x,y : x + y if x &gt; 0 else x - y, '-':lambda x,y : x-y, '*':lambda x,y : x*y, '/':lambda x,y : x/y,&#125;res = oper_func_dict['+'](x=0,y=1)print(res)三元表达式12x + 1 if x &gt; 0 else x - 1#当条件满足时(x &gt; 0) 执行表达式左边的,反之执行表达式右边的跳转表：包含函数的字典或者列表123456789101112131415mylist = [lambda x,y:x**y,lambda x,y:x**(y+1),lambda x,y:x**(y+2)]#列表中的每一数据都是一个函数#求出0-4数据的每一个2，3，4次方的结果for var in range(5): #取出来0-4的数据 for func in mylist: #func = lambda x:x**2 #func = lambda x:x**3 #func = lambda x:x**4 res = func(var,2) print(res) #外层for循环取出每一个值 #传递到内存循环中执行三次，分别求出2，3，4的方结果 print('-------------')#跳转表：包含函数的字典或者列表作业：模拟人生123456789101112131415move_dict = &#123; 'w': lambda y: y + 1, 's': lambda y: y - 1, 'a': lambda x: x - 1, 'd': lambda x: x + 1,&#125;x = 0y = 0while True: move = input('你要怎么移动:') if 'w' == move or 's' == move: y = move_dict[move](y. if 'a' == move or 'd' == move: x = move_dict[move](x) print('你当前的位置:%s:%s' % (x,y))递归1234567- 当函数自身包含了对自身的调用，那么就是递归- 递归有最大上限次数:1000次左右- 递归每一次都在开启一个新的函数空间- 递归会非常占用内存- 递归一定要确定终止条件普通循环 for while 一般适用于解决线性循环递归的优势在与解决非线性的递归求和作业练习：12345678910111213141516mylist = [1,2,[3],5,[6,[7,8,9]],1,2] #-&gt; 44#试一下用循环求和，#如果列表变化，那么代码可以兼容，可以直接复用，不能改变mysum = 0def get_sum(iter):#接收一个等待求和的多层序列 #iter 中 无非两种数据类型: list int global mysum for var in iter: if type(var) == int: #当前取出来的数据是int #if type(var) == type([]) mysum += var else: get_sum(var) #遇到的又是一个列表，那么我们继续遍历 #for循环结束的时候，递归结束get_sum(mylist)print(mysum)递归统计每一个出现的字符出现的次数123456789101112131415161718192021222324mylist = ['asdazxc','adxzc',['12390145fcsdjfhzkjxcmnasd','123987189asjkdsajkb'],'asdqwewqerq',['asd890q8390'],'asdhquiweqysa','asdhjkzhxjkckjasdh']#把一样的提出来#统计每一个出现的字符出现的次数#for循环实现dict_num = &#123;&#125;#key:对应的字符#value:出现的次数def get_num(seq): #字典是可变数据类型，所以直接可以在函数作用域内进行修改 for var in seq: #遍历整个列表数据 if type(var) == list: #如果取出来的还是一个列表，那么就继续递归 get_num(var) else: #如果碰到的是一个字符串 for i in var: #遍历字符串，记录次数 if i in dict_num: # 如果获取到的字符，已经存在了字典中，那么他的次数+1 dict_num[i] = dict_num[i] + 1 else: # 如果获取到的字符没出现过，那么就创建默认值1就行 dict_num[i] = 1get_num(mylist)for key in dict_num: print(key,':',dict_num[key])回文判断123456789101112131415161718192021222324252627282930#问题：使用递归 判断一个字符串是否是回文:mystr = input("请输入一个你觉得是回文的字符串我来帮你判断:")if mystr == mystr[::-1]: print('这就是回文')else: print('这不是回文')def p_h(obj): if len(obj) &lt; 2: #'a' return True #返回 结束 elif obj[0] != obj[-1]: #如果判断对应索引位置的值不一样，那么就返回False return False # 现在我判断完了0和-1位置，是不是就可以不要他们了 return p_h(obj[1:-1])print(p_h(mystr))#奇数一定有1，偶数一定没有def p_h_2(obj): #7 - 1 / 2 = 3 #7 / 2 - 1 / 2 #结果少了小数点后的 index = len(obj) // 2 #取出中间索引位置 #取出下一半字符串 b = obj[index:] if not (len(obj) &amp; 1) else obj[index+1:] #判断是否是奇或 偶数位 #三元表达式 当 if条件成立，那么返回左边的，反之返回右边的 return True if obj[:index] == b[::-1] else Falseprint(p_h_2(mystr))1234567891011#回文判断def p_h_2(obj): #7 - 1 / 2 = 3 #7 / 2 - 1 / 2 #结果少了小数点后的 index = len(obj) // 2 #取出中间索引位置 #取出下一半字符串 b = obj[index:] if not (len(obj) &amp; 1) else obj[index+1:] #判断是否是奇或 偶数位 #三元表达式 当 if条件成立，那么返回左边的，反之返回右边的 return True if obj[:index] == b[::-1] else Falseprint(p_h_2(mystr))12345678910#递归回文判断def p_h(obj): if len(obj) &lt; 2: #'a' return True #返回 结束 elif obj[0] != obj[-1]: #如果判断对应索引位置的值不一样，那么就返回False return False # 现在我判断完了0和-1位置，是不是就可以不要他们了 return p_h(obj[1:-1])print(p_h(mystr))os模块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465- os模块支持以下平台，他会根据平台来对应处理你调用的函数 - posix：类Unix操作 安卓 Centos ubuntu Debian - nt：Win - mac：MacOS - 4月28号早上8点多的时候我的mac丢了 - dos：DOS - dos必须关机 开机的阶段才能看到 - U盘安装dos操作系统- os.name 输出当前os模块在哪个平台下- os.getcwd() -&gt; str - 获取当前的程序工作目录 - 工作目录：是我们程序在运行期间的时候，如果你需要和当前运行环境(操作系统)进行交互，相对路径互相参照，工作目录可以在程序运行期间修改 - 运行目录：维护当前程序是从哪个路径下被执行的- os.listdir(path=os.getcwd()) -&gt; list - 返回指定path目录下的所有文件及文件夹的列表 - 当你不传递一个路径的时候，默认的会返回当前的工作目录下的内容 - 该函数返回的结果，不会明确什么是文件，什么是文件夹 - 返回的结果是一个字符串列表，并且每一个路径都是相对路径的 - 该函数也会将隐藏文件展示- os.remove(file_path) #rm - 删除file_path所指定的一个文件 - 如果成功返回None，失败了直接报错 - 删除的时候一定要指明文件的后缀 IsADirectoryError: [Errno 21] Is a directory: 'test' 删除了一个文件夹 FileNotFoundError: [Errno 2] No such file or directory: 'tesasdjklajdkt' 删除了一个不存在的文件- os.rmdir(dir_path) # rm -rf - 删除dir_path指定的一个文件夹(目录) - 如果成功返回None，失败了直接报错 - 无法递归删除文件夹，如果文件夹不为空，那么删除不了- os.makedirs('a/b/c') - 递归创建目录 - 可以嵌套创建目录 - 成功返回None，失败则报错- os.mkdir('a') - 创建目录 - 不能在linux下创建一个和文件名重名的文件夹 - 虽然类型不同，但是名字也不能是相同的 - 成功返回None，失败则报错- os.chdir() - 在程序运行期间可以通过该函数来改变工作目录 - os.listdir() 这个函数可以不传递参数执行，返回当前工作目录下的所有文件及文件夹的列表os模块下还有一个子模块叫os.pathos.path可以处理和路径及文件类型有关的问题- os.path.isfile(path) -&gt; Bool - 判断路径是否是一个真正的文件 - os.path.isdir(path) -&gt; Bool - 判断路径是否是一个真正的目录- os.path.join('path','sub_path') - 拼接path和sub_path - 可以构成绝对路径 - 路径中重复的部分不会被去掉 &gt;&gt;&gt; os.path.join('home','home/CODE') 'home/home/CODE'- os.path.exists(path) - 判断路径是否存在 - 如果存在返回True，反之返回False- os.path.getsize(path) - 返回路径对应的文件大小 - 返回的文件大小单位为Byteos语音控制你的电脑123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117'''pip install PyAudio 是可以控制你的音频设备 录音还有播放pip install pyttsx3 是可以让你的电脑播放音频pip install requests 可以访问百度语音接口然后安装好pywin32软件即可''''''1.你先向电脑传输音频2.解析音频 转换成字符串 requests 百度云接口3.说话后的字符串再分析4.os.system(处理分析后的字符串)'''import pyttsx3 #播放import pyaudio #录音import time #获取时间import json #用来分析json字符串import requests #访问链接from urllib.request import urlopen,Request #访问连接import base64 #b64编码import osdef talk(data): eg = pyttsx3.init() eg.say(data) eg.runAndWait()#向电脑说话def get_audio(): pa = pyaudio.PyAudio() #初始化音频设备 audio_equip = pa.open( format=pyaudio.paInt16,#存储位深 channels=1,#声道 rate=16000,#采样率 input=True,#输入 frames_per_buffer=1024,#获取的数据大小 ) times = 0 data = [] print('[+] 请说话...') start = time.time() while times &lt; 45: #控制到了说话时间为3秒 audio_data = audio_equip.read(1024) #从设备中读取音频 data.append(audio_data) #吧每一次read读取到的音频 追加到我的data列表中 times += 1 end = time.time() print('[+] 你说话耗时:%.2f' % (end-start)) audio_equip.close() #关闭设备 res = b''.join(data) #把列表中的所有数据拼接成整体 return resdef get_token(): url = 'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&amp;client_id=%s&amp;client_secret=%s' client_id = 'npFlwGurf1tMvMS8myW6W9AA' client_secret = 'TZcTamTfVlYWilclkLbatZe18e8xYzIY' host = url % (client_id,client_secret) res = urlopen(host).read().decode() #urlopen函数打开链接提交参数，获取Toekn #但是这里获取到的是一个json的并且是编码过后的数据 token = json.loads(res)['access_token'] return token#百度音频解析 def bd_analysis(): token = get_token() audio_data = get_audio() audio_data_len = len(audio_data) audio_data = base64.b64encode(audio_data).decode() #百度云在接收音频的时候，需要传递两个值 #第一个是音频的实际数据，用base64编码 #第二个是音频的长度, 一定是未编码之前的 data = &#123; 'format':'wav', 'rate':16000, 'channel':1, 'cuid': '1804shuaideyipi', 'dev_pid':1536, 'token':token, 'speech':audio_data, 'len':audio_data_len, &#125; data = json.dumps(data).encode() #处理成json格式并且编码 host = 'http://vop.baidu.com/server_api' #把所有的东西都给到百度 headers = &#123; 'Content-Type':'application/json', #指明你提交的数据类型 &#125; req = Request(url=host,headers=headers,data=data) try: res = json.loads(urlopen(req).read().decode())['result'][0].replace('，','') except : res = '语音质量有问题,请重新喊话!' talk('语音质量有问题,请重新喊话!') else: print('[+] 你说话的内容:',res) return reswhile True: if 'yes' in bd_analysis(): talk('请告诉我，我要做什么！') res = bd_analysis() if '计算器' in res: os.system('calc') talk('爷，你的计算器打开了') elif '取消关机' in res: os.system('shutdown -a') talk('已经取消关机了') elif '关机' in res: os.system('shutdown -s -t 1000') talk('OK给你关机!') else: pass文件操作123456789101112131415161718192021222324252627282930313233所有的文件都是在磁盘上的！CPU只能处理在内存中的数据，也就是说，CPU无法直接去阅读磁盘里的文件CPU &lt;-&gt; MEM &lt;-&gt; DISK- 文件操作，在程序里都是对内存中的文件进行操作！第一步：打开文件 fp = open(path, mode='r') open函数返回的是一个文件的句柄，不是完全的文件展开体，只是一个可以导出整个文件的头指针第二步：读 fp.read(num) 函数直接阅读整个文件，并返回整个文件为一个字符串 把整个文件读到了内存 如果给read函数传递了num变量 那么他是通过num来读取对应文件中的指定字符个数 read函数获取到的文件内容会保留行末尾的\n\r fp.readline() readline函数一次可以读取文件中的一行内容 当遇到了\n\r则停止，代表当前是一行了 当遇到了EOF（文件结束标志） readline如果去读取超过文件本身行数的次数，那么不会报错，只会返回空 readline不会一次性把整个文件展开在内存 但是需要我们手动的维护行数 readline函数在获取到文件内容的每一行后，也会保留结尾的\r\n fp.readlines() 返回了字符串列表 列表中每一个元素都是一行的数据 并且保留行末尾的换行符号第三步：关闭文件 fp.close()fp.tell() 获取文件指针位置 with open('1.txt') as fp 这里的with as 语句可以自动做资源创建和释放文件权限： w:权限可以让我们打开一个文件，进行写入，但是每一次打开都会将之前的文件内容清空 write函数在写入文件内容的时候，不会自动的带换行\r\n a：append 追加，读写指针在文件末尾缓冲和缓存12345678910111213141516缓冲区( 内存(临时) ) 针对读写文件 - 缓冲区让效率慢的和效率快的组件之间可以协同工作，缓和速度之间的矛盾，不频繁的写入磁盘，可以保护设备。因为磁盘的寿命是由写次数决定的。 - 当你关闭文件的时候，缓冲区中的内容会刷新到磁盘上 - 手动刷新缓冲区：fp.flush() - 磁盘是保存数据的- 内存是流通数据的- CPU才是真正计算数据的- CPU处理内存中的数据，而内存中的数据来自于磁盘缓存：为了提高数据流通速度缓存是在CPU里有缓存是一块超级告诉的数据流通空间（类似内存），但是太贵了，所以电脑上缓存空间一般不大L1：CPU经常从L1中拿取数据、控制线程和进程L2：存储数据L3：管控内存读写指针修改123456789101112131415fp.seek(offset,when)offset：偏移量 字节为单位when: 从哪里开始移动 0:文件开头 1:当前位置 2:文件末尾a模式下的文件末尾读写指针如何移动到文件头部呢？fp.seek(0,0) -&gt; 回到了文件开头fp.tell() 获取文件指针，返回的也是以一个字节为单位不同权限下读写指针位置：- r: 文件开头- w: 文件开头- a: 文件末尾csv文件操作12345678- CSV文件是一个用于电子表格存储类型- csv文件是存储了以逗号分隔的数据csv文件默认写入的时候 会在每两行之间多一个空行解决办法：在打开文件的时候fp = open('1.csv','w',newline='')#newline参数用来控制 每一次写入csv文件数据的时候，一行行之间是否需要空行12345678910111: 处理普通文本对象为csv文本对象 打开文件： fp = open(path,mode) 加工： csv_read_fp = csv.reader(fp) 负责读取 csv_write_fp = csv.writer(fp) 负责写入2: 对csv_read_fp进行for循环迭代，就可以一行行的访问csv表格中的内容 for var1,var2 in csv_read_fp: print(var1,var2)3: 对csv_write_fp文件写入内容，写入的是一些逗号分隔开的数据 csv_write_fp.wirterow([seq])12345字典读取csv时： dict_read_csv = csv.DictReader(fp) for var in dict_read_csv: print(var['name'],var['sex'])csv文件中第一行是key值，下面的数据是value123456789字典写一个csv文件 dict_write_csv = csv.DictWriter(fp,fileds) fp: 打开的文件对象，需要加工成csv字典处理文件对象 fileds： 标题行 第一行 fileds 也是一个逗号分隔的数据 比如: fileds = ['name','age','sex'] dict_write_csv.writeheader() #将指定的标题行先写入到csv文件里 dict_write_csv.writerow(&#123;'name':'BOB','age':'16','sex':'man'&#125;)1234567891011121314151617181920212223import csvfp = open('test1.csv','w',newline='')fileds = ['name','age','sex'] #标题行name = ['Bob','Jack','Lucy']age = [10,16,18]sex = ['man','man','woman']human_list = []for index in range(3): #0-2 #外层循环用来控制生产三个数据 human_dict = &#123;&#125; human_dict[fileds[0]] = name[index] #name human_dict[fileds[1]] = age[index] #name human_dict[fileds[2]] = sex[index] #name human_list.append(human_dict)#BOB = &#123;'name':'BOB','age':'16','sex':'man'&#125;dict_write_csv = csv.DictWriter(fp,fileds) #加工文件对象，指明标题行print(help(csv.DictWriter)) #写入标题行#******************************dict_write_csv.writeheader() #用来在csv文件中写入标题行#******************************for var in human_list: #遍历用户字典，分别写入csv文件中 dict_write_csv.writerow(var)fp.close()]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python基础数据类型]]></title>
    <url>%2F2018%2F07%2F26%2F%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5%E8%83%8C%E8%AF%B5%2F</url>
    <content type="text"><![CDATA[数据类型：数字，字符串，列表，元组，集合，字典数字1234567整数：int浮点数：float布尔值：大小写敏感 非空非零为真，0或空为假复数：以J或j结尾，type(判断谁) 查看类型字符串123456789101112字符串里面的东西是无意义的索引：从左到右，从0开始，从右到左，从-1开始切片：左闭右开 a[start:stop(不取):step] step 步长 start起点 stop终点(不取) 同符号情况下，如果步长是负数，那么应该从大到小 start &gt; stop 如果步长是个正的，那么从小大到 start &gt; stop字符串是一个不可变数据类型 一般对于不可变数据的函数处理，操作只会返回一个新的值，不会影响自己本身 字符串支持 加法和乘法 分别是拼接和多次输出列表12345678910111213列表(list) 语法: a = [1,2,3,4,5] 支持索引和切片 一个列表里可以存储任意的数据类型 可以创建一个空列表 列表可变，可以通过索引访问修改通过切片重新赋值 切片修改的时候，只要给的值和坑对应了就行列表的范围赋值： 切片赋值： 步长绝对值为1时，取一个数据集合的每一个值，放置到这个之前的位置 步长绝对值大于1时，一个萝卜一个坑，要一一对应 切片的步长包含起点元组123456元组(tuple) () 不可变 创建一个只含有一个数据的元组 a = (&apos;a&apos;,) 只含有单个数据的元组，要加逗号总结1234567891011121314字符串、列表、元组 都是有顺序的一个数据集，也就是有序的序列序列就是有顺序的数据集。字符串 列表 元组都是序列。可变数据： 列表 （可变而的是列表中的数据，而不是这个对象）不可变数据： 数、字符串、元组可变不可变性质:不可变的是类型其中的数据不可变数据对象，不可变的是指向关系，不是这个变量名不可变的变量，变量在变的时候，重新给了新的指向关系，原来的不可变指向关系被抛弃了！可变的变量，直接就能变指向关系iterable 可迭代的对象 含有数据是一个集合 数据前后可以互相找到有序的序列就是可迭代的对象，如字符串，列表和元组。序列123序列包含：字符串，元组，列表序列支持索引和切片序列是可迭代的对象变量的本质12345678910111213141516171819变量本质： 变量不需要先定义(不需要声明大小类型)，可以直接使用，直接赋值a = 1 变量可以重复赋值，哪怕更换类型 同时可以给多个变量赋值 命名风格，不要和模块名，常用函数 print，不能用数字开头，字母，数字，下划线，在python3，中文也可以做变量名 __num__ 特殊的python内置变量 不支持自增和自减 引用计数： 就是针对一些不可变数据 变量的内存分配方式 变量在创建的时候，首先不会直接开辟空间，会先去查找，已有的空间 如果有这个数据了，那么他不会创建新的，而是利用已有的 del语句可以删除一个变量名，但是不会释放变量数据占据的空间 del语句还把引用计数减1了，数据的空间只有在引用计数真正为0的时候才会释放 python中的del语句释放数据内存? x 查看变量的内存地址：id(变量名) import sys sys.getrefcount() 查看变量的引用计数 注意： python解释器有没有在用 赋值语句是否是单独创建，还是借用别人引用计数1234567引用计数： 常见变量会使用引用计数的方式分配内存， 一个变量创建的时候，不会去直接创建一个新的地址，先去查找已有的(不可变数据：元组，字符串，整数) del 引用计数减一 当一个对象真正最后引用计数为0的时候，才会被释放，延迟性 del切断了变量名和具体数据的内存地址的连接，该变量所使用的数据的引用计数减去1使用引用计数的原因：定义变量开辟空间，变量多，占用多，值相同的内存空间，相互共享，而不用创建运算表达式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859算数表达式: + - * / // % ** 逻辑表达式 返回值类型是Bool a = 1 非空非0为真 b = 0 0或空为假 not a 逻辑非 a and b 逻辑与 a or b 逻辑或 a is b a和b是不是同一个对象 a is not b a和b不是同一个对象 is不光是判断值相同，还要判断是否是同一地址 与：and -&gt; False 真真为真，真假为假，假假为假，只要有假则为假 或：or -&gt; True真真为真，真假为真，假假为假，只要有真则为真关系表达式 如果不是数字来判断，那么判断的就是阿斯克码 表达式 汉译 返回值类型 a==b a,b是否值相等 bool a!=b a,b是否值不相等 bool a&lt;&gt;b a,b是否值不相等 bool a&gt;b a是否大于b bool a&lt;b a是否小于b bool a&gt;=b a是否大于等于b bool a&lt;=b a是否小于等于b bool 小写字母a的十进制 ascii：97 大写字母A的十进制 ascii：65位运算： 表达式 汉译 操作解释 ~a 按位取反 -(a+1) a&lt;&lt;n 左移n位 - a&gt;&gt;n 右移n位 - a&amp;b a和b按位与 11-&gt;1 00-&gt;0 01-&gt;0(都是1时才得1) a|b a和b按位或 01-&gt;1 11-&gt;1 00-&gt;0(只要有1就得1) a^b a和b按位异或 01-&gt;1 11-&gt;0 00-&gt;0(相同得0，不同得1) 计算机中存储的都是二进制 所有的运算，到最后，都是二进制的补码在运算，补码才是真正在计算机里存储的， 符号位参与运算，计算完成的结果也是补码 原码，反码，补码 正数的原码，反码，补码都是本身 负数： 原码：1000 0001 最高位是符号位 反码：1111 1110 符号位不变，其余各位取反 补码：1111 1111 -1 补码是反码加一 所有的运算都是 补码在做运算 1 -1 原码 0000 0001 1000 0001 反码 0000 0001 1111 1110 负数的反码 符号为不变，其余各位取反 补码 0000 0001 1111 1111 反码+1 对补码在求一次补码即可求出原码 a &gt;&gt; n 向右移动 位移的位置包含起点，其实就位移了一位。类似切片中的步长，步长计算也包含起点 ------------------------ a &amp; b a和b按位与 ，位上的值，只要有0，结果为0 a | b a和b按位或，位上的值，只要有1，结果为1 a ^ b a和b按位异或，只要值不同，结果才为1 所有的运算，都是补码在运算！！！条件分支语句123456789101112131415161718192021222324if …. else… 语句中 如果有一个条件满足，其他不会执行else条件也可以没有,elif条件也可以没有elif 可以 继续细分条件while条件语句返回值为True时，执行语句才会被执行for 访问可迭代的对象 for var in 可迭代的对象(str,list,tuple): 一次次的从里面取一个值break 条件满足时，直接跳出循环continue 条件满足时，只是跳过本次循环 循环搭配else语句来使用，这里else语句中的内容会在循环正常结束之后来执行#for var in seq: #遍历一个序列(前后数据间有顺序关系)，然后去其中一次次的拿取值 #for循环一般不用来实现死循环 #for次数一般由我们的数据长度来决定 #for循环每次会向后遍历 #for循环的死循环 需要构建环形或者无限延申的数据 #from itertools import cycle #cycle([1,2,3]) -&gt; 圈python3和python2区别123456789101112python3: print() %s接收到的可以是任意的数据类型 %d 用来输出整数 %f 用来输出浮点数，%.100f 控制输出的精度 input() 所有接收到的都是字符串 range() 抽象,不会生成数据，只有在使用的时候才会生成数据python2: print() input() 有效的数据，代码输入进来也是有效的，缓冲区溢出攻击 raw_input() 所有接收到的都是字符串 range() 具象的，会立即创建出实际的数据，很耗费内存 xrange() 抽象的，不会生成数据，只有在使用的时候才会生成数据深浅拷贝123456789101112131415拷贝： 可变数据对象的指针被共享了(引用计数)，所以需要我们引入拷贝创建变量的时候，我们希望的只是值相等，而不是互相影响a[:] 这是返回了一个新的列表，只是值和原先的a是一样的浅拷贝的方法： 切片拷贝，只能是复制浅层的数据对象，返回一个新的地址中的数据，内层的数据并没有实现拷贝 a=[1,2,3,4] b=a[:] import copy b=copy.copy(a)深拷贝： 深拷贝可以实现地址不同 深拷贝，拷贝的都是列表中的指向关系，对应列表中的数据还是使用引用计数的 import copy a = [1,2,3,['a','b']] b = copy.deepcopy(a)作业：使用切片实现深拷贝123456789101112a=[1,2,[1,2,3,[1,2,[1,2],3]]]b=a[:]b[-1]=a[-1][:] #[1,2,3,[1,2,[1,2],3]]b[-1][-1]=a[-1][-1][:] #[1,2,[1,2],3]b[-1][-1][2]=a[-1][-1][2][:]print("a:",a)print("b:",b)print("------------")b[-1][-1][2][-1]='abc'print("a:",a)print("b:",b)作业：求出mylist中每一个值123456789101112mylist = [1,2,3,[1,2,('a','b')],'c','def']for var in mylist: if type(var) == type([1]):#print('----',var)#当前满足列表 for var1 in var: if type(var1) == type((1,)):#var1此时是元组 for var2 in var1: print(var2) else: print(var1) else: print(var)print('---------------------')作业：两数交换有几种办法12345678两数交换有几种办法？分别列举a=1b=2最笨的方法：x=a a=b b=x方法一：a,b=b,a方法二：a=a+b a=a-b b=a-b方法三：a=a*b b=a/b a=a/b方法四：a=a|b b=a^b a=a^b作业：实现99乘法表12345678for i in range(1,10): for j in range(1,i+1): if i&gt;j: print("%s x %s = %s "%(j,i,i*j),end="") else: print() j+=1 i+=1作业：机器学习代码1234567891011121314151617181920212223242526272829import pickleimport osif os.path.exists("data.pkl"): f=open("data.pkl","rb") mydict=pickle.load(f) # print("数据已存在！") f.close()else: mydict=&#123;'hello':'hello'&#125; f=open("data.pkl","wb") pickle.dump(mydict,f) # print("新建数据库信息！") f.close()while True: ques=input("请输入困扰你的问题： ") if ques != "quit": if ques in mydict: print(mydict[ques]) else: ans=input("你教教俺吧。。。") if ans: mydict[ques]=ans else: break f=open("data.pkl","wb")pickle.dump(mydict,f)f.close()作业：实现计算器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cm = input("请输入你要计算的表达式:")index = 0for var in cm: if var in &#123;'+','-','*','/'&#125;: l_num,r_num = float(cm[:index]),float(cm[index+1:]) #取出左边的数据,并且转换成浮点型 #取出右边的数据,并且转换成浮点型 break index += 1 #index是操作符在输入表达式的里面cau = &#123; '+': l_num + r_num, '-': l_num - r_num, "*": l_num * r_num,&#125; #if条件远远不如字典判断快if r_num != 0: cau['/'] = l_num / r_numprint('result:',cau.get(cm[index]))#get方法在key值不存在的时候，不会爆错#cm[index]: 获取到了操作符#********************************************************************************expr = input('请输入一个运算表达式:')#' 2 |*| 0'index = 0 #用来查找表达式中 + - * /符号的位置for var in expr: #定位表达式中操作符的位置 if var in &#123;'+','-','*','/'&#125;: print("[+] 操作符位置:%d" % index) print("[+] 操作符:%s" % var) break # 找到了操作符，那么就跳出循环即可 #%d 可以整形转义输出 #%s 转移输出字符串 index += 1#找到左右两个数字#通过切片访问到字符串中的所有两个数字l_num = float(expr[:index]) #左边的操作数r_num = float(expr[index+1:]) #右边的操作数 不能是0#除法 被除数不能为0oper = expr[index] #找到了操作符res = &#123; '+': l_num + r_num, '-': l_num - r_num, '*': l_num * r_num,&#125;if r_num != 0: #当第二个操作不为0的时候 才支持除法 res['/'] = l_num / r_numprint('你的结果是: %s' % res.get(oper))#get获取字典中不存在key值不会报错，只会返回None # %d 只能支持数字(整数) # %s 随意一些，支持所有的类型字典1234567891011121314151617181920212223242526272829303132333435创建方法： 1、语法大括号包裹：创建字典 = &#123;key:value&#125; 2、工厂方法创建字典：res = dict(([1, 2],['a', 'b'])) 3、内建方法：dict.fromkeys( [1,2,3,4,5], 'a' ) 批量创建key值，无法单独为每个key分配具体的value字典的key是绝对唯一的，不可变的数据才可以做key值字典的value可以重复，可以是任意的数据类型字典来自于hash表构成的，hash的检索特别块，hash之后，key值对应的hash值会指向一个具体value地址，也就是为啥我们通过key值访问value很快，就是因为hash表hash算法处理后的数据，不管之前有多么接近，之后绝对是唯一的，所以需要，key值是一个不能变的字典也算的上是个无序的数据类型，在python3.6 字典有序了字典： &#123; key: value &#125; key： 1：hash运算key创建出hash表 2：hash表的查询速度很快 3：字典，他是不可以做索引，切片 4：key值必须是一个不可变数据对象：数字，字符串，元组， 5：key值必须是一个唯一的 value： 1：可以存储不同的数据类型 2：多个key同时对应一个value &#123;1:'a' , 2: 'a'&#125;访问字典： mydict[key] mydict.keys() 获取字典中所有的key值 mydict.values() 获取字典中所有的value值更新字典： mydict[key]=value 如果key存在的话，就更新value，如果key不存在的话就创建一个先的key:value的值删除字典： del mydict[key] 直接删除key值 mydict.pop() 在删除key值得过程中，还会把value值返回 mydict.clear() 清空字典 del mydict 直接删除字典mydict.get(key) 此命令在key存在的时候返回对应的value，若key不存在，返回空，不报错集合123456789101112131415161718192021222324252627282930313233343536373839404142434445464748可变集合：myset=set()不可变集合：myset=frozenset()做爬虫的时候使用集合保存爬取的URL，可以处理重复的连接集合中的数据没有前后关系，而且是无序的，不能使用for循环来遍历集合的特性： 1、集合是无序的，无法使用for来遍历,不可以索引和切片 2、集合的数据是去重的 3、集合不能存储可变数据对象，因为可变数据对象无法进行hash运算 4、集合中的所有数据元素都要经过hash运算，会维护hash表 5、一个空集合只能通过set()的方式来创建 myset=&#123;&#125;这个创建的是一个字典 6、没有value的字典就是集合 7、普通集合是可变的，不可变集合是frozenset(序列)更新集合： set.add(不可变数据类型) 如果这个类型是不可变序列，这个序列会原样加进集合中 set.update(数据集str,list,tuple,dict,set) 数据集将拆分成单个的元素，去掉重复的，然后加入到集合中 数据集不允许含有可变数据对象 数据集：str,list,tuple,dict(key值作为集合中的数据)，set,frozenset可变集合---删除集合 set.remove(集合中的数据元素) 删除后没有任何返回 set.pop() 不接收任何参数，随机删除，并返回被删除的元素 del myset 直接删除这个变量可变集合和不可变集合都只能通过for循环迭代访问可用in 和 not in 判断元素是否在集合中可以用in和not in去获取一个数据集中是否有某个元素 字符串，元组，列表，字典，集合 in是去判断数据库里读取的数据集更新集合： myset.add(seq) 直接修改集合本身，会保留和维护数据的形态到集合中 myset.update(seq) 直接修改集合本身，会将数据拆分去重后加入到集合中 并且update不接收一个不可拆分的数据，比如整数 update也可以接收一个列表删除集合: myset.pop() 随机删除并返回删除的值 myset.remove(obj) 在集合中删除obj,删除一个不存在的值会报错 myset.discard(obj) 在集合中删除obj,删除一个不存在的值不会报错 del myset 直接把集合删除了，集合的引用计数减去1集合的运算 a的元素b都有 子集：a.issubset(b) a是b的子集 超集：b.isuperset(b) b是a的超集 交集(&amp;)：a和b中共同含有的数据，去重后返回的新的集合就a和b的交集 并集(|)：a和b两个集合所有元素放到一起，去掉重复返回的新的集合就是a和b的交集 差集(-)：a-b 从a中去掉a和b共有的，也就是b中有的a都不要了，返回一个新德集合 对称差分(^)：找出两个集合中各自单独有的数据，也就是a和b的交集减去并集的数据系统内置函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162enumerate(iter):接受一个可迭代的对象作为参数，返回一个enumerate对象， 也是一个迭代器，该对象生成由iter每个元素的index值和item值len(seq):返回seq长度max(iter,key=None) or max(arg0,arg1...key=None): 返回iter或(arg0,arg1)中的最大值，如果指定了key， 这个key必须是可以传给sort()方法的，用于比较回调的函数min(iter,key=None) or min(arg0,arg1...key=None): 返回iter或(arg0,arg1)中的最大值，如果指定了key， 这个key必须是可以传给sort()方法的，用于比较回调的函数 &gt;&gt;&gt; max('a123','b123',key=lambda x:x[2]) &gt;&gt;&gt; 'a123'max函数之后的lambda表达式，在指定出元素之后， 会按照你选择的元素来排序，x[2]就是x的第二个元素进行排序reversed(seq):接受一个序列作为参数，返回一个以逆序访问的迭代器sorted(iter,cmp=None,key=None): 接受一个可迭代的对象作为参数，返回一个有序的列表，可选参数是一个排序方式sum(seq,init=0):返回seq和可选参数init的总和zip(it0,it1,...itN):返回一个列表，用法如下： 可以将对应的序列 对应的索引位置 拼接成一个二元组或者多元组 如果序列长度不一，以短的为主。 zip函数返回的是一个抽象的数据，保证内存安全，实现了迭代器(可以延迟生产数据) &gt;&gt;&gt; a=zip('123','abcdef','ABC') &lt;zip object at 0x000001E28964C848&gt; &gt;&gt;&gt; for i in a: ... print(i) ... ('1', 'a','A') ('2', 'b','B') ('3', 'c','C')map(func,seq):map函数第一个参数可以是一个函数对象，第二个是一个序列 map函数可以传入的函数依次作用在序列的每一个元素上。 实例： &gt;&gt;&gt; def ys(x): ... return x*x+1 &gt;&gt;&gt; mylist=[1,2,3,4,5] &gt;&gt;&gt; yes=map(ys,mylist) &gt;&gt;&gt; for i in yes: ... print(i) 2 5 10 17 26reduce函数(导入reduce函数 from functools import reduce) 用法：reduce把一个函数作用在一个序列[x1,x2,x3...]上，这个函数必须接收两个参数 reduce把结果继续和序列的下一个元素左累积计算，效果如下： &gt;&gt;&gt; def add(x,y): ... return x+y &gt;&gt;&gt; from functools import reduce &gt;&gt;&gt; mylist=[1,2,3,4,5] &gt;&gt;&gt; reduce(add,mylist) 15 &gt;&gt;&gt; def cf(x,y): ... return x*y+1 &gt;&gt;&gt; reduce(cf,mylist) 120eval(字符串对象) -&gt; 一般不要用 会把无意义的字符串变成了合法的表达式 表达式 一个有效的可以得出结果的式子repr(表达式) 将一个表达式变成无意义的字符串str内置函数1234567891011121314151617181920212223242526字符串内建函数--大小写转换函数 string.lower():字母大写转换为小写 string.upper():字母小写转换为大写 string.swapcase():字母大写转换为小写,小写转大写 string.title():将语句中所有单词的首字母大写 string.capitalize():将语句中首字母大写，其他小写字符串内建函数--搜索函数 string.find(str,[start=0,stop=len(string)]) 计算string中出现str的第一个字母的索引，如果没有出现，则返回-1 string.index(str,[start=0,stop=len(string)]) 计算string中出现str的第一个字母的索引，如果没有出现，出现异常 string.count(str,[start=0,stop=len(string)]): 计算str在string中出现的次数 string.endswith(str,[start=0,stop=len(string)]) 检查sring是否是以str结尾，如果是返回True，反之返回False字符串内建函数--替换函数 string.replace(str1,str2,[num=string.count(str1)]) 将str1替换为str2，num为替换次数，默认次数为str1出现的次数 string.strip(chr):在string的开头和结尾删除chr，当chr为空时，默认删除空白符(\r,\n,\t," ") string.rstrip():删除string字符串末尾的空格，或者换行符号 string.lstrip():删除string字符串开头的空格，或者换行符号字符串内建函数--判断函数 string.isdigit():如果string只包含数字，则返回True，否则返回False string.islower():如果字符串中的字母都是小写则返回True，否则返回False string.isupper():如果字符串中的字母都是大写则返回True，否则返回False string.isspace():字符串中只包含空白字符，返回True，否则返回False列表内置函数12345678list.append(obj):在尾部追加objlist.count():返回一个对象在列表中出现的次数list.extend(seq):把序列seq中的内容添加到列表中&gt;&gt;&gt; mylist.extend('abc')&gt;&gt;&gt; [1, 2, 3, 'a', 'b', 'c']list.insert(index,obj):在索引index的位置插入obj，原位置数据向后移动list.pop(index):删除并返回index位置的数据对象，默认是最后一个对象list.reverse():反转列表元组内置函数12tuple.index(obj,beg=0,end=len(string)):检查obj是否包含在tuple中tuple.count(obj):返回obj出现的次数推导式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374推导式： 一种方便的结合for循环进行数据处理的方式 for循环 -&gt; 序列中一个个的取值列表推导式 [ 表达式 for var in iterable if 过滤条件 ] 1：for循环从iterable取值 2：取到的值首先要经过if条件判断 3：判断条件成立的数据，放到表达式运算，运算后的结果，作为新列表中的值集合推导式 &#123; key for var in iterable if 过滤条件 &#125;字典推导式 &#123; key:value for var in iterable if 过滤条件 &#125;元组推导式 == 迭代器 ( key for var in iterable if 过滤条件 ) -&gt; iter 列表表达式： [ 表达式 for value in 序列 if 过滤条件 ]元组表达式： ( 表达式 for value in 序列 if 过滤条件 ) 所有从这个for循环出来的每一个数据首先会经过if条件过滤，然后执行前面的表达式， 最后重新返回成一个新的列表，过滤条件可有可无 &gt;&gt;&gt; mylist=[1,2,3,4] &gt;&gt;&gt; [var*var for var in mylist if var!=3] [1, 4, 16] &gt;&gt;&gt; (var*var for var in mylist if var!=3) &lt;generator object &lt;genexpr&gt; at 0x00000238D160B3B8&gt; &gt;&gt;&gt; my_tuple=(var*var for var in mylist if var!=3) &gt;&gt;&gt; for i in my_tuple: ... print(i) ... 1 4 16 &gt;&gt;&gt; my_tuple=(var*var for var in mylist if var!=3) &gt;&gt;&gt; my_tuple.__next__() 1 &gt;&gt;&gt; my_tuple.__next__() 4 &gt;&gt;&gt; my_tuple.__next__() 16 &gt;&gt;&gt; my_tuple.__next__() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; StopIteration 通过列表推导式就可以把我们含有大小写的列表改成全部大写的列表 我们生成出所有经过表达式的一个结果序列，并且是列表类型的 元组表达式就是生成器，只有在使用到的时候才生成，比较节约内存字典推导式： 和列表类似，只不过需要两个值存在来维护字典的键值对形式 &#123;key:value for key in 序列 if 过滤条件&#125; enumerate(obj):这个函数会返回两个值，一个是序列的下标，一个是下标对应的值 &gt;&gt;&gt; mylist=['a','b','c','d'] &gt;&gt;&gt; mydict=&#123;key:value for key,value in enumerate(mylist)&#125; &gt;&gt;&gt; mydict &#123;0: 'a', 1: 'b', 2: 'c', 3: 'd'&#125; mydict = &#123;'初心':&#123;'money':100000,'sex':'male'&#125;,'Infor':&#123;'Money':110000,'sex':'male'&#125;&#125;#list(mydict[var].keys())[0]newdict = &#123;var:&#123;list(mydict[var].keys())[0]:mydict[var][list(mydict[var].keys())[0]]+1000&#125; for var in mydict&#125;print(newdict)集合推到式： 集合推导式跟列表推导式非常相似，唯一的区别在于用&#123;&#125;代替[] &#123;表达式 for value in 序列 if 过滤条件&#125; &gt;&gt;&gt; mylist ['a', 'b', 'c', 'd'] &gt;&gt;&gt; myset=&#123;var*2 for var in mylist&#125; &gt;&gt;&gt; myset &#123;'aa', 'bb', 'cc', 'dd'&#125;推到式：表达式 for var in 序列 if 过滤作业：2万以下的 加工资12345678910111213141516171819202122232425262728293031323334353637383940414243salary_list = [13000,12700,15000,14000,25000,16000,18000,22000,32000]#2万以下的 加工资#加1000new_list = []for var in salary_list: if var &lt;= 20000: var+=1000 new_list.append(var)print(new_list)res = [ var + 1000 for var in salary_list if var &lt;= 20000 ]salary_list[:len(res)] = resprint(res)#1: for循环取值#2: 经过if条件判断#3: 放到最前面，作为新列表的值 #if...else if如果不满足，那么执行else #for...else 可以循环正常结束的时候，for...else执行#把新的列表替换原来的列表元素**********************************************************************mylist = [13000,15000,15000,17000,20000,14500,23400,27000] #15000 + 2000 - &gt; 17000 #这个17000和后面的17000重复了，所以会替换多次，一个15000到最后多添加了好几次呢def replace(old,new): #不要因为数据相同而重复替换 要避免这个 #直接修改mylist 这个变量本身 global mylist #使用全局变量mylist及index_list global index_list for _index,var in enumerate(mylist): if var == old and _index not in index_list: #如果这个索引还没出现过，那么就替换 print('当前替换的是:',mylist[_index]) mylist[_index] = new index_list.append(_index) #替换完成，记录一下 print("--------------") #函数之行一次之后打印一次横线 #函数没有返回值，那么就返回None[replace(var,var+2000) for var in mylist if var &lt; 20000] #var : old #var + 2000 : newprint('new:',mylist)作业：做一个自己的帮助文档123456789101112131415161718192021222324252627282930313233343536373839404142def func(): ''' 这就是我的帮助文档 ''' #__doc__ 可以调取帮助文档help(func)print(func.__doc__)res = dir(str)help_dict = &#123;&#125;#帮助文档的列表for func in res: #提取每个函数 if '__' in func: #过滤下划线函数 continue help_dict[func] = func.__doc__ #把帮助文档追加到列表 #有则修改，没有则增加 #key: func 函数名字符串 #value: func.__doc__ 帮助文档for key in help_dict: print(key) #首先打印函数名 print(help_dict[key]) #在打印帮助文档 print('-------------------------')#Web GUI***************************************************************************************while True: print('退出请输入: q/Q\n') user_req = input('请输入查询序列类型(str/list/tuple/dict/set):\n') print() if user_req == 'q' or user_req == 'Q': break else: try: res = dir(eval(user_req)) print(res) print() search_req = input('请输入查询函数:\n') print() try: help(eval(user_req + '.' + search_req)) except AttributeError as first_reason: print('请重新输入!!!The reason: ',str(first_reason)) except NameError as second_reason: print("错啦,重新输入!!!The reason: ",str(second_reason))作业：每个爷们加1000工资12345678910111213141516171819202122mydict = &#123; 'KM': &#123;'sex':'male', '工作':'Star', 'money':13000,&#125;, 'Charles': &#123;'money':13000, '性别':'male', 'like':'DJ'&#125;, 'Mark Smith':&#123;'salary':13000, 'sex':'male', 'job':'Rap'&#125;, 'QQ': &#123;'money':15000, '性别':'female','job':'Dancer'&#125;&#125;#dict keys values dict[key] for key in dict#推导式实现一下，每个爷们加个1000#job要留下来,money要留下来def func(var): var = list(var) if 'male' in var:#先判断是否是个男的 for _index,value in enumerate(var): #判断是不是个数字 if type(value) == int: var[_index] = value + 1000 #数个数字 加1000 return tuple(var)new_dict = &#123; key:dict( zip( list( mydict[key].keys() ), func( mydict[key].values() ) ) ) for key in mydict &#125;#只有工资对应的value值是一个整数 intfor key in new_dict: print(key,':',new_dict[key])print("==================")作业：四色五入12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849a = 123.9443712837819float_index = 2 #我就要2位小数int_part = str(a).split('.')[0] #123 整数部分 strfloat_part = str(a).split('.')[-1] #90182039 小数部分 strprint("原有数据:",a)print('整数部分:',int_part)print('小数部分:',float_part)#字符串判断整数 直接对比值大小#字符串判断的是字母 那就是对比ascii码 a 97 A 65if len(float_part) &lt;= float_index: #判断小数长度与精度位数的大小 print("处理完成之后的小数:",a)else: if int(float_part[float_index]) &gt;= 5: #获取小数部分最后一位 print('小数部分最后一位:',float_part[float_index]) print('扔掉最后一位的结果:',float_part[:float_index]) float_part = str( int(float_part[:float_index]) + 1 ) print('最后的小数部分:',float_part) else: #如果说位数精度的数字小于5，不满足上位的条件，那么直接把后面的位省去 print('小数部分最后一位:',float_part[float_index]) print('扔掉最后一位的结果:',float_part[:float_index]) float_part = str( int(float_part[:float_index]) ) print('最后的小数部分:',float_part) res = float('.'.join( [int_part,float_part] )) #res = float(int_part + '.' + float_part) print('整数和小数拼接:',res)def func(var,f_index): ''' func(var,f_index) -&gt; float 这个函数用来做四舍五入的精度处理 参数： var是你传入的小数 f_index是你需要的精度 返回值： 处理后的小数 ''' int_part = str(var).split('.')[0] #123 整数部分 str float_part = str(var).split('.')[-1] #90182039 小数部分 st if len(float_part) &lt;= f_index: #判断小数长度与精度位数的大小 float_part = float_part.ljust(f_index,'0') #需要补位的长度 else: #如果需要来维护精度，本身的浮点数长度大于了精度要求 if int(float_part[f_index]) &gt;= 5: #获取小数部分最后一位 float_part = str( int(float_part[:f_index]) + 1 ) else: #如果说位数精度的数字小于5，不满足上位的条件，那么直接把后面的位省去 float_part = str( int(float_part[:f_index]) ) res = float('.'.join( [int_part,float_part] )) #res = float(int_part + '.' + float_part) return resres = func(1.2,5) #-&gt;1.124print(res)作业：人生12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# seq 序列: str list tuple set dict# iterable 可迭代的对象: str list tuple set dict 文件 数据库句柄 数据库返回结果集 生成器迭代器import random#baby -&gt; 小孩#babe、sweet、my cup of tea -&gt; 宝贝 #you are my cup of tea#random choice -&gt; a random element from a non-empty sequence.#choice(seq) method of random.Random instance #Choose a random element from a non-empty sequence. #从一个不为空的序列中去取一个值te = &#123; #个人信息 'name':'human', 'age':18, 'job':'tea', 'like':'study', 'babe':&#123;&#125;, #保存你的娃 #娃的名字，娃的性别&#125;sex_list = ['male','female'] #人的性别mind_list = ['不好','还行','非常好',' '] #情绪的列表，为了可以随机抽样选择things_list = ['normal','dangours','love','gay','moeny','babe']active_dict = &#123; #当你情绪不一样的时候，所要做的事情 '不好': 'play computer', #可以这样创建，但是后面的表达式 会实际的运行的 '还行': 'eat', '非常好' : '不上课了 我要到外面的世界', &#125;#字典不具体的来保存行为，他只是来保存我们要做的事情 #这个事情一定不要在定义字典的时候来实现#赋值语句是没有返回值的，直接修改的是对象本身for var in range(365 * 80): mind = random.choice(mind_list) #随机抽取今天的情绪 things = random.choice(things_list) #随机抽取时间 active = active_dict.get(mind) #执行今天这个心情我要做的事情 if things == 'babe': print('今天是第%d天,今天生了!' % var) print(' * ') print(' *** ') print(' ****** ') print(' ** ') print(' ** ') babe_name = 'babe' + str(var) #宝宝名字命名 babe_sex = random.choice(sex_list) te['babe'][babe_name] = babe_sex elif things == 'dangours': print('这是第%d天,今天GG了' % var) break else: #其他时候都是平平淡淡 if active: te['like'] = active print('今天是第%d天,今天我遇到了%s: 今天的心情%s, 我要做的事情%s' % (var, things, mind, te['like'] ))else: print('完美结束')print('----------人生总结----------')for key in te: print('%s:%s' % (key,te[key])) if key == 'babe': print("你还有孩子，在下面-------") for babe_name in te[key]: #拿到我的孩子列表 print('%s:%s' % (babe_name,te[key][babe_name]))#'rich':富有#'handsome':帅气]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python基础数据类型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kvm安装]]></title>
    <url>%2F2018%2F07%2F24%2F%E5%AE%89%E8%A3%85kvm%2F</url>
    <content type="text"><![CDATA[VMware虚机在启动之前开启CPU虚拟化1、安装桌面GUIyum groupinstall &quot;GNOME Desktop&quot; &quot;Graphical Administration Tools&quot; 2、安装kvmyum -y install libcanberra-gtk2 qemu-kvm.x86_64 qemu-kvm-tools.x86_64 libvirt.x86_64 libvirt-cim.x86_64 libvirt-client.x86_64 libvirt-java.noarch libvirt-python.x86_64 libiscsi-1.7.0-5.el6.x86_64 dbus-devel virt-clone tunctl virt-manager libvirt libvirt-python python-virtinst 查看kvm模块是否已经安装成功3、安装桥接网络，并设置/yum -y install bridge-utils设置完成后重启网络，并查看网络[root@localhost network-scripts]# brctl show bridge name bridge id STP enabled interfaces br0 8000.000c29c12e49 yes ens37 virbr0 8000.525400c9ff4e yes virbr0-nic 4、重启libvirt,设置开机自启动systemctl start libvirtd systemctl enable libvirtd 5、使用virt-manager图形化来管理kvm虚机之后就是正常安装系统的步骤]]></content>
      <categories>
        <category>kvm</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mongodb的优缺点]]></title>
    <url>%2F2018%2F07%2F24%2Fmongodb%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[mongodb的优缺点对比mysql, mongo的优缺点有：缺点不支持事务操作占用空间过大MongoDB没有如MySQL那样成熟的维护工具无法进行关联表查询，不适用于关系多的数据复杂聚合操作通过mapreduce创建，速度慢模式自由， 自由灵活的文件存储格式带来的数据错误预分配模式带来的磁盘瓶颈。mongodb采用数据文件预分配模式来生成数据文件，数据文件的大小从64M开始，每增加一个文件，大小翻倍，直到2G，以后每次增加数据就会生成2G左右的数据文件，结合mongodb的mmap内存模型，对于写数据文件，将随机写转换为顺序写，一定程度上缓解了磁盘的io压力。但在实际使用中，遇到了在预分配2G的数据文件时，如果磁盘io较慢，则mongodb基本锁死，无法响应请求的情况。持续时间则根据磁盘io的性能来确定。这个问题在2.0之后版本可能会有些改善，但在磁盘性能低的服务器上，该问题依旧存在.这个问题目前没有太好的解决方案，只能建议使用读写性能比较好的服务器来跑mongodb。在数据存量大于内存大小时，mongodb遇到冷数据查询速度变慢。mongodb使用mmap的内存管理模式，如果查询的都是热数据，那么会在内存中直接查询，如果遇到冷数据，就需要从磁盘读取，并将一部分热数据从内存卸载掉.有人曾经说mongodb内存管理是加载固定大小的文件块到内存，即如果冷数据在磁盘上，他会根据请求的数据，加载一定大小的数据块到内存，并卸载掉同样的热数据，这个操作本身会带来一定io.因为mongodb使用的是全局锁，在某个操作缓慢时，整个操作队列会全部变慢。这个问题造成了mongodb会出现偶发性堵塞问题，连带整个库的性能下降。该问题在应用需要尽量避免出现，需要将mongodb的数据大小规划好，尽量不要使数据量超过内存的大小，如果超过内存大小后，尽量不要去请求冷数据。Mongodb全局锁机制。mongodb最大的问题或者可以说是它的锁机制，在2.2版本之前，一个实例只有一个读写锁，不管有多少数据库和数据集合，当一个操作进行时其他操作只能等待，在2.2版本后，mongodb锁降低了粒度，改为按库锁。MongoDB 使用的是“readers-writer”锁， 可以支持并发但有很大的局限性，当一个读锁存在,许多读操作可以使用这把锁，然而, 当一个写锁的存在，一个单一的写操作会exclusively 持有该锁，同时其它读，写操作不能使用共享这个锁；举个例子，假设一个集合里有 10 个文档，多个 update 操作不能并发在这个集合上，即使是更新不同的文档。删除数据集合后空间不会自动释放mongodb删除集合后磁盘空间不释放，只有用db.repairDatabase()去修复才能释放。修复可能要花费很长的时间,在使用db.repairDatabase()去修复时一定要停掉读写，并且mongodb要有备机才可以，不然千万不要随便使用db.repairDatabase()来修复数据库，切记。但是在修复的过程中如果出现了非正常的mongodb的挂掉，再次启动时启动不了的，需要先修复才可以，可以利用./mongod –repair –dbpath=/data/mongo/如果你是把数据库单独的放在一个文件夹中指定dbpath时就指向要修复的数据库就可以。###replica set一些隐含问题 ###replica set模式最多支持12台服务器，而有投票权的服务器只支持7台，如果超过7台服务器，需设置部分服务器为无投票权服务器replica set模式中，一个set服务器如果小于2台服务器，则自动故障恢复不会起作用，如果4台服务器出现2/2互相ping不通的情况，同样不会自动故障恢复。一般来说，一个set中尽量是有单数服务器。replica set中，因为mongodb是按照时间进行操作，如果set中某个服务器时间超前或者延迟，很容易出现secondaries不断尝试更新oplog或者同步延迟的问题。甚至造成某些操作失败，如drop操作。###分片模式的一些隐含问题 ###config server尽量按照官方的要求，有3个configserver，如果只有2个configserver，则shard的自动负载均衡和自动切片功能不可用。api中的nearest模式在shard中，判断的是set到mongos的距离而非set到client的距离，在切片模式下，尽量不要使用nearest模式，可能会造成一些请求延迟增加的问题。优点文档结构的存储方式，能够更便捷的获取数据内置GridFS，支持大容量的存储内置Sharding，分片简单海量数据下，性能优越支持自动故障恢复（复制集）mongodb是一个介于nosql数据库和mysql数据库之间的一个数据存储系统，它没有严格的数据格式，但同时支持复杂查询，而且自带sharding模式和Replica Set模式，支持分片模式，复制模式，自动故障处理，自动故障转移，自动扩容，全内容索引，动态查询等功能。扩展性和功能都比较强大。mongodb在数据查询方面，支持类sql查询，可以一个key多value内容，可以组合多个value内容来查询，支持索引，支持联合索引，支持复杂查询 ，支持排序，基本上除了join和事务类型的操作外，mongodb支持所有mysql支持的查询，甚至某个客户端api支持直接使用sql语句查询mongodb。mongodb的sharding功能目前日渐完善，支持自定义范围分片，hash自动分片等，分片自动扩容，shard之间自动负载均衡等功能。实际使用中功能还不错。]]></content>
      <categories>
        <category>mongo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mongo安装和使用]]></title>
    <url>%2F2018%2F07%2F24%2FMongo%E5%AE%89%E8%A3%85%E5%8F%8A%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%2F</url>
    <content type="text"><![CDATA[mongo安装和使用#安装mongo参考文档：https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/yum安装，先获取repo源[mongodb-enterprise] name=MongoDB Enterprise Repository baseurl=https://repo.mongodb.com/yum/redhat/$releasever/mongodb-enterprise/3.6/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc sudo yum install -y mongodb-enterprise #安装最新mongo，默认会依赖安装下面的包mongodb-enterprise, mongodb-enterprise-server, mongodb-enterprise-shell, mongodb-enterprise-mongos, mongodb-enterprise-tools 安装指定版本使用下面命令yum install -y mongodb-enterprise-3.6.5 mongodb-enterprise-server-3.6.5 mongodb-enterprise-shell-3.6.5 mongodb-enterprise-mongos-3.6.5 mongodb-enterprise-tools-3.6.5 启动使用systemctl start mongod service mongod start/stop/restart chkconfig mongod on mongo --host 127.0.0.1:27017 数据目录日志：/var/log/mongodb 数据：/var/lig/mongo 使用resource安装获取Mongo的安装包：curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.6.tgz tar -xf mongodb-linux-x86_64-3.4.6.tgz mv mongodb-3.4.6 /usr/local/mongodb cd /usr/local/mongodb 手动创建db和log目录 mkdir -p /data/db mkdir /data/log touch /data/log/mongodb.log 启动mongo./bin/mongod --dbpath /data/db --logpath /data/log/mongodb.log --fork --port 27017 --dbpath 数据存储目录 --logpath mongo运行日志记录 --fork 是后台运行 --port 是运行的端口（默认是27017） 出现如上图的字样就说明启动成功了进入数据库./bin/mongo mongodb数据简介mongodb是一个介于nosql数据库和mysql数据库之间的一个数据存储系统，它没有严格的数据格式， 但同时支持复杂查询，而且自带sharding模式和Replica Set模式，支持分片模式，复制模式， 自动故障处理，自动故障转移，自动扩容，全内容索引，动态查询等功能。扩展性和功能都比较强大。 mongodb在数据查询方面，支持类sql查询，可以一个key多value内容，可以组合多个value内容来查询， 支持索引，支持联合索引，支持复杂查询 ，支持排序，基本上除了join和事务类型的操作外， mongodb支持所有mysql支持的查询，甚至某个客户端api支持直接使用sql语句查询mongodb。 mongodb的sharding功能目前日渐完善，支持自定义范围分片，hash自动分片等，分片自动扩容， shard之间自动负载均衡等功能。实际使用中功能还不错。 mongodb 文档数据库,存储的是文档(Bson-&gt;json的二进制化). 特点:内部执行引擎为JS解释器, 把文档存储成bson结构,在查询时,转换为JS对象,并可以通过熟悉的js语法来操作. mongo和传统型数据库相比,最大的不同: 传统型数据库: 结构化数据, 定好了表结构后,每一行的内容,必是符合表结构的,就是说--列的个数,类型都一样. mongo文档型数据库: 表下的每篇文档,都可以有自己独特的结构(json对象都可以有自己独特的属性和值) 安装目录下，bin下脚本作用##mongo数据库的用户验证##超级账号创建&gt; db.createUser(… … {… … user:”admin”,… … pwd:”admin123”,… … roles:[ { role:”userAdminAnyDatabase”,db:”admin”}]… … } )创建完成后，修改mongo启动的配置文件，加入auth=on dbpath=/data/db logpath=/data/log/mongodb.conf port=27017 auth=on fork=true logappend=true 杀死mongo的所有进程， pkill -9 mongo 重新启动mongod(server) [root@www1 mongodb]# ~/bin/mongod -f conf/mongodb.conf about to fork child process, waiting until server is ready for connections. forked process: 18135 child process started successfully, parent exiting [root@www1 mongodb]# ./bin/mongo 启动mongo(client) &gt; show dbs 2018-06-24T21:47:19.974+0800 E QUERY [thread1] Error: listDatabases failed:{ &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not authorized on admin to execute command { listDatabases: 1.0, $db: \&quot;admin\&quot; }&quot;, &quot;code&quot; : 13, &quot;codeName&quot; : &quot;Unauthorized&quot; } : 这时无法show dbs就没有权限查看数据库了，需要使用admin来验证登陆 &gt; db.auth(&apos;admin&apos;,&apos;admin123&apos;) 1 返回1表示已经验证成功 &gt; show dbs admin 0.000GB config 0.000GB data 0.000GB local 0.000GB 此时admin验证成功，但是每个数据库此时会要有自己的认证用户 若要查看某一个数据库的数据，还要使用admin超管为每个数据库创建账号，并认证登陆 需要注意的是在建立data数据库用户的时候一定要先启用data数据库，否则会出现问题 &gt;use data &gt;db.createUser({user:&apos;u1&apos;,pwd:&apos;123qwe&apos;,roles:[{role:&apos;readWrite&apos;,db:&apos;data&apos;}]}) &gt; db.auth(&apos;u1&apos;,&apos;123qwe&apos;) 1 &gt; show collections stu 超管密码忘记，更改密码步骤：1、更改配置文件，将auth=true注释掉，或者true改为false2、重启mongopkill -9 mongo ./bin/mongod -f conf/mongodb.conf ./bin/mongo &gt;use admin &gt; db.system.users.find() #查找admin用户 &gt; db.system.users.remove({&apos;_id&apos;:&apos;data.admin&apos;}) #根据id将admin用户删除，然后重新建admin &gt; &gt; db.createUser( ... ... { ... ... user:&quot;admin&quot;, ... ... pwd:&quot;admin123&quot;, ... ... roles:[ { role:&quot;userAdminAnyDatabase&quot;,db:&quot;admin&quot;}] ... ... } ) db.createUser({ user:&quot;admin&quot;,pwd:&quot;admin123&quot;, roles:[{role:&quot;userAdminAnyDatabase&quot;,db:&quot;admin&quot;}]}) 3、再次kill掉mongo，将auth改为true后进行重启mongo数据库RoleBuilt-In Roles（内置角色）： 1. 数据库用户角色：read、readWrite; 2. 数据库管理角色：dbAdmin、dbOwner、userAdmin； 3. 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager； 4. 备份恢复角色：backup、restore； 5. 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase 6. 超级用户角色：root // 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase） 7. 内部角色：__system Read：允许用户读取指定数据库 readWrite：允许用户读写指定数据库 dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile userAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户 clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。 readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限 readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限 userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限 dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。 root：只在admin数据库中可用。超级账号，超级权限 userAdminAnyDatabase 权限只是针对用户管理的，对其他是没有权限的。 mongodump --port=27020 -uzjyr -pzjyr --db=test -o backup #只要读权限就可以备份 mongorestore --port=27020 -uzjy -pzjy --db=test backup/test/ #读写权限可以进行还原 更新用户密码 use xx db.changeUserPassword(&quot;username&quot;,&quot;newpassword&quot;) 删除用户 切换到用户授权的db use xx 执行删除操作 db.dropUser(&quot;username&quot;) 更新用户 切换到用户授权的db use xx 执行更新 字段会覆盖原来的内容 db.updateUser(&quot;username&quot;,{ pwd:&quot;new password&quot;, customData:{ &quot;title&quot;:&quot;PHP developer&quot; } }) 查看角色信息 use admin db.getRole(&quot;rolename&quot;,{showPrivileges:true}) 删除角色 use admin db.dropRole(&quot;rolename&quot;)更新用户密码 查看用户信息 use admin db.getUser(&quot;username&quot;)]]></content>
      <categories>
        <category>mongo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mongo常用操作]]></title>
    <url>%2F2018%2F07%2F24%2Fmongo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[mongo常用操作参考文档：https://www.jb51.net/article/48217.htmhelphelp db.help(); db.yourColl.help(); db.youColl.find().help(); rs.help(); 数据库的操作# 查看数据库 show dbs # 切换数据库 use mydatabase # 删除当前数据库 db.dropDatabase() #进入需要删除的数据库下执行此命令 #克隆数据库 db.cloneDatabase(“127.0.0.1”); 将指定机器上的数据库的数据克隆到当前数据库 db.copyDatabase(&quot;mydb&quot;, &quot;temp&quot;, &quot;127.0.0.1&quot;);将本机的mydb的数据复制到temp数据库中 db.repairDatabase(); 修复当前数据库 #获取当前数据库的状态 db.getName(); db; db和getName方法是一样的效果，都可以查询当前使用的数据库 db.stats(); 显示当前db状态 db.version(); 当前db版本 db.getMongo(); 查看当前db的链接机器地址 集合操作 Collection聚集集合# 查看集合 show collections # 删除集合 db.users.drop() #创建一个聚集集合（table） db.createCollection(“collName”, {size: 20, capped: 5, max: 100});//创建成功会显示{“ok”:1} //判断集合是否为定容量db.collName.isCapped(); # 得到指定名称的聚集集合（table） db.getCollection(&quot;account&quot;); # 得到当前db的所有聚集集合 db.getCollectionNames(); #显示当前db所有聚集索引的状态 db.printCollectionStats(); 文档操作插入文档 db.users.insert({ name:&apos;harttle&apos;, url:&apos;http://harttle.com&apos; }) 查询文档 # 查询所有 db.users.find() # 条件查询 db.users.find({ name:&apos;harttle&apos; }) # 有缩进的输出 db.users.find().pretty() 更新文档 db.users.update({ name:&apos;harttle&apos; }, { url:&apos;http://harttle.com&apos; }) 删除文档 # 删除所有 db.users.remove({}) # 条件删除 db.users.remove({ url:&apos;http://harttle.com&apos; }) ##用户操作### 添加一个用户 db.addUser(&quot;name&quot;); db.addUser(&quot;userName&quot;, &quot;pwd123&quot;, true); 添加用户、设置密码、是否只读 # 数据库认证、安全模式 db.auth(&quot;userName&quot;, &quot;123123&quot;); # 显示当前所有用户 show users; # 删除用户 db.removeUser(&quot;userName&quot;); ##查询操作### 去掉查询结果显示id #查询所有记录 db.userInfo.find(); # 相当于：select* from userInfo; # 查询去掉后的当前聚集集合中的某列的重复数据 db.userInfo.distinct(&quot;name&quot;); 会过滤掉name中的相同数据 # 查询age = 22的记录 db.userInfo.find({&quot;age&quot;: 22}); # 查询age &gt; 22的记录 db.userInfo.find({age: {$gt: 22}}); # 查询age &lt; 22的记录 db.userInfo.find({age: {$lt: 22}}); # 查询age &gt;= 25的记录 db.userInfo.find({age: {$gte: 25}}); # 查询age &lt;= 25的记录 db.userInfo.find({age: {$lte: 25}}); # 查询age &gt;= 23 并且 age &lt;= 26 db.userInfo.find({age: {$gte: 23, $lte: 26}}); # 查询name中包含 mongo的数据 db.userInfo.find({name: /mongo/}); # 查询name中以mongo开头的 db.userInfo.find({name: /^mongo/}); # 查询指定列name、age数据 db.userInfo.find({}, {name: 1, age: 1}); # 查询指定列name、age数据, age &gt; 25 db.userInfo.find({age: {$gt: 25}}, {name: 1, age: 1}); # 按照年龄排序 升序：db.userInfo.find().sort({age: 1}); 降序：db.userInfo.find().sort({age: -1}); # 查询name = zhangsan, age = 22的数据 db.userInfo.find({name: &apos;zhangsan&apos;, age: 22}); # 查询前5条数据 db.userInfo.find().limit(5); # 查询10条以后的数据 db.userInfo.find().skip(10); # 查询在5-10之间的数据 db.userInfo.find().limit(10).skip(5); 可用于分页，limit是pageSize，skip是第几页*pageSize # or与 查询 db.userInfo.find({$or: [{age: 22}, {age: 25}]}); # 查询第一条数据 db.userInfo.findOne(); # 查询某个结果集的记录条数 db.userInfo.find({age: {$gte: 25}}).count(); # 按照某列进行排序 db.userInfo.find({sex: {$exists: true}}).count(); ##索引### 创建索引 db.userInfo.ensureIndex({name: 1}); db.userInfo.ensureIndex({name: 1, ts: -1}); # 查询当前聚集集合所有索引 db.userInfo.getIndexes(); # 查看总索引记录大小 db.userInfo.totalIndexSize(); # 读取当前集合的所有index信息 db.users.reIndex(); # 删除指定索引 db.users.dropIndex(&quot;name_1&quot;); # 删除所有索引索引 db.users.dropIndexes(); ##修改、添加、删除集合数据### 添加 db.users.save({name: ‘zhangsan&apos;, age: 25, sex: true}); # 修改 db.users.update({age: 25}, {$set: {name: &apos;changeName&apos;}}, false, true); 相当于：update users set name = ‘changeName&apos; where age = 25; db.users.update({name: &apos;Lisi&apos;}, {$inc: {age: 50}}, false, true); 相当于：update users set age = age + 50 where name = ‘Lisi&apos;; db.users.update({name: &apos;Lisi&apos;}, {$inc: {age: 50}, $set: {name: &apos;hoho&apos;}}, false, true); 相当于：update users set age = age + 50, name = ‘hoho&apos; where name = ‘Lisi&apos;; # 删除 db.users.remove({age: 132}); # 查询修改删除 db.users.findAndModify({ query: {age: {$gte: 25}}, #query 查询过滤条件 {} sort: {age: -1}, #如果多个文档符合查询过滤条件，将以该参数指定的排列方式选择出排在首位的对象 update: {$set: {name: &apos;a2&apos;}, $inc: {age: 2}}, remove: true #若为true，被选中对象将在返回前被删除 }); db.runCommand({ findandmodify : &quot;users&quot;, query: {age: {$gte: 25}}, sort: {age: -1}, update: {$set: {name: &apos;a2&apos;}, $inc: {age: 2}}, remove: true }); #update 或 remove 其中一个是必须的参数; 其他参数可选。 ##语句块操作### 简单Hello World print(&quot;Hello World!&quot;); # 将一个对象转换成json tojson(new Object()); tojson(new Object(&apos;a&apos;)); # 循环添加数据 &gt; for (var i = 0; i &lt; 30; i++) { ... db.users.save({name: &quot;u_&quot; + i, age: 22 + i, sex: i % 2}); ... }; &gt; for (var i = 0; i &lt; 30; i++) db.users.save({name: &quot;u_&quot; + i, age: 22 + i, sex: i % 2}); # find 游标查询 &gt;var cursor = db.users.find(); &gt; while (cursor.hasNext()) { printjson(cursor.next()); } # forEach迭代循环 db.users.find().forEach(printjson); # forEach中必须传递一个函数来处理每条迭代的数据信息 db.things.find({x:4}).forEach(function(x) {print(tojson(x));}); # forEach传递函数显示信息 # 将find游标当数组处理 var cursor = db.users.find(); cursor[4]; # 取得下标索引为4的那条数据 # 既然可以当做数组处理，那么就可以获得它的长度：cursor.length();或者cursor.count(); # 那样我们也可以用循环显示数据 for (var i = 0, len = c.length(); i &lt; len; i++) printjson(c[i]); # 将find游标转换成数组 &gt; var arr = db.users.find().toArray(); # 用toArray方法将其转换为数组 &gt; printjson(arr[2]); # 定制我们自己的查询结果，只显示age &lt;= 28的并且只显示age这列数据 db.users.find({age: {$lte: 28}}, {age: 1}).forEach(printjson); db.users.find({age: {$lte: 28}}, {age: true}).forEach(printjson); db.users.find({age: {$lte: 28}}, {age: false}).forEach(printjson); #排除age序列 ##其他 ### 查询之前的错误信息 db.getPrevError(); # 清除错误记录 db.resetError(); 查看聚集集合基本信息 1、查看帮助 db.yourColl.help(); 2、查询当前集合的数据条数 db.yourColl.count(); 3、查看数据空间大小 db.userInfo.dataSize(); 4、得到当前聚集集合所在的db db.userInfo.getDB(); 5、得到当前聚集的状态 db.userInfo.stats(); 6、得到聚集集合总大小 db.userInfo.totalSize(); 7、聚集集合储存空间大小 db.userInfo.storageSize(); 8、Shard版本信息 db.userInfo.getShardVersion() 9、聚集集合重命名 db.userInfo.renameCollection(&quot;users&quot;); 将userInfo重命名为users 10、删除当前聚集集合 db.userInfo.drop(); show dbs:显示数据库列表 show collections：显示当前数据库中的集合（类似关系数据库中的表） show users：显示用户 use &lt;db name&gt;：切换当前数据库，这和MS-SQL里面的意思一样 db.help()：显示数据库操作命令，里面有很多的命令 db.foo.help()：显示集合操作命令，同样有很多的命令，foo指的是当前数据库下，一个叫foo的集合，并非真正意义上的命令 db.foo.find()：对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据） db.foo.find( { a : 1 } )：对于当前数据库中的foo集合进行查找，条件是数据中有一个属性叫a，且a的值为1]]></content>
      <categories>
        <category>mongo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mongodump与mongorestore]]></title>
    <url>%2F2018%2F07%2F24%2Fmongo%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[MongoDB 备份(mongodump)与恢复(mongorestore)mongoexport/mongoimport导入/导出的是JSON格式，而mongodump/mongorestore导入/导出的是BSON格式。JSON可读性强但体积较大，BSON则是二进制文件，体积小但对人类几乎没有可读性。在一些mongodb版本之间，BSON格式可能会随版本不同而有所不同，所以不同版本之间用mongodump/mongorestore可能不会成功，具体要看版本之间的兼容性。当无法使用BSON进行跨版本的数据迁移的时候，使用JSON格式即mongoexport/mongoimport是一个可选项。跨版本的mongodump/mongorestore个人并不推荐，实在要做请先检查文档看两个版本是否兼容（大部分时候是的）。JSON虽然具有较好的跨版本通用性，但其只保留了数据部分，不保留索引，账户等其他基础信息。使用时应该注意。mongodump命令脚本语法如下：&gt;mongodump -h dbhost -d dbname -o dbdirectory -h： MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d： 需要备份的数据库实例，例如：test -o： 备份的数据存放位置，例如：c:\data\dump，当然该目录需要提前建立，在备份完成后， 系统自动在dump目录下建立一个test目录，这个目录里面存放该数据库实例的备份数据。 mongodump –host HOST_NAME –port PORT_NUMBER 该命令将备份所有MongoDB数据mongodump –host runoob.com –port 27017[root@www1 mongodb]# mongodump -h localhost -u u1 -p 123qwe -d data -o data_mongo.tarmongodump –dbpath DB_PATH –out BACKUP_DIRECTORYmongodump –dbpath /data/db/ –out /data/backup/mongodump –collection COLLECTION –db DB_NAME 该命令将备份指定数据库的集合。mongodump –collection mycol –db testmongorestoremogorestore命令脚本语法如下：&gt;mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt; --host &lt;:port&gt;, -h &lt;:port&gt;： MongoDB所在服务器地址，默认为： localhost:27017 --db , -d ： 需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2 --drop： 恢复的时候，先删除当前数据，然后恢复备份的数据。就是说，恢复后，备份后添加修改的数据都会被删除，慎用哦！ path： mongorestore 最后的一个参数，设置备份数据所在位置，例如：c:\data\dump\test。 你不能同时指定 &lt;path&gt; 和 --dir 选项，--dir也可以设置备份目录。 --dir： 指定备份的目录 你不能同时指定 &lt;path&gt; 和 --dir 选项。 mongoexport参数 -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 -c:指明collection的名字 -f:指明要导出那些列 -o:指明到要导出的文件名 -q:指明导出数据的过滤条件 root@mongo:~/cas.mongo# mongorestore -h mongo:27017 -uadmin -pPassw0rd -d admin admin root@mongo:~/cas.mongo# mongorestore -h mongo:27017 -ucas -pPassw0rd -d cas cas [root@localhost mongodb]# ./bin/mongoexport -d test -c students -o students.dat -d:指明使用的库，本例中为test -c:指明要导出的集合，本例中为students -o:指明要导出的文件名，本例中为students.dat ./bin/mongoexport -d test -c students --csv -f classid,name,age -o students_csv.dat -csv：指明要导出为csv格式 -f：指明需要导出classid、name、age这3列的数据 mongoimport参数 -h:指明数据库宿主机的IP -u:指明数据库的用户名 -p:指明数据库的密码 -d:指明数据库的名字 -c:指明collection的名字 -f:指明要导入那些列 ./bin/mongoimport -d test -c students students.dat 参数说明： -d:指明数据库名，本例中为test -c:指明collection名，本例中为students students.dat：导入的文件名 ./bin/mongoimport -d test -c students --type csv --headerline --file students_csv.dat -type:指明要导入的文件格式 -headerline:指明第一行是列名，不需要导入 -file：指明要导入的文件 –备份单个表mongodump -u superuser -p 123456 --port 27017 --authenticationDatabase admin -d myTest -c d -o /backup/mongodb/myTest_d_bak_201507021701.bak –备份单个库mongodump -u superuser -p 123456 --port 27017 --authenticationDatabase admin -d myTest -o /backup/mongodb/ –备份所有库mongodump -u superuser -p 123456 --authenticationDatabase admin --port 27017 -o /root/bak –备份所有库推荐使用添加–oplog参数的命令，这样的备份是基于某一时间点的快照，只能用于备份全部库时才可用，单库和单表不适用：mongodump -h 127.0.0.1 --port 27017 --oplog -o /root/bak –同时，恢复时也要加上–oplogReplay参数，具体命令如下(下面是恢复单库的命令)：mongorestore -d swrd --oplogReplay /home/mongo/swrdbak/swrd/ –恢复单个库：mongorestore -u superuser -p 123456 --port 27017 --authenticationDatabase admin -d myTest /backup/mongodb/ –恢复所有库：mongorestore -u superuser -p 123456 --port 27017 --authenticationDatabase admin /root/bak –恢复单表mongorestore -u superuser -p 123456 --authenticationDatabase admin -d myTest -c d /backup/mongodb/myTest_d_bak_201507021701.bak/myTest/d.bson]]></content>
      <categories>
        <category>mongo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库迁移如mongo数据库步骤]]></title>
    <url>%2F2018%2F07%2F24%2Fcq%E5%B9%B3%E5%8F%B0%E8%BF%81%E7%A7%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E6%AD%A5%E9%AA%A4%2F</url>
    <content type="text"><![CDATA[备份MySQL12root@db:/# mysqldump -uroot -p -d campus&gt;campus.sql #密码 Passwrd备份Mongo12root@mongo:~# mongodump -d user -o userroot@mongo:~# mongodump -d store -o store将MySQL备份成Mongo格式，使用python脚本来实现，脚本如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import pymysql,osimport pandas as pdfrom sqlalchemy import create_enginehost='192.168.100.100'port=3306user='root'password='123qwe'database='data'#存放导出的数据的路径BASE_DIR="D:\\mygit\\old\\"#定义连接数据库的引擎dbconn=pymysql.connect( host=host, port=port, user=user, password=password, database=database, charset='utf8', cursorclass=pymysql.cursors.DictCursor )table_list=[]#查询数据库中的表的sql语句tab_sql="show tables;"#获取查询数据库游标cursor=dbconn.cursor()#执行查询所有表cursor.execute(tab_sql)#获取查询的结果，结果是一系列字典组成的字典res=cursor.fetchall()#使用循环，将具体的表名从结果中取出来存入存放到一个列表中for i in range(len(res)): table_list.append(res[i]['Tables_in_%s'%database])# print(table_list)cursor.close()dbconn.close()import csvfor t in table_list: print(("%s表中数据"%t).center(50,"*")) #为每一个表新建一个文件，保存输出的结果 path=BASE_DIR+t fp=open(path,'w',encoding="utf-8") conn=pymysql.connect( host=host, port=port, user=user, password=password, database=database, charset='utf8', cursorclass=pymysql.cursors.DictCursor ) cursor=conn.cursor() print(cursor) sql="select * from %s"%t print(sql) cursor.execute(sql) res =cursor.fetchall() for var in res: fileds=var.keys() fp.write(str(var)) fp.close()将导出的文件导入Mongo123456789#!/bin/bashBASE_PATH="/root/old"for var in `ls $BASE_PATH` :do echo $var #mongoimport -uadmin -pPassw0rd -d old -c $var $BASE_PATH/$var mongoimport -d old -c $var $BASE_PATH/$vardone将MySQL导出为csv格式1mysql -uusername -ppassword -h 172.16.81.236 –D my_db --default-character-set=gbk -e 'select * from server_warning_unrepaired' | sed 's/\t/","/g;s/^/"/;s/$/"/;s/\n//g' &gt; /tmp/file.csv将csv到如到mongo1mongoimport --db network1 --collection networkmanagement --type csv --headerline --ignoreBlanks --file /home/erik/Documents/networkmanagement-1.csv]]></content>
      <categories>
        <category>mongo</category>
      </categories>
      <tags>
        <tag>mysql迁移</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker设置本地仓库]]></title>
    <url>%2F2018%2F07%2F24%2Fdocker_registry%2F</url>
    <content type="text"><![CDATA[account:chenqmcopenssl req -newkey rsa:4096 -nodes -sha256 -keyout ${HOSTNAME}.key -x509 -days 365 -out ${HOSTNAME}.crt vim /etc/docker/daemon.json{&quot;registry-mirrors&quot;: [&quot;http://187193f5.m.daocloud.io&quot;]} 拉取registrydocker pull registry 启动registrydocker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 将镜像进行tag打包，传入本地镜像[root@www1 ~]# docker tag 471e783ffeca 127.0.0.1:5000/mdc-cas [root@www1 ~]# docker push 127.0.0.1:5000/mdc-cas]]></content>
      <categories>
        <category>docker</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[根据PID查看进程启动路径]]></title>
    <url>%2F2018%2F07%2F24%2Fshell%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[12345根据PID查看进程启动路径cqxyw1 ~ # ps eho command -p 30143/// MvGJ6F80QE USER=www-data PWD=/tmp HOME=/var/www SHLVL=3 _=/usr/bin/nohup OLDPWD=/srv/drupal根据pid查看网络状况netstat -pan | grep 23371/// MvGJ6F80QE USER=www-data PWD=/tmp HOME=/var/www SHLVL=3 _=/usr/bin/nohup OLDPWD=/srv/drupal]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux系统根目录扩容]]></title>
    <url>%2F2018%2F07%2F24%2F%E6%A0%B9%E7%9B%AE%E5%BD%95%E6%89%A9%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[VMware的虚机根目录空间不足，添加一个100g磁盘，然后给根目录进行磁盘扩展原磁盘：/dev/sda 20g新磁盘：/dev/sdb 100g1234567891011[root@server ~]# df -ThFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/centos-root xfs 17G 8.7G 8.4G 51% /devtmpfs devtmpfs 1.5G 0 1.5G 0% /devtmpfs tmpfs 1.5G 0 1.5G 0% /dev/shmtmpfs tmpfs 1.5G 11M 1.5G 1% /runtmpfs tmpfs 1.5G 0 1.5G 0% /sys/fs/cgroup/dev/sda1 xfs 1014M 137M 878M 14% /boottmpfs tmpfs 300M 4.0K 300M 1% /run/user/42tmpfs tmpfs 300M 28K 300M 1% /run/user/1000/dev/sr0 iso9660 4.2G 4.2G 0 100% /run/media/qmc/CentOS 7 x86_641234567891011121314151617181920212223242526272829303132333435[root@server ~]# pvcreate /dev/sdb Physical volume "/dev/sdb" successfully created. [root@server ~]# vgs #查看当前卷组名centos VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;19.00g 0 [root@server ~]# vgextend centos /dev/sdb Volume group "centos" successfully extended[root@server ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 2 2 0 wz--n- 118.99g &lt;100.00g[root@server ~]# lvextend /dev/centos/root /dev/sdb Size of logical volume centos/root changed from &lt;17.00 GiB (4351 extents) to 116.99 GiB (29950 extents). Logical volume centos/root successfully resized.[root@server ~]# xfs_growfs /dev/mapper/centos-root meta-data=/dev/mapper/centos-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0data blocks changed from 4455424 to 30668800[root@server ~]# df -ThFilesystem Type Size Used Avail Use% Mounted on/dev/mapper/centos-root xfs 117G 8.7G 109G 8% /devtmpfs devtmpfs 1.5G 0 1.5G 0% /devtmpfs tmpfs 1.5G 0 1.5G 0% /dev/shmtmpfs tmpfs 1.5G 11M 1.5G 1% /runtmpfs tmpfs 1.5G 0 1.5G 0% /sys/fs/cgroup/dev/sda1 xfs 1014M 137M 878M 14% /boottmpfs tmpfs 300M 4.0K 300M 1% /run/user/42tmpfs tmpfs 300M 28K 300M 1% /run/user/1000/dev/sr0 iso9660 4.2G 4.2G 0 100% /run/media/qmc/CentOS 7 x86_64]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[virsh相关命令]]></title>
    <url>%2F2018%2F07%2F24%2F%E5%85%B3%E4%BA%8Evirsh%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[关于virsh相关命令常用文件路径1234567891011虚拟机配置文件默认路径：[root@bainuo qemu]# pwd/etc/libvirt/qemu[root@bainuo qemu]# lsnetworks vm01.xml磁盘文件默认路径：[root@bainuo images]# pwd/var/lib/libvirt/images[root@bainuo images]# lsvm01.img虚机1234567891011121314151617181920212223242526272829303132333435363738394041424344virsh命令参数 功能 用法举例list 查看已经存在的domain信息(可以带参数) virsh list --all (查看所有的虚拟机)start 开始一个不活跃的domain(前提是存在) virsh start test2autostart 配置domain随boot启动 virsh autostart test2shutdown 优雅的关闭domain virsh shutdown test2destroy 立刻终止一个domain(强制关闭) virsh destroy test2reboot 重启一个domain(仅仅发送reboot命令) virsh reboot test2suspend 挂起服务器 virsh suspend test2resume 恢复服务器 virsh resume test2console 连接domain的虚拟的控制台(只能有1个) virsh console test2ttyconsole 输出设备使用的domain的tty console virsh ttyconsole test2dominfo 返回关于domain的基本信息 virsh dominfo test2migrate 迁移一个domain到另一台主机 KVM虚拟网络管理命令(virtual network)：virsh命令参数 功能 用法举例net-autostart 配置一个虚拟网络开机自启(--disable可以关闭) virsh net-autostart br0net-create 通过一个xml文件创建一个虚拟网络 virsh net-create ./virbr1.xmlnet-define 通过xml文件定义一个虚拟网络，仅定义不实例化 virsh net-define ./virbr1.xmlnet-destory 停止由其名称(uuid)指定的虚拟网络，立即生效 virsh net-destroy br0net-dumpxml 以xml文件的形式输出一个虚拟网络的配置信息 virsh net-dumpxml br0net-edit 编辑一个虚拟网络的配置文件(修改虚拟网络配置) virsh net-edit br0net-info 返回要查看的虚拟网络的基本信息 virsh net-info defaultnet-list 查看当前的虚拟网络信息(可以带参数) virsh net-list --allnet-name net-start 开始一个不活跃的虚拟网络 virsh net-start br0net-undefine 将一个不活跃的虚拟网络取消定义 virsh net-undefine br0net-uuid net-update 创建并启用一个网络：net-define -&gt; net-startvirsh net-define br0.xmlvirsh net-list --all (有br0网络,但处于不活跃状态)virsh net-start br0virsh net-list --all (br0网络已处于活跃状态) 停用并删除一个网络(以br0为例)： net-destroy -&gt; net-undefinevirsh net-destroy br0virsh net-list --all (br0网络变为不活跃状态)virsh net-undefine br0virsh net-list --all (br0网络已被删除)存储池12345678910111213创建基于文件夹的存储池1) 定义一个存储池virsh pool-define-as kvm_images dir - - - - “/kvm/images”2) 查看创建的存储池信息virsh pool-list –all3) 建立基于文件夹的存储池virsh pool-build kvm_images4) 使存储池生效virsh pool-start kvm_images5) 这时候，存储池还不是自动运行，使用virsh pool-autostartvirsh pool-autostart kvm_images6) 验证存储池virsh pool-info kvm_images123456789101112131415161718192021222324 virsh回车进入交互式界面：versionpwdhostname 显示本节点主机名nodeinfo 显示节点信息list --all 显示所有云主机7种状态： running 运行中 idel 空闲，未运行 paused 暂停状态 shutdown 关闭 crashed 虚拟机崩溃 dying 垂死状态，但是又没有完全关闭或崩溃 shutdown &lt;domain&gt; destroy &lt;domain&gt; 强制关闭虚拟机（相当于直接拨电源） start &lt;domain&gt; 启动虚拟机 edit &lt;domain&gt; 编辑该虚拟机的xml文件 dommemstat &lt;domain&gt; 获取domain的内存状态 suspend &lt;domain&gt; 挂起一个正在运行的虚拟机，该虚拟机仍占资源； resume &lt;domain&gt; 从挂起状态恢复一下虚拟机 vcpuinfo &lt;domain&gt; 显示一些虚拟机的vcpu的信息 vncdisplay &lt;domain&gt; 显示vnc监听地址和端口快照相关命令12345snapshot-create &lt;domain&gt; xmlfile 给domain创建一个snapshot，详细内容保存在xmlfile中snapshot-current &lt;domain&gt; 显示一个domain的当前的snapshotsnapshot-list &lt;domain&gt; 显示一个domain的所有的snapshotsnapshot-revert &lt;domain&gt; snapshot 恢复一个domian到以前的snapshotsnapshot-delete &lt;domain&gt; snapshot --children 删除一个domain的snapshot如何用libvirt远程管理虚拟机？12345678910111213141516171819要用libvirt连接到超级管理程序，我们需要一个URI，这个URI配合virsh和virt-viewer命令使用，后面可以跟一些可选项，virt-viewer可以调用一些链接参数，例如：virsh -c qemu:///system 当链接到远程机器时，可以定义几种使用的协议：ssh，tcp，tls。当链接到远程机器时，需要使用远程主机的用户和主机名进行链接，如果没有定义链接用户，则会使用本机环境的$USER的用户进行链接，当连接到qemu hypervisor时，接受两种链接类型：system可以有所有的访问权限，session有限制的访问。例如：使用full access链接至本机的qemu hypervisor，前面的-c 是为了执行后面的list命令(--connect)virsh -c qemu:///system list使用full access链接至远程主机的qemu hypervisor，每次都要输入ssh密码，改成ssh无密码登陆就不需要输入密码了，直接显示结果。 virsh -c qemu+ssh://tux@mercur/system 直接进入交互virsh模式 virsh -c qemu+ssh://10.1.1.8/system list 直接显示list后的结果 其余连接格式如下： qemu:///session (local access to per-user instance) qemu+unix:///session (local access to per-user instance) qemu:///system (local access to system instance) qemu+unix:///system (local access to system instance) qemu://example.com/system (remote access, TLS/x509) qemu+tcp://example.com/system (remote access, SASl/Kerberos) qemu+ssh:///system (remote access, SSH tunnelled)使用libvirt创建kvm虚拟机：12345671、制作虚拟机镜像qemu-img create -f qcow2 test.qcow2 10G //格式，名字，大小2、下载并复制iso镜像到指定目录（在第3步中创建xml文件中指定）3、创建安装配置文件，demo.xml如下，可以根据自己需求更改virsh define demo.xml //创建虚拟机virsh start test_ubuntu //启动虚拟机virsh vncdisplay test_ubuntu ////查看虚拟机的vnc端口， 然后就可以通过vnc登录来完成虚拟机的安装demo.xml 内容如下 默认路径在/etc/libvirt/qemu123456789101112131415161718192021222324252627282930313233343536373839&lt;domain type='kvm'&gt; &lt;name&gt;test_ubuntu&lt;/name&gt; //虚拟机名称 &lt;memory&gt;1048576&lt;/memory&gt; //最大内存，单位k &lt;currentMemory&gt;1048576&lt;/currentMemory&gt; //可用内存，单位k &lt;vcpu&gt;8&lt;/vcpu&gt; //虚拟cpu个数 &lt;os&gt; &lt;type arch='x86_64' machine='pc'&gt;hvm&lt;/type&gt; &lt;boot dev='cdrom'/&gt; //光盘启动 &lt;/os&gt; &lt;features&gt; &lt;acpi/&gt; &lt;apic/&gt; &lt;pae/&gt; &lt;/features&gt; &lt;clock offset='localtime'/&gt; &lt;on_poweroff&gt;destroy&lt;/on_poweroff&gt; &lt;on_reboot&gt;restart&lt;/on_reboot&gt; &lt;on_crash&gt;destroy&lt;/on_crash&gt; &lt;devices&gt; &lt;emulator&gt;/usr/libexec/qemu-kvm&lt;/emulator&gt; &lt;disk type='file' device='disk'&gt; &lt;driver name='qemu' type='qcow2'/&gt; &lt;source file='/var/lib/libvirt/images/test.qcow2'/&gt; //目的镜像路径 &lt;target dev='hda' bus='ide'/&gt; &lt;/disk&gt; &lt;disk type='file' device='cdrom'&gt; &lt;source file='/var/lib/libvirt/images/ubuntu.iso'/&gt; //光盘镜像路径 &lt;target dev='hdb' bus='ide'/&gt; &lt;/disk&gt; &lt;interface type='bridge'&gt; //虚拟机网络连接方式 &lt;source bridge='kvmbr0'/&gt; //当前主机网桥的名称 &lt;mac address="00:16:3e:5d:aa:a8"/&gt; //为虚拟机分配mac地址，务必唯一，否则dhcp获得同样ip,引起冲突 &lt;/interface&gt; &lt;input type='mouse' bus='ps2'/&gt; &lt;graphics type='vnc' port='-1' autoport='yes' listen = '0.0.0.0' keymap='en-us'/&gt; //vnc方式登录，端口号自动分配，自动加1，可以通过virsh vncdisplay来查询 &lt;/devices&gt; &lt;/domain&gt;使用virsh-install安装虚机命令1virt-install \ --name=guest1-rhel5-64 \ --file=/var/lib/libvirt/images/guest1-rhel5-64.dsk \ --file-size=8 \ --nonsparse --graphics spice \ --vcpus=2 --ram=2048 \ --location=http://example1.com/installation_tree/RHEL5.6-Serverx86_64/os \ --network bridge=br0 \ --os-type=linux \ --os-variant=rhel5.4使用 qemu-img 和 qemu-kvm 命令行方式安装1234567891011（1）创建一个空的qcow2格式的镜像文件 qemu-img create -f qcow2 windows-master.qcow2 10G（2）启动一个虚机，将系统安装盘挂到 cdrom，安装操作系统 qemu-kvm -hda windows-master.qcow2 -m 512 -boot d -cdrom /home/user/isos/en_winxp_pro_with_sp2.iso（3）现在你就拥有了一个带操作系统的镜像文件。你可以以它为模板创建新的镜像文件。使用模板的好处是，它会被设置为只读所以可以免于破坏。 qemu-img create -b windows-master.qcow2 -f qcow2 windows-clone.qcow2（4）你可以在新的镜像文件上启动虚机了 qemu-kvm -hda windows-clone.qcow2 -m 400]]></content>
      <categories>
        <category>kvm</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zfs和gluster安装]]></title>
    <url>%2F2018%2F07%2F24%2Fcentos7%E4%B8%8A%E5%AE%89%E8%A3%85zfs%E5%92%8Cgluster%2F</url>
    <content type="text"><![CDATA[在同一台主机上zfs和gluster无法同时安装centos7上安装zfshttps://blog.csdn.net/linuxnews/article/details/512863581、获取163yum源wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo2、安装zfs的yum源yum -y install http://download.zfsonlinux.org/epel/zfs-release.el7_3.noarch.rpm3、安装zfsyum -y install kernel zfs12yum localinstall --nogpgcheck http://epel.mirror.net.in/epel/7/x86_64/e/epel-release-7-5.noarch.rpmyum localinstall --nogpgcheck http://archive.zfsonlinux.org/epel/zfs-release.el7.noarch.rpm1yum install kernel-devel zfszfs命令 ——&gt; https://docs.oracle.com/cd/E26926_01/html/E29115/zfs-1m.htmlzpool命令 ——&gt; https://docs.oracle.com/cd/E26926_01/html/E29115/zpool-1m.html安装gluster1、获取163yum源​ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.163.com/.help/CentOS7-Base-163.repo2、安装最新版本的gluster软件仓库：​ yum -y install centos-release-gluster3103、安装gluster软件：​ yum -y install glusterfs glusterfs-server glusterfs-fuse glusterfs-cli glusterfs-geo-replication4、 查看版本信息：​ glusterfs -VCentOS 7 升级内核到4.4.6 LTSrpm –import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpmyum –enablerepo=elrepo-kernel install kernel-lt-devel kernel-lt -yawk -F\’ ‘$1==”menuentry “ {print $2}’ /etc/grub2.cfggrub2-set-default xxxx rebootuname -r]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建个人博客]]></title>
    <url>%2F2018%2F07%2F24%2Fhexo%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1、安装12345678yum -y install npm gitmkdir /hexocd /hexohexo init npm install npm install --save hexo-admin npm install hexo-cli hexo server2、常用命令12345清理缓存命令：hexo clean重新构建项目：hexo generate启动server: hexo server -p 4000 提交改动到git：hexo deploy新建标签页：hexo new page tags3、博客主题下载网址1https://hexo.io/themes/4、]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客next主题设计]]></title>
    <url>%2F2018%2F07%2F24%2Fhexo%E5%8D%9A%E5%AE%A2next%E4%B8%BB%E9%A2%98%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[hexo博客next主题设计参考文章：http://theme-next.iissnan.com/getting-started.html一、新增访客统计及网站字数统计1234567891011121314151617181920212223242526272829303132331、安装依赖包，切换到博客根目录，打开Git Bash，输入以下代码安装字数统计包npm install hexo-wordcount --save2、打开文件：themes/next/layout/_partials/footer.swig,输入以下代码后保存退出。&lt;!-- 新增访客统计代码 --&gt;&lt;div class="copyright" &gt; &#123;% set current = date(Date.now(), "YYYY") %&#125; &amp;copy; &#123;% if theme.since and theme.since != current %&#125; &#123;&#123; theme.since &#125;&#125; - &#123;% endif %&#125; &lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love"&gt; &lt;i class="fa fa-balance-scale"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class="author" itemprop="copyrightHolder"&gt;&#123;&#123; config.author &#125;&#125;&lt;/span&gt;&lt;/div&gt;&lt;div class="busuanzi-count"&gt; &lt;script async="" src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; &lt;span class="site-uv"&gt; &lt;i class="fa fa-user"&gt;&lt;/i&gt; 访问用户： &lt;span class="busuanzi-value" id="busuanzi_value_site_uv"&gt;&lt;/span&gt; 人 &lt;/span&gt; &lt;div class="powered-by"&gt;&lt;/div&gt; &lt;span class="site-uv"&gt; &lt;i class="fa fa-eye"&gt;&lt;/i&gt; 访问次数： &lt;span class="busuanzi-value" id="busuanzi_value_site_pv"&gt;&lt;/span&gt; 次 &lt;/span&gt; &lt;!-- 博客字数统计 --&gt; &lt;span class="site-pv"&gt; &lt;i class="fa fa-pencil"&gt;&lt;/i&gt; 博客全站共： &lt;span class="post-count"&gt;&#123;&#123; totalcount(site) &#125;&#125;&lt;/span&gt; 字 &lt;/span&gt;&lt;/div&gt;&lt;!-- 新增访客统计代码 END--&gt;二、next主题如何添加动态背景注意：如果next主题在5.1.1以上的话就不用我这样设置，直接在主题配置文件中找到canvas_nest: false，把它改为canvas_nest: true就行了（注意分号后面要加一个空格）修改_layout.swig打开 next/layout/_layout.swig在 &lt; /body&gt;之前添加代码(注意不要放在&lt; /head&gt;的后面)123&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125;修改配置文件打开 /next/_config.yml,在里面添加如下代码：(可以放在最后面)123456# --------------------------------------------------------------# background settings# --------------------------------------------------------------# add canvas-nest effect# see detail from https://github.com/hustcc/canvas-nest.jscanvas_nest: true到此就结束了，运行 hexo clean，然后运行 hexo g,然后运行 hexo s，最后打开浏览器在浏览器的地址栏输入 localhost:4000 就能看到效果了\（￣︶￣）/如果你感觉默认的线条太多的话可以这么设置====&gt;在上一步修改 _layout.swig中，把刚才的这些代码：123&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125;改为1234&#123;% if theme.canvas_nest %&#125;&lt;script type="text/javascript"color="0,0,255" opacity='0.7' zIndex="-2" count="99" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"&gt;&lt;/script&gt;&#123;% endif %&#125;color ：线条颜色, 默认: &#39;0,0,0&#39;；三个数字分别为(R,G,B)opacity: 线条透明度（0~1）, 默认: 0.5count: 线条的总数量, 默认: 150zIndex: 背景的z-index属性，css属性用于控制所在层的位置, 默认: -1三、然hexo内的markdown文件显示文件将网站根目录下的source文件夹下新建images目录，将需要的文件根据自己的需要在新建文件夹来保存图片，引用图片的格式为/images/img/1.jpg四、添加评论可以使用的评论系统有HyperComments：https://www.hypercomments.com （来自俄罗斯的评论系统，使用谷歌账号注册。可以访问，不会用，好气，，）来必力：https://livere.com （来自韩国，使用邮箱注册。）畅言： http://changyan.kuaizhan.com （安装需要备案号。不太好用。）Gitment： https://github.com/imsun/gitment （有点小bug，比如说每次需要手动初始化，登录时会跳到主页。。）Valine: https://github.com/xCss/Valine (基于Leancloud的极简风评论系统，用了下，没效果，是我Next主题的原因还是？）综上，最终采用了来必力。打开来必力官网：https://livere.com按套路注册（有可能注册上面要花费点功夫）。（貌似需要科学上网？之前没科学上网好像登录界面显示不了）。安装点击上方的安装，选择免费的city版本。 获取UUID复制其中的uid字段。打开主题目录下的 blog/themes/next/_config.yml 配置文件，定位到 livere_uid 字段，粘贴上刚刚复制的UID。至此，大功告成。五、添加打赏功能六、添加本地搜索安装 hexo-generator-searchdb，在站点的根目录下执行以下命令：$ npm install hexo-generator-searchdb –save编辑 站点配置文件，新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000编辑 主题配置文件，启用本地搜索功能：123# Local searchlocal_search: enable: true]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[cloudstack管理节点安装参考]]></title>
    <url>%2F2018%2F07%2F24%2Fcloudstack%E7%AE%A1%E7%90%86%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[参考文档：https://www.ibm.com/developerworks/cn/cloud/library/1303_chenyz_cloudstack/]]></content>
      <categories>
        <category>cloudstack</category>
      </categories>
      <tags>
        <tag>cloudstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloudstack安装]]></title>
    <url>%2F2018%2F07%2F24%2Fcloudstack%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[cloudstack安装http://developer.huawei.com/ict/forum/thread-23211.htmlhttps://blog.csdn.net/chengxuyuanyonghu/article/details/78847656https://blog.csdn.net/hejin_some/article/details/72673192https://blog.csdn.net/hzhsan/article/details/44098537/ kvm网络virt-install –virt-type=kvm –name=centos88 –vcpus=2 –memory=4096 –location=/tmp/CentOS-7-x86_64-Minimal-1511.iso –disk path=/home/vms/centos88.qcow2,size=40,format=qcow2 –network bridge=br0 –graphics none –extra-args=’console=ttyS0’ –force1virt-install --connect qemu:///system --name centos7 --memory=1024 --vcpus=2 --disk path=/data/secondary/kali.qcow2,device=disk,format=qcow2,bus=virtio,cache=none,size=5 --cdrom /tmp/CentOS-7-x86_64-DVD-1804.iso --os-type=linux --network bridge=br0,model=virtio,model=e1000 --hvm --virt-type=kvm --noautoconsole --graphics vnc,listen=0.0.0.0,port=59011virt-install --virt-type=kvm --name=centos88 --vcpus=2 --memory=1024 --location=/tmp/CentOS-7-x86_64-DVD-1804.iso --disk path=/data/secondary/kali.qcow2,size=6,format=qcow2 --network bridge=br0 --graphics none --extra-args='console=ttyS0' --force]]></content>
      <categories>
        <category>cloudstack</category>
      </categories>
      <tags>
        <tag>cloudstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cloudstack-概念]]></title>
    <url>%2F2018%2F07%2F24%2Fcloudstack-%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[CloudStack是一个开源的具有高可用性及扩展性的云计算平台 ，现在又Apache基金会在管理。云计算的三种服务模式123SAAS：软件即服务PAAS：平台即服务IAAS：基础架构即服务区域(Zone)：1区域可以理解为一个数据中心或机房，是逻辑范围最大的组成单元。由一组POD、二级存储、及网络架构组成。区域只能选择一中网络架构。区域间是相互独立的，如需要通信，只能在网络配置打通区域的公有网络。区域之间只能复制ISO和模板，虚拟机不能进行区域之间的迁移工作，如需要，可将虚机转换成模板，再复制到另一个区域。创建时，可以选择该区域是公共区域，还是只对某组用户的私有区域。提供点（POD）1可理解为一个物理机架，包括交换机、服务器和存储。所以提供点内的计算服务器，系统虚机都在同一个子网中集群（cluster）1最小的逻辑组织单元，由一组计算服务器及一个或多个主存储组成， 同一个集群内的服务器必须使用相同的虚拟化管理程序，硬件型号也必须相同。集群内的虚拟机可以在集群内的不同主机之间实现动态迁移。集群内可以添加多个作为共享存储所使用的主存储计算节点（HOST) 就是运行虚拟机（VM）的主机主存储 (一级存储)12一般作为每个集群多台计算服务器共同使用的共享存储存在。一个集群中可以有一个或多个不同类型的存储。主存储用于存储所有虚拟机内数据的镜像文件和数据卷文件。分为共享存储和本地存储。使用共享存储可以实现虚机的在线迁移。一级存储与 cluster 关联，它为该 cluster 中的主机的全部虚拟机提供磁盘卷。一个 cluster 至少有一个一级存储，且在部署时位置要临近主机以提供高性能。二级存储12每个区域只需要一个二级存储，用于存放创建虚拟所使用的ISO镜像文件、模板文件，以及对虚机所做的快照和卷备份文件。这些都是占用空间大、读写频率低的数据文件(冷数据),并不是关键数据，使用配置不高、最简单的NFS来存储就够了。二级存储与 zone 关联，它存储模板文件，ISO 镜像和磁盘卷快照。一个 zone 包含多个 pod，一个 pod 包含多个 cluster，一个 cluster 包含多个 host123模板：可以启动虚拟机的操作系统镜像，也包括了诸如已安装应用的其余配置信息。ISO 镜像：包含操作系统数据或启动媒质的磁盘镜像。磁盘卷快照：虚拟机数据的已储存副本，能用于数据恢复或者创建新模板。123一个完整的 CloudStack 环境包括两部分： 管理服务器（Management Server） 虚拟机管理器 (Hypervisor) 也叫主机host或者代理agent虚拟机实例的动态迁移12静态迁移：在虚拟机关机或暂停的情况下从一台物理机迁移到另一台物理机动态迁移：让虚拟机在不关机且能持续提供服务的前提下，从一个虚拟平台的主机（Host）迁移到其他虚拟平台的主机上运行，中间仅有非常短暂的停机时间，普通用户无法对自己的虚拟机进行动态迁移，只有管理员可以。虚拟机实例的动态迁移只能在同一集群中进安全组1安全组相当于在虚拟机实例的操作系统之外部署了一道防火墙，每个CloudStack账户都会生成一个默认安全组，该组默认拒绝所有流入流量和允许所有流出流量。一个用户可以创建多个安全组，一个安全组可以应用到多个虚拟机实例上，一个虚拟机实例也可以使用多个安全组。一个安全组相当于一条或多条防火墙规则。虚拟机实例在创建时可以选择多个安全组，选择后不可以加入或退出其他安全组高级网络功能12345678910111213141516171819202122232425虚拟路由器本质上一个运行Debian 7.0的虚拟机实例，提供了各种高级网络管理功能。1、防火墙（不能基于账户进行策略指定，也不能设定出口规则） 不能基于账户进行策略指定，也不能设定出口规则 默认可以访问外部服务，但外部服务不能访问虚拟机实例2、负载均衡 负载均衡有工作在二层，三层，四层和七层的负载均衡 可以通过集群的方式来保证高可用 CloudStack的负载均衡是通过在虚拟路由器里使用HAProxy实现的 轮询算法：根据用户的请求依次将请求转发给内部的应用服务器 最少连接算法：把当前请求分配给连接数最少的应用服务器 源算法：尽量保证始终来自同一个客户端的请求分发给同一个应用服务器，适用于不使用Cookie的Web应用 要使用负载均衡，前端的负载均衡器需要为该服务配置一个服务IP地址，服务地址用于接收用户的请求。 公用端口用于接收用户外部的请求，专用端口指虚拟机提供服务的端口3、静态NAT：将内外的私有IP转换为公有IP（1对1）4、端口转发：把访问A服务器某端口的数据转发到B服务器的某端口中5、VPN VPN可以使用户安全，方便地访问一个虚拟网络内的所有虚拟机 默认情况下，防火墙信任VPN拨入者6、VPC：Virtual Private Cloud 从整体网络中分割出来的一个逻辑隔离的网络，在该虚拟网络中，用户具有完全的控制权7、冗余路由 使用多个路由来防止单点故障时导致内部网络不能与外部网络通信的问题 冗余路由组共用一个内网IP（网关）和一个外网IP 提供冗余功能的两天虚拟路由器应尽量运行在不同物理主机上]]></content>
      <categories>
        <category>cloudstack</category>
      </categories>
      <tags>
        <tag>cloudstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VNC安装]]></title>
    <url>%2F2018%2F07%2F24%2FVNC%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[VNC安装安装在Centos71、安装的centos已经安装了GUI桌面系统123456#安装桌面版，安装有500M以上，有点慢yum groupinstall "GNOME Desktop" "Graphical Administration Tools" #默认使用图形化桌面启动,三种命令ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target systemctl set-default runlevel5.target systemctl set-default graphical.target2、安装vncserver1yum -y install tigervnc-server3、启动并配置vncserver12[root@cloud ~]# vncserver [root@cloud ~]# vncpasswd4、修改配置文件12345678910111213141516171819202122[root@cloud ~]# cd /root/.vnc/[root@cloud .vnc]# cat config [Unit]Description=Remote desktop service (VNC)After=syslog.target network.target[Service]Type=forkingUser=root #设置远程连接用户为root# Clean any existing files in /tmp/.X11-unix environmentExecStartPre=/bin/sh -c '/usr/bin/vncserver -kill 1 &gt; /dev/null 2&gt;&amp;1 || :'#这一句不要改变ExecStart=/usr/bin/vncserver :1 -geometry 1280x1024 -depth 16 -securitytypes=none -fp /usr/share/X11/fonts/miscPIDFile=/root/.vnc/%H%i.pidExecStop=/bin/sh -c '/usr/bin/vncserver -kill 1 &gt; /dev/null 2&gt;&amp;1 || :'[Install]WantedBy=multi-user.target5、修改完后启动 vncserver-1[root@cloud system]# systemctl start vncserver@\:1.service6、然后使用vncviewer，输入IP:5901就可以连接到虚机了安装在win10下载server和viewer两个版本，都分别安装https://www.xp510.com/xiazai/Networking/mstsc/23862.htmlserver配置：]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>VNC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程线程]]></title>
    <url>%2F2018%2F07%2F03%2F%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程、线程、多线程相关总结一、说说概念1、进程（process）狭义定义：进程就是一段程序的执行过程。广义定义：进程是一个具有一定独立功能的程序关于某个数据集合的一次运行活动。它是操作系统动态执行的基本单元，在传统的操作系统中，进程既是基本的分配单元，也是基本的执行单元。简单的来讲进程的概念主要有两点：第一，进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。进程状态：进程有三个状态，就绪、运行和阻塞。就绪状态其实就是获取了出cpu外的所有资源，只要处理器分配资源就可以马上执行。就绪状态有排队序列什么的，排队原则不再赘述。运行态就是获得了处理器分配的资源，程序开始执行。阻塞态，当程序条件不够时候，需要等待条件满足时候才能执行，如等待i/o操作时候，此刻的状态就叫阻塞态。2、程序说起进程，就不得不说下程序。先看定义：程序是指令和数据的有序集合，其本身没有任何运行的含义，是一个静态的概念。而进程则是在处理机上的一次执行过程，它是一个动态的概念。这个不难理解，其实进程是包含程序的，进程的执行离不开程序，进程中的文本区域就是代码区，也就是程序。3、线程通常在一个进程中可以包含若干个线程，当然一个进程中至少有一个线程，不然没有存在的意义。线程可以利用进程所拥有的资源，在引入线程的操作系统中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。4、多线程在一个程序中，这些独立运行的程序片段叫作“线程”（Thread），利用它编程的概念就叫作“多线程处理”。多线程是为了同步完成多项任务，不是为了提高运行效率，而是为了提高资源使用效率来提高系统的效率。线程是在同一时间需要完成多项任务的时候实现的。最简单的比喻多线程就像火车的每一节车厢，而进程则是火车。车厢离开火车是无法跑动的，同理火车也不可能只有一节车厢。多线程的出现就是为了提高效率。二、说说区别1、进程与线程的区别：进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.2) 线程的划分尺度小于进程，使得多线程程序的并发性高。3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。三、说说优缺点线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP(多核处理机)机器上运行，而进程则可以跨机器迁移。四、总结入职第一天闲的无聊，参考下别人的总结自己也简单总结了下。知道以上的基本面试够用了，至于进程、线程的细节，底层构成，调度等问题是操作系统的东西。我就不详述了。五、实例1、多线程写日志，涉及到单例模式，异步写]]></content>
      <categories>
        <category>进程线程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git和markdown使用总结]]></title>
    <url>%2F2018%2F06%2F21%2Fgit%E5%92%8Cmarkdown%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[git 上传更新代码步骤- git pull #先拉取最新代码 - 将自己的写好的代码放入到相应的文件夹下，比如op/issues - 如果有图片将对应的图片也复制到当前目录下的img下 - git add 自己加入到的文件和图片 - git commit 自己加入和文件和图片 -m message - 这里如果不加-m message 选项可能会push不成功，最好加上 - git push #上传自己新加的文件到GitHub markdown语法总结- 图片方法一： - 加入图片，格式是 ![]() - 其中的[]中的内容可以自定义，比如[log] - ()中写使用该图片的文件相对图片的相对路径 方法二： &lt;img src=&quot;images/img/1.jpg&quot; width=256 height=256 /&gt; 图片引用方法一实例此时img文件夹和当前文档在同一级目录下 ![1](/images/img/1.jpg) ![2](/images/img/2.jpg) 图片引用方法二实例，可以控制图片大小&lt;img src=&quot;/images/img/1.jpg&quot; width=256 height=256 /&gt; &lt;img src=&quot;/images/img/2.jpg&quot; width=256 height=256 /&gt; 让图片居中的方法，使用div标签&lt;div align=center&gt; &lt;img src=&quot;/images/img/1.jpg&quot; width=256 height=256 /&gt; &lt;/div&gt; - 斜体- 用左右各一个 *的方式包裹住文字就是斜体的语法 - 粗体- 用左右各两个**的方式包裹住文字就是粗体的语法 - 改变字体大小- 一个字、一句话、一个段落加上#就可以改变字体的大小 - 分割线- 输入三个--就可以得到分割线 - 引用-在内容首位加入&gt;符号即可 - 表格1、 原生的表格语法 | 嘻嘻 | 哈哈 | 呵呵 | :------------- :|:-------------:| :-----:| | 你好|我好|大家好 | | 是的| 是的 | 是的 | 2、 也可以使用html语言来实现，实例如下 &lt;table&gt; &lt;tr&gt; &lt;th width=10%, bgcolor=yellow &gt;参数&lt;/th&gt; &lt;th width=40%, bgcolor=yellow&gt;详细解释&lt;/th&gt; &lt;th width=50%, bgcolor=yellow&gt;备注&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor=#eeeeee&gt; -l &lt;/td&gt; &lt;td&gt; use a long listing format &lt;/td&gt; &lt;td&gt; 以长列表方式显示（显示出文件/文件夹详细信息） &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td bgcolor=#00FF00&gt;-t &lt;/td&gt; &lt;td&gt; sort by modification time &lt;/td&gt; &lt;td&gt; 按照修改时间排序（默认最近被修改的文件/文件夹排在最前面） &lt;/td&gt; &lt;tr&gt; &lt;td bgcolor=rgb(0,10,0)&gt;-r &lt;/td&gt; &lt;td&gt; reverse order while sorting &lt;/td&gt; &lt;td&gt; 逆序排列 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; html方式实现表格实例参数详细解释备注-luse a long listing format以长列表方式显示（显示出文件/文件夹详细信息）-tsort by modification time按照修改时间排序（默认最近被修改的文件/文件夹排在最前面）-rreverse order while sorting逆序排列]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
